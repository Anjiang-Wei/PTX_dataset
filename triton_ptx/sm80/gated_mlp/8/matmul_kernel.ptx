//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	matmul_kernel           // -- Begin function matmul_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel
.visible .entry matmul_kernel(
	.param .u64 .ptr .global .align 1 matmul_kernel_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_8
)
.reqntid 256
{
	.reg .pred 	%p<91>;
	.reg .b32 	%r<5141>;
	.reg .b64 	%rd<186>;
	.loc	1 68 0                          // gated_mlp.py:68:0
$L__func_begin0:
	.loc	1 68 0                          // gated_mlp.py:68:0

// %bb.0:
	ld.param.b32 	%r494, [matmul_kernel_param_7];
	ld.param.b32 	%r493, [matmul_kernel_param_6];
	ld.param.b32 	%r492, [matmul_kernel_param_4];
	ld.param.b32 	%r491, [matmul_kernel_param_3];
	ld.param.b64 	%rd41, [matmul_kernel_param_2];
	ld.param.b64 	%rd40, [matmul_kernel_param_1];
	ld.param.b64 	%rd39, [matmul_kernel_param_0];
$L__tmp0:
	.loc	1 91 24                         // gated_mlp.py:91:24
	mov.u32 	%r591, %ctaid.x;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:93:27 ]
	add.s32 	%r592, %r491, 255;
	.loc	2 40 28                         // standard.py:40:28 @[ gated_mlp.py:93:27 ]
	shr.s32 	%r593, %r592, 31;
	shr.u32 	%r594, %r593, 24;
	add.s32 	%r595, %r592, %r594;
	shr.s32 	%r596, %r595, 8;
$L__tmp2:
	.loc	1 94 38                         // gated_mlp.py:94:38
	shl.b32 	%r598, %r596, 3;
	.loc	1 95 22                         // gated_mlp.py:95:22
	div.s32 	%r599, %r591, %r598;
	.loc	1 96 29                         // gated_mlp.py:96:29
	shl.b32 	%r1, %r599, 3;
	.loc	1 97 35                         // gated_mlp.py:97:35
	sub.s32 	%r600, 1, %r1;
	.loc	1 97 48                         // gated_mlp.py:97:48
	min.s32 	%r2, %r600, 8;
	.loc	1 98 34                         // gated_mlp.py:98:34
	mul.lo.s32 	%r601, %r599, %r598;
	sub.s32 	%r3, %r591, %r601;
	.loc	1 99 40                         // gated_mlp.py:99:40
	div.s32 	%r4, %r3, %r2;
	.loc	1 109 23                        // gated_mlp.py:109:23
	shl.b32 	%r602, %r4, 8;
	.loc	1 109 51                        // gated_mlp.py:109:51
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r5, 3;
	and.b32 	%r7, %r6, 120;
	and.b32 	%r8, %r5, 16;
	and.b32 	%r603, %r6, 248;
	.loc	1 109 38                        // gated_mlp.py:109:38
	or.b32 	%r9, %r602, %r603;
	.loc	1 109 68                        // gated_mlp.py:109:68
	rem.s32 	%r10, %r9, %r491;
	.loc	1 110 26                        // gated_mlp.py:110:26
	and.b32 	%r11, %r5, 128;
	shr.u32 	%r604, %r5, 5;
	bfe.u32 	%r12, %r5, 5, 3;
	or.b32 	%r13, %r12, 8;
	or.b32 	%r14, %r12, 16;
	or.b32 	%r15, %r604, 24;
	or.b32 	%r16, %r12, 32;
	or.b32 	%r17, %r12, 40;
	or.b32 	%r18, %r12, 48;
	or.b32 	%r19, %r604, 56;
	or.b32 	%r20, %r12, 64;
	or.b32 	%r21, %r12, 72;
	or.b32 	%r22, %r12, 80;
	or.b32 	%r23, %r604, 88;
	or.b32 	%r24, %r12, 96;
	or.b32 	%r25, %r12, 104;
	or.b32 	%r26, %r12, 112;
	or.b32 	%r27, %r604, 120;
	.loc	1 111 22                        // gated_mlp.py:111:22
	mul.wide.u32 	%rd90, %r7, 2;
	add.s64 	%rd42, %rd39, %rd90;
	.loc	1 112 40                        // gated_mlp.py:112:40
	mul.lo.s32 	%r605, %r493, %r12;
	shl.b32 	%r606, %r493, 3;
	add.s32 	%r607, %r605, %r606;
	add.s32 	%r608, %r607, %r606;
	shl.b32 	%r609, %r493, 4;
	add.s32 	%r610, %r608, %r609;
	add.s32 	%r611, %r610, %r606;
	add.s32 	%r612, %r611, %r606;
	add.s32 	%r613, %r612, %r609;
	add.s32 	%r614, %r613, %r606;
	add.s32 	%r615, %r614, %r606;
	add.s32 	%r616, %r615, %r609;
	add.s32 	%r617, %r616, %r606;
	add.s32 	%r618, %r617, %r606;
	.loc	1 112 52                        // gated_mlp.py:112:52
	add.s32 	%r619, %r10, %r605;
	add.s32 	%r620, %r10, %r607;
	add.s32 	%r621, %r10, %r608;
	mad.lo.s32 	%r622, %r493, %r15, %r10;
	add.s32 	%r623, %r10, %r610;
	add.s32 	%r624, %r10, %r611;
	add.s32 	%r625, %r10, %r612;
	mad.lo.s32 	%r626, %r493, %r19, %r10;
	add.s32 	%r627, %r10, %r613;
	add.s32 	%r628, %r10, %r614;
	add.s32 	%r629, %r10, %r615;
	mad.lo.s32 	%r630, %r493, %r23, %r10;
	add.s32 	%r631, %r10, %r616;
	add.s32 	%r632, %r10, %r617;
	add.s32 	%r633, %r10, %r618;
	mad.lo.s32 	%r634, %r493, %r27, %r10;
	.loc	1 112 22                        // gated_mlp.py:112:22
	mul.wide.s32 	%rd91, %r619, 2;
	add.s64 	%rd50, %rd40, %rd91;
	mul.wide.s32 	%rd92, %r620, 2;
	add.s64 	%rd51, %rd40, %rd92;
	mul.wide.s32 	%rd93, %r621, 2;
	add.s64 	%rd52, %rd40, %rd93;
	mul.wide.s32 	%rd94, %r622, 2;
	add.s64 	%rd53, %rd40, %rd94;
	mul.wide.s32 	%rd95, %r623, 2;
	add.s64 	%rd54, %rd40, %rd95;
	mul.wide.s32 	%rd96, %r624, 2;
	add.s64 	%rd55, %rd40, %rd96;
	mul.wide.s32 	%rd97, %r625, 2;
	add.s64 	%rd56, %rd40, %rd97;
	mul.wide.s32 	%rd98, %r626, 2;
	add.s64 	%rd57, %rd40, %rd98;
	mul.wide.s32 	%rd99, %r627, 2;
	add.s64 	%rd58, %rd40, %rd99;
	mul.wide.s32 	%rd100, %r628, 2;
	add.s64 	%rd59, %rd40, %rd100;
	mul.wide.s32 	%rd101, %r629, 2;
	add.s64 	%rd60, %rd40, %rd101;
	mul.wide.s32 	%rd102, %r630, 2;
	add.s64 	%rd61, %rd40, %rd102;
	mul.wide.s32 	%rd103, %r631, 2;
	add.s64 	%rd62, %rd40, %rd103;
	mul.wide.s32 	%rd104, %r632, 2;
	add.s64 	%rd63, %rd40, %rd104;
	mul.wide.s32 	%rd105, %r633, 2;
	add.s64 	%rd64, %rd40, %rd105;
	mul.wide.s32 	%rd106, %r634, 2;
	add.s64 	%rd65, %rd40, %rd106;
$L__tmp3:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:120:33 ]
	add.s32 	%r635, %r492, 127;
$L__tmp4:
	.loc	1 129 33                        // gated_mlp.py:129:33
	shl.b32 	%r639, %r493, 7;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p1, %r635, 127;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p2, %r7, %r492;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shr.u32 	%r640, %r5, 1;
	and.b32 	%r641, %r640, 56;
	xor.b32 	%r642, %r641, %r7;
	and.b32 	%r643, %r6, 1920;
	or.b32 	%r29, %r642, %r643;
	shl.b32 	%r644, %r29, 1;
	mov.b32 	%r645, global_smem;
	add.s32 	%r646, %r645, %r644;
	add.s32 	%r495, %r646, 131072;
	add.s32 	%r497, %r646, 135168;
	add.s32 	%r499, %r646, 139264;
	add.s32 	%r501, %r646, 143360;
	add.s32 	%r503, %r646, 147456;
	add.s32 	%r505, %r646, 151552;
	add.s32 	%r507, %r646, 155648;
	add.s32 	%r509, %r646, 159744;
	selp.b32 	%r647, 16, 0, %p1;
	selp.b32 	%r498, %r647, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r495 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r497 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r499 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r501 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r503 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r505 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r507 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r509 + 0 ], [ %rd42 + 0 ], 0x10, %r498;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p3, %r12, %r492;
	setp.lt.s32 	%p4, %r13, %r492;
	setp.lt.s32 	%p5, %r14, %r492;
	setp.lt.s32 	%p6, %r15, %r492;
	setp.lt.s32 	%p7, %r16, %r492;
	setp.lt.s32 	%p8, %r17, %r492;
	setp.lt.s32 	%p9, %r18, %r492;
	setp.lt.s32 	%p10, %r19, %r492;
	setp.lt.s32 	%p11, %r20, %r492;
	setp.lt.s32 	%p12, %r21, %r492;
	setp.lt.s32 	%p13, %r22, %r492;
	setp.lt.s32 	%p14, %r23, %r492;
	setp.lt.s32 	%p15, %r24, %r492;
	setp.lt.s32 	%p16, %r25, %r492;
	setp.lt.s32 	%p17, %r26, %r492;
	setp.lt.s32 	%p18, %r27, %r492;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shr.u32 	%r30, %r5, 2;
	and.b32 	%r31, %r30, 56;
	xor.b32 	%r648, %r31, %r603;
	shl.b32 	%r649, %r12, 8;
	or.b32 	%r32, %r648, %r649;
	shl.b32 	%r650, %r32, 1;
	add.s32 	%r511, %r645, %r650;
	add.s32 	%r513, %r511, 4096;
	add.s32 	%r515, %r511, 8192;
	add.s32 	%r517, %r511, 12288;
	add.s32 	%r519, %r511, 16384;
	add.s32 	%r521, %r511, 20480;
	add.s32 	%r523, %r511, 24576;
	add.s32 	%r525, %r511, 28672;
	add.s32 	%r527, %r511, 32768;
	add.s32 	%r529, %r511, 36864;
	add.s32 	%r531, %r511, 40960;
	add.s32 	%r533, %r511, 45056;
	add.s32 	%r535, %r511, 49152;
	add.s32 	%r537, %r511, 53248;
	add.s32 	%r539, %r511, 57344;
	add.s32 	%r541, %r511, 61440;
	selp.b32 	%r512, %r647, 0, %p3;
	// begin inline asm
	cp.async.cg.shared.global [ %r511 + 0 ], [ %rd50 + 0 ], 0x10, %r512;
	// end inline asm
	selp.b32 	%r514, %r647, 0, %p4;
	// begin inline asm
	cp.async.cg.shared.global [ %r513 + 0 ], [ %rd51 + 0 ], 0x10, %r514;
	// end inline asm
	selp.b32 	%r516, %r647, 0, %p5;
	// begin inline asm
	cp.async.cg.shared.global [ %r515 + 0 ], [ %rd52 + 0 ], 0x10, %r516;
	// end inline asm
	selp.b32 	%r518, %r647, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r517 + 0 ], [ %rd53 + 0 ], 0x10, %r518;
	// end inline asm
	selp.b32 	%r520, %r647, 0, %p7;
	// begin inline asm
	cp.async.cg.shared.global [ %r519 + 0 ], [ %rd54 + 0 ], 0x10, %r520;
	// end inline asm
	selp.b32 	%r522, %r647, 0, %p8;
	// begin inline asm
	cp.async.cg.shared.global [ %r521 + 0 ], [ %rd55 + 0 ], 0x10, %r522;
	// end inline asm
	selp.b32 	%r524, %r647, 0, %p9;
	// begin inline asm
	cp.async.cg.shared.global [ %r523 + 0 ], [ %rd56 + 0 ], 0x10, %r524;
	// end inline asm
	selp.b32 	%r526, %r647, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r525 + 0 ], [ %rd57 + 0 ], 0x10, %r526;
	// end inline asm
	selp.b32 	%r528, %r647, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r527 + 0 ], [ %rd58 + 0 ], 0x10, %r528;
	// end inline asm
	selp.b32 	%r530, %r647, 0, %p12;
	// begin inline asm
	cp.async.cg.shared.global [ %r529 + 0 ], [ %rd59 + 0 ], 0x10, %r530;
	// end inline asm
	selp.b32 	%r532, %r647, 0, %p13;
	// begin inline asm
	cp.async.cg.shared.global [ %r531 + 0 ], [ %rd60 + 0 ], 0x10, %r532;
	// end inline asm
	selp.b32 	%r534, %r647, 0, %p14;
	// begin inline asm
	cp.async.cg.shared.global [ %r533 + 0 ], [ %rd61 + 0 ], 0x10, %r534;
	// end inline asm
	selp.b32 	%r536, %r647, 0, %p15;
	// begin inline asm
	cp.async.cg.shared.global [ %r535 + 0 ], [ %rd62 + 0 ], 0x10, %r536;
	// end inline asm
	selp.b32 	%r538, %r647, 0, %p16;
	// begin inline asm
	cp.async.cg.shared.global [ %r537 + 0 ], [ %rd63 + 0 ], 0x10, %r538;
	// end inline asm
	selp.b32 	%r540, %r647, 0, %p17;
	// begin inline asm
	cp.async.cg.shared.global [ %r539 + 0 ], [ %rd64 + 0 ], 0x10, %r540;
	// end inline asm
	selp.b32 	%r542, %r647, 0, %p18;
	// begin inline asm
	cp.async.cg.shared.global [ %r541 + 0 ], [ %rd65 + 0 ], 0x10, %r542;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p19, %r635, 255;
	.loc	1 128 18                        // gated_mlp.py:128:18
	add.s64 	%rd66, %rd42, 256;
	.loc	1 129 18                        // gated_mlp.py:129:18
	mul.wide.s32 	%rd107, %r639, 2;
	add.s64 	%rd74, %rd50, %rd107;
	add.s64 	%rd75, %rd51, %rd107;
	add.s64 	%rd76, %rd52, %rd107;
	add.s64 	%rd77, %rd53, %rd107;
	add.s64 	%rd78, %rd54, %rd107;
	add.s64 	%rd79, %rd55, %rd107;
	add.s64 	%rd80, %rd56, %rd107;
	add.s64 	%rd81, %rd57, %rd107;
	add.s64 	%rd82, %rd58, %rd107;
	add.s64 	%rd83, %rd59, %rd107;
	add.s64 	%rd84, %rd60, %rd107;
	add.s64 	%rd85, %rd61, %rd107;
	add.s64 	%rd86, %rd62, %rd107;
	add.s64 	%rd87, %rd63, %rd107;
	add.s64 	%rd88, %rd64, %rd107;
	add.s64 	%rd89, %rd65, %rd107;
	.loc	1 123 55                        // gated_mlp.py:123:55
	add.s32 	%r651, %r492, -128;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p20, %r7, %r651;
	.loc	1 123 20                        // gated_mlp.py:123:20
	bar.sync 	0;
	add.s32 	%r543, %r646, 163840;
	add.s32 	%r545, %r646, 167936;
	add.s32 	%r547, %r646, 172032;
	add.s32 	%r549, %r646, 176128;
	add.s32 	%r551, %r646, 180224;
	add.s32 	%r553, %r646, 184320;
	add.s32 	%r555, %r646, 188416;
	add.s32 	%r557, %r646, 192512;
	selp.b32 	%r652, 16, 0, %p20;
	selp.b32 	%r546, %r652, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r543 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r545 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r547 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r549 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r551 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r553 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r555 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r557 + 0 ], [ %rd66 + 0 ], 0x10, %r546;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p21, %r12, %r651;
	setp.lt.s32 	%p22, %r13, %r651;
	setp.lt.s32 	%p23, %r14, %r651;
	setp.lt.s32 	%p24, %r15, %r651;
	setp.lt.s32 	%p25, %r16, %r651;
	setp.lt.s32 	%p26, %r17, %r651;
	setp.lt.s32 	%p27, %r18, %r651;
	setp.lt.s32 	%p28, %r19, %r651;
	setp.lt.s32 	%p29, %r20, %r651;
	setp.lt.s32 	%p30, %r21, %r651;
	setp.lt.s32 	%p31, %r22, %r651;
	setp.lt.s32 	%p32, %r23, %r651;
	setp.lt.s32 	%p33, %r24, %r651;
	setp.lt.s32 	%p34, %r25, %r651;
	setp.lt.s32 	%p35, %r26, %r651;
	setp.lt.s32 	%p36, %r27, %r651;
	.loc	1 124 20                        // gated_mlp.py:124:20
	add.s32 	%r559, %r511, 65536;
	add.s32 	%r561, %r511, 69632;
	add.s32 	%r563, %r511, 73728;
	add.s32 	%r565, %r511, 77824;
	add.s32 	%r567, %r511, 81920;
	add.s32 	%r569, %r511, 86016;
	add.s32 	%r571, %r511, 90112;
	add.s32 	%r573, %r511, 94208;
	add.s32 	%r575, %r511, 98304;
	add.s32 	%r577, %r511, 102400;
	add.s32 	%r579, %r511, 106496;
	add.s32 	%r581, %r511, 110592;
	add.s32 	%r583, %r511, 114688;
	add.s32 	%r585, %r511, 118784;
	add.s32 	%r587, %r511, 122880;
	add.s32 	%r589, %r511, 126976;
	selp.b32 	%r653, 16, 0, %p21;
	selp.b32 	%r560, %r653, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r559 + 0 ], [ %rd74 + 0 ], 0x10, %r560;
	// end inline asm
	selp.b32 	%r654, 16, 0, %p22;
	selp.b32 	%r562, %r654, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r561 + 0 ], [ %rd75 + 0 ], 0x10, %r562;
	// end inline asm
	selp.b32 	%r655, 16, 0, %p23;
	selp.b32 	%r564, %r655, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r563 + 0 ], [ %rd76 + 0 ], 0x10, %r564;
	// end inline asm
	selp.b32 	%r656, 16, 0, %p24;
	selp.b32 	%r566, %r656, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r565 + 0 ], [ %rd77 + 0 ], 0x10, %r566;
	// end inline asm
	selp.b32 	%r657, 16, 0, %p25;
	selp.b32 	%r568, %r657, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r567 + 0 ], [ %rd78 + 0 ], 0x10, %r568;
	// end inline asm
	selp.b32 	%r658, 16, 0, %p26;
	selp.b32 	%r570, %r658, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r569 + 0 ], [ %rd79 + 0 ], 0x10, %r570;
	// end inline asm
	selp.b32 	%r659, 16, 0, %p27;
	selp.b32 	%r572, %r659, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r571 + 0 ], [ %rd80 + 0 ], 0x10, %r572;
	// end inline asm
	selp.b32 	%r660, 16, 0, %p28;
	selp.b32 	%r574, %r660, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r573 + 0 ], [ %rd81 + 0 ], 0x10, %r574;
	// end inline asm
	selp.b32 	%r661, 16, 0, %p29;
	selp.b32 	%r576, %r661, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r575 + 0 ], [ %rd82 + 0 ], 0x10, %r576;
	// end inline asm
	selp.b32 	%r662, 16, 0, %p30;
	selp.b32 	%r578, %r662, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r577 + 0 ], [ %rd83 + 0 ], 0x10, %r578;
	// end inline asm
	selp.b32 	%r663, 16, 0, %p31;
	selp.b32 	%r580, %r663, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r579 + 0 ], [ %rd84 + 0 ], 0x10, %r580;
	// end inline asm
	selp.b32 	%r664, 16, 0, %p32;
	selp.b32 	%r582, %r664, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r581 + 0 ], [ %rd85 + 0 ], 0x10, %r582;
	// end inline asm
	selp.b32 	%r665, 16, 0, %p33;
	selp.b32 	%r584, %r665, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r583 + 0 ], [ %rd86 + 0 ], 0x10, %r584;
	// end inline asm
	selp.b32 	%r666, 16, 0, %p34;
	selp.b32 	%r586, %r666, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r585 + 0 ], [ %rd87 + 0 ], 0x10, %r586;
	// end inline asm
	selp.b32 	%r667, 16, 0, %p35;
	selp.b32 	%r588, %r667, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r587 + 0 ], [ %rd88 + 0 ], 0x10, %r588;
	// end inline asm
	selp.b32 	%r668, 16, 0, %p36;
	selp.b32 	%r590, %r668, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r589 + 0 ], [ %rd89 + 0 ], 0x10, %r590;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	@%p1 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:                              // %.lr.ph
	.loc	1 0 0                           // gated_mlp.py:0
	cvt.s64.s32 	%rd1, %r619;
	cvt.s64.s32 	%rd2, %r620;
	cvt.s64.s32 	%rd3, %r621;
	cvt.s64.s32 	%rd4, %r622;
	cvt.s64.s32 	%rd5, %r623;
	cvt.s64.s32 	%rd6, %r624;
	cvt.s64.s32 	%rd7, %r625;
	cvt.s64.s32 	%rd8, %r626;
	cvt.s64.s32 	%rd9, %r627;
	cvt.s64.s32 	%rd10, %r628;
	cvt.s64.s32 	%rd11, %r629;
	cvt.s64.s32 	%rd12, %r630;
	cvt.s64.s32 	%rd13, %r631;
	cvt.s64.s32 	%rd14, %r634;
	shr.s32 	%r636, %r635, 31;
	shr.u32 	%r637, %r636, 25;
	add.s32 	%r638, %r635, %r637;
	shr.s32 	%r28, %r638, 7;
	cvt.s64.s32 	%rd15, %r639;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shr.u32 	%r737, %r8, 1;
	.loc	1 109 51                        // gated_mlp.py:109:51
	bfe.s32 	%r738, %r5, 2, 1;
	add.s32 	%r34, %r28, -2;
	and.b32 	%r739, %r5, 3;
	mul.lo.s32 	%r740, %r739, 136;
	and.b32 	%r741, %r738, 544;
	xor.b32 	%r742, %r741, %r740;
	shl.b32 	%r743, %r5, 7;
	and.b32 	%r744, %r743, 1024;
	or.b32 	%r745, %r742, %r744;
	xor.b32 	%r746, %r745, %r737;
	shl.b32 	%r747, %r11, 4;
	or.b32 	%r35, %r746, %r747;
	xor.b32 	%r36, %r35, 16;
	xor.b32 	%r37, %r35, 32;
	xor.b32 	%r38, %r35, 48;
	xor.b32 	%r39, %r35, 64;
	xor.b32 	%r40, %r35, 80;
	xor.b32 	%r41, %r35, 96;
	xor.b32 	%r42, %r35, 112;
	or.b32 	%r43, %r35, 4096;
	xor.b32 	%r44, %r35, 4112;
	xor.b32 	%r45, %r35, 4128;
	xor.b32 	%r46, %r35, 4144;
	xor.b32 	%r47, %r35, 4160;
	xor.b32 	%r48, %r35, 4176;
	xor.b32 	%r49, %r35, 4192;
	xor.b32 	%r50, %r35, 4208;
	or.b32 	%r51, %r35, 8192;
	xor.b32 	%r52, %r35, 8208;
	xor.b32 	%r53, %r35, 8224;
	xor.b32 	%r54, %r35, 8240;
	xor.b32 	%r55, %r35, 8256;
	xor.b32 	%r56, %r35, 8272;
	xor.b32 	%r57, %r35, 8288;
	xor.b32 	%r58, %r35, 8304;
	or.b32 	%r59, %r35, 12288;
	xor.b32 	%r60, %r35, 12304;
	xor.b32 	%r61, %r35, 12320;
	xor.b32 	%r62, %r35, 12336;
	xor.b32 	%r63, %r35, 12352;
	xor.b32 	%r64, %r35, 12368;
	xor.b32 	%r65, %r35, 12384;
	xor.b32 	%r66, %r35, 12400;
	mul.lo.s32 	%r748, %r739, 264;
	and.b32 	%r749, %r738, 1056;
	xor.b32 	%r750, %r749, %r748;
	shl.b32 	%r751, %r5, 8;
	and.b32 	%r752, %r751, 6144;
	or.b32 	%r753, %r750, %r752;
	and.b32 	%r5076, %r30, 24;
	xor.b32 	%r68, %r5076, %r753;
	xor.b32 	%r69, %r68, 32;
	xor.b32 	%r70, %r68, 8224;
	xor.b32 	%r71, %r68, 16416;
	xor.b32 	%r72, %r68, 24608;
	xor.b32 	%r73, %r68, 64;
	xor.b32 	%r74, %r68, 8256;
	xor.b32 	%r75, %r68, 16448;
	xor.b32 	%r76, %r68, 24640;
	xor.b32 	%r77, %r68, 96;
	xor.b32 	%r78, %r68, 8288;
	xor.b32 	%r79, %r68, 16480;
	xor.b32 	%r80, %r68, 24672;
	xor.b32 	%r81, %r68, 128;
	xor.b32 	%r82, %r68, 8320;
	xor.b32 	%r83, %r68, 16512;
	xor.b32 	%r84, %r68, 24704;
	xor.b32 	%r85, %r68, 160;
	xor.b32 	%r86, %r68, 8352;
	xor.b32 	%r87, %r68, 16544;
	xor.b32 	%r88, %r68, 24736;
	xor.b32 	%r89, %r68, 192;
	xor.b32 	%r90, %r68, 8384;
	xor.b32 	%r91, %r68, 16576;
	xor.b32 	%r92, %r68, 24768;
	xor.b32 	%r93, %r68, 224;
	xor.b32 	%r94, %r68, 8416;
	xor.b32 	%r95, %r68, 16608;
	xor.b32 	%r96, %r68, 24800;
	add.s32 	%r4944, %r492, -256;
	.loc	1 120 22                        // gated_mlp.py:120:22
	shl.b64 	%rd16, %rd14, 1;
	shl.b64 	%rd108, %rd15, 2;
	add.s64 	%rd185, %rd40, %rd108;
	shl.b64 	%rd18, %rd15, 1;
	mad.lo.s32 	%r755, %r493, %r26, %r10;
	mul.wide.s32 	%rd19, %r755, 2;
	mad.lo.s32 	%r757, %r493, %r25, %r10;
	mul.wide.s32 	%rd20, %r757, 2;
	shl.b64 	%rd21, %rd13, 1;
	shl.b64 	%rd22, %rd12, 1;
	shl.b64 	%rd23, %rd11, 1;
	shl.b64 	%rd24, %rd10, 1;
	shl.b64 	%rd25, %rd9, 1;
	shl.b64 	%rd26, %rd8, 1;
	shl.b64 	%rd27, %rd7, 1;
	shl.b64 	%rd28, %rd6, 1;
	shl.b64 	%rd29, %rd5, 1;
	shl.b64 	%rd30, %rd4, 1;
	shl.b64 	%rd31, %rd3, 1;
	shl.b64 	%rd32, %rd2, 1;
	shl.b64 	%rd33, %rd1, 1;
	and.b32 	%r758, %r5, 15;
	mul.wide.u32 	%rd109, %r758, 16;
	add.s64 	%rd110, %rd109, %rd39;
	add.s64 	%rd184, %rd110, 512;
	mov.b32 	%r5075, 0;
	mov.b32 	%r4947, 0f00000000;
	mov.b32 	%r4946, 1;
	mov.b32 	%r4945, -1;
	shl.b32 	%r4717, %r36, 1;
	shl.b32 	%r4718, %r37, 1;
	shl.b32 	%r4719, %r38, 1;
	shl.b32 	%r4720, %r39, 1;
	shl.b32 	%r4721, %r40, 1;
	shl.b32 	%r4722, %r41, 1;
	shl.b32 	%r4723, %r42, 1;
	shl.b32 	%r4724, %r43, 1;
	shl.b32 	%r4725, %r44, 1;
	shl.b32 	%r4726, %r45, 1;
	shl.b32 	%r4727, %r46, 1;
	shl.b32 	%r4728, %r47, 1;
	shl.b32 	%r4729, %r48, 1;
	shl.b32 	%r4730, %r49, 1;
	shl.b32 	%r4731, %r50, 1;
	shl.b32 	%r4732, %r51, 1;
	shl.b32 	%r4733, %r52, 1;
	shl.b32 	%r4734, %r53, 1;
	shl.b32 	%r4735, %r54, 1;
	shl.b32 	%r4736, %r55, 1;
	shl.b32 	%r4737, %r56, 1;
	shl.b32 	%r4738, %r57, 1;
	shl.b32 	%r4739, %r58, 1;
	shl.b32 	%r4740, %r59, 1;
	shl.b32 	%r4741, %r60, 1;
	shl.b32 	%r4742, %r61, 1;
	shl.b32 	%r4743, %r62, 1;
	shl.b32 	%r4744, %r63, 1;
	shl.b32 	%r4745, %r64, 1;
	shl.b32 	%r4746, %r65, 1;
	shl.b32 	%r4747, %r66, 1;
	shl.b32 	%r4751, %r69, 1;
	shl.b32 	%r4752, %r70, 1;
	shl.b32 	%r4753, %r71, 1;
	shl.b32 	%r4754, %r72, 1;
	shl.b32 	%r4755, %r73, 1;
	shl.b32 	%r4756, %r74, 1;
	shl.b32 	%r4757, %r75, 1;
	shl.b32 	%r4758, %r76, 1;
	shl.b32 	%r4759, %r77, 1;
	shl.b32 	%r4760, %r78, 1;
	shl.b32 	%r4761, %r79, 1;
	shl.b32 	%r4762, %r80, 1;
	shl.b32 	%r4763, %r81, 1;
	shl.b32 	%r4764, %r82, 1;
	shl.b32 	%r4765, %r83, 1;
	shl.b32 	%r4766, %r84, 1;
	shl.b32 	%r4767, %r85, 1;
	shl.b32 	%r4768, %r86, 1;
	shl.b32 	%r4769, %r87, 1;
	shl.b32 	%r4770, %r88, 1;
	shl.b32 	%r4771, %r89, 1;
	shl.b32 	%r4772, %r90, 1;
	shl.b32 	%r4773, %r91, 1;
	shl.b32 	%r4774, %r92, 1;
	shl.b32 	%r4775, %r93, 1;
	shl.b32 	%r4776, %r94, 1;
	shl.b32 	%r4777, %r95, 1;
	shl.b32 	%r4778, %r96, 1;
	mov.b32 	%r4948, %r4947;
	mov.b32 	%r4949, %r4947;
	mov.b32 	%r4950, %r4947;
	mov.b32 	%r4951, %r4947;
	mov.b32 	%r4952, %r4947;
	mov.b32 	%r4953, %r4947;
	mov.b32 	%r4954, %r4947;
	mov.b32 	%r4955, %r4947;
	mov.b32 	%r4956, %r4947;
	mov.b32 	%r4957, %r4947;
	mov.b32 	%r4958, %r4947;
	mov.b32 	%r4959, %r4947;
	mov.b32 	%r4960, %r4947;
	mov.b32 	%r4961, %r4947;
	mov.b32 	%r4962, %r4947;
	mov.b32 	%r4963, %r4947;
	mov.b32 	%r4964, %r4947;
	mov.b32 	%r4965, %r4947;
	mov.b32 	%r4966, %r4947;
	mov.b32 	%r4967, %r4947;
	mov.b32 	%r4968, %r4947;
	mov.b32 	%r4969, %r4947;
	mov.b32 	%r4970, %r4947;
	mov.b32 	%r4971, %r4947;
	mov.b32 	%r4972, %r4947;
	mov.b32 	%r4973, %r4947;
	mov.b32 	%r4974, %r4947;
	mov.b32 	%r4975, %r4947;
	mov.b32 	%r4976, %r4947;
	mov.b32 	%r4977, %r4947;
	mov.b32 	%r4978, %r4947;
	mov.b32 	%r4979, %r4947;
	mov.b32 	%r4980, %r4947;
	mov.b32 	%r4981, %r4947;
	mov.b32 	%r4982, %r4947;
	mov.b32 	%r4983, %r4947;
	mov.b32 	%r4984, %r4947;
	mov.b32 	%r4985, %r4947;
	mov.b32 	%r4986, %r4947;
	mov.b32 	%r4987, %r4947;
	mov.b32 	%r4988, %r4947;
	mov.b32 	%r4989, %r4947;
	mov.b32 	%r4990, %r4947;
	mov.b32 	%r4991, %r4947;
	mov.b32 	%r4992, %r4947;
	mov.b32 	%r4993, %r4947;
	mov.b32 	%r4994, %r4947;
	mov.b32 	%r4995, %r4947;
	mov.b32 	%r4996, %r4947;
	mov.b32 	%r4997, %r4947;
	mov.b32 	%r4998, %r4947;
	mov.b32 	%r4999, %r4947;
	mov.b32 	%r5000, %r4947;
	mov.b32 	%r5001, %r4947;
	mov.b32 	%r5002, %r4947;
	mov.b32 	%r5003, %r4947;
	mov.b32 	%r5004, %r4947;
	mov.b32 	%r5005, %r4947;
	mov.b32 	%r5006, %r4947;
	mov.b32 	%r5007, %r4947;
	mov.b32 	%r5008, %r4947;
	mov.b32 	%r5009, %r4947;
	mov.b32 	%r5010, %r4947;
	mov.b32 	%r5011, %r4947;
	mov.b32 	%r5012, %r4947;
	mov.b32 	%r5013, %r4947;
	mov.b32 	%r5014, %r4947;
	mov.b32 	%r5015, %r4947;
	mov.b32 	%r5016, %r4947;
	mov.b32 	%r5017, %r4947;
	mov.b32 	%r5018, %r4947;
	mov.b32 	%r5019, %r4947;
	mov.b32 	%r5020, %r4947;
	mov.b32 	%r5021, %r4947;
	mov.b32 	%r5022, %r4947;
	mov.b32 	%r5023, %r4947;
	mov.b32 	%r5024, %r4947;
	mov.b32 	%r5025, %r4947;
	mov.b32 	%r5026, %r4947;
	mov.b32 	%r5027, %r4947;
	mov.b32 	%r5028, %r4947;
	mov.b32 	%r5029, %r4947;
	mov.b32 	%r5030, %r4947;
	mov.b32 	%r5031, %r4947;
	mov.b32 	%r5032, %r4947;
	mov.b32 	%r5033, %r4947;
	mov.b32 	%r5034, %r4947;
	mov.b32 	%r5035, %r4947;
	mov.b32 	%r5036, %r4947;
	mov.b32 	%r5037, %r4947;
	mov.b32 	%r5038, %r4947;
	mov.b32 	%r5039, %r4947;
	mov.b32 	%r5040, %r4947;
	mov.b32 	%r5041, %r4947;
	mov.b32 	%r5042, %r4947;
	mov.b32 	%r5043, %r4947;
	mov.b32 	%r5044, %r4947;
	mov.b32 	%r5045, %r4947;
	mov.b32 	%r5046, %r4947;
	mov.b32 	%r5047, %r4947;
	mov.b32 	%r5048, %r4947;
	mov.b32 	%r5049, %r4947;
	mov.b32 	%r5050, %r4947;
	mov.b32 	%r5051, %r4947;
	mov.b32 	%r5052, %r4947;
	mov.b32 	%r5053, %r4947;
	mov.b32 	%r5054, %r4947;
	mov.b32 	%r5055, %r4947;
	mov.b32 	%r5056, %r4947;
	mov.b32 	%r5057, %r4947;
	mov.b32 	%r5058, %r4947;
	mov.b32 	%r5059, %r4947;
	mov.b32 	%r5060, %r4947;
	mov.b32 	%r5061, %r4947;
	mov.b32 	%r5062, %r4947;
	mov.b32 	%r5063, %r4947;
	mov.b32 	%r5064, %r4947;
	mov.b32 	%r5065, %r4947;
	mov.b32 	%r5066, %r4947;
	mov.b32 	%r5067, %r4947;
	mov.b32 	%r5068, %r4947;
	mov.b32 	%r5069, %r4947;
	mov.b32 	%r5070, %r4947;
	mov.b32 	%r5071, %r4947;
	mov.b32 	%r5072, %r4947;
	mov.b32 	%r5073, %r4947;
	mov.b32 	%r5074, %r4947;
$L__BB0_3:                              // =>This Inner Loop Header: Depth=1
	setp.lt.s32 	%p37, %r5075, %r34;
	add.s32 	%r4711, %r4945, 1;
	setp.gt.s32 	%p38, %r4711, 1;
	selp.b32 	%r4945, 0, %r4711, %p38;
	.loc	1 123 20                        // gated_mlp.py:123:20
	cp.async.wait_group 	2;
	bar.sync 	0;
	shl.b32 	%r4712, %r4945, 15;
	add.s32 	%r4714, %r645, 131072;
	add.s32 	%r4715, %r4714, %r4712;
	shl.b32 	%r4716, %r35, 1;
	add.s32 	%r763, %r4715, %r4716;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1087, %r1088, %r1089, %r1090}, [%r763];
	// end inline asm
	add.s32 	%r768, %r4715, %r4717;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1535, %r1536, %r1537, %r1538}, [%r768];
	// end inline asm
	add.s32 	%r773, %r4715, %r4718;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1983, %r1984, %r1985, %r1986}, [%r773];
	// end inline asm
	add.s32 	%r778, %r4715, %r4719;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2431, %r2432, %r2433, %r2434}, [%r778];
	// end inline asm
	add.s32 	%r783, %r4715, %r4720;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2879, %r2880, %r2881, %r2882}, [%r783];
	// end inline asm
	add.s32 	%r788, %r4715, %r4721;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3327, %r3328, %r3329, %r3330}, [%r788];
	// end inline asm
	add.s32 	%r793, %r4715, %r4722;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3775, %r3776, %r3777, %r3778}, [%r793];
	// end inline asm
	add.s32 	%r798, %r4715, %r4723;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4223, %r4224, %r4225, %r4226}, [%r798];
	// end inline asm
	add.s32 	%r803, %r4715, %r4724;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1199, %r1200, %r1201, %r1202}, [%r803];
	// end inline asm
	add.s32 	%r808, %r4715, %r4725;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1647, %r1648, %r1649, %r1650}, [%r808];
	// end inline asm
	add.s32 	%r813, %r4715, %r4726;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2095, %r2096, %r2097, %r2098}, [%r813];
	// end inline asm
	add.s32 	%r818, %r4715, %r4727;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2543, %r2544, %r2545, %r2546}, [%r818];
	// end inline asm
	add.s32 	%r823, %r4715, %r4728;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2991, %r2992, %r2993, %r2994}, [%r823];
	// end inline asm
	add.s32 	%r828, %r4715, %r4729;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3439, %r3440, %r3441, %r3442}, [%r828];
	// end inline asm
	add.s32 	%r833, %r4715, %r4730;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3887, %r3888, %r3889, %r3890}, [%r833];
	// end inline asm
	add.s32 	%r838, %r4715, %r4731;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4335, %r4336, %r4337, %r4338}, [%r838];
	// end inline asm
	add.s32 	%r843, %r4715, %r4732;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1311, %r1312, %r1313, %r1314}, [%r843];
	// end inline asm
	add.s32 	%r848, %r4715, %r4733;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1759, %r1760, %r1761, %r1762}, [%r848];
	// end inline asm
	add.s32 	%r853, %r4715, %r4734;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2207, %r2208, %r2209, %r2210}, [%r853];
	// end inline asm
	add.s32 	%r858, %r4715, %r4735;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2655, %r2656, %r2657, %r2658}, [%r858];
	// end inline asm
	add.s32 	%r863, %r4715, %r4736;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3103, %r3104, %r3105, %r3106}, [%r863];
	// end inline asm
	add.s32 	%r868, %r4715, %r4737;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3551, %r3552, %r3553, %r3554}, [%r868];
	// end inline asm
	add.s32 	%r873, %r4715, %r4738;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3999, %r4000, %r4001, %r4002}, [%r873];
	// end inline asm
	add.s32 	%r878, %r4715, %r4739;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4447, %r4448, %r4449, %r4450}, [%r878];
	// end inline asm
	add.s32 	%r883, %r4715, %r4740;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1423, %r1424, %r1425, %r1426}, [%r883];
	// end inline asm
	add.s32 	%r888, %r4715, %r4741;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1871, %r1872, %r1873, %r1874}, [%r888];
	// end inline asm
	add.s32 	%r893, %r4715, %r4742;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2319, %r2320, %r2321, %r2322}, [%r893];
	// end inline asm
	add.s32 	%r898, %r4715, %r4743;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2767, %r2768, %r2769, %r2770}, [%r898];
	// end inline asm
	add.s32 	%r903, %r4715, %r4744;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3215, %r3216, %r3217, %r3218}, [%r903];
	// end inline asm
	add.s32 	%r908, %r4715, %r4745;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3663, %r3664, %r3665, %r3666}, [%r908];
	// end inline asm
	add.s32 	%r913, %r4715, %r4746;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4111, %r4112, %r4113, %r4114}, [%r913];
	// end inline asm
	add.s32 	%r918, %r4715, %r4747;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4559, %r4560, %r4561, %r4562}, [%r918];
	// end inline asm
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r4748, %r4945, 16;
	add.s32 	%r4749, %r645, %r4748;
	shl.b32 	%r4750, %r68, 1;
	add.s32 	%r923, %r4749, %r4750;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1091, %r1092, %r1539, %r1540}, [%r923];
	// end inline asm
	add.s32 	%r928, %r923, 16384;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1987, %r1988, %r2435, %r2436}, [%r928];
	// end inline asm
	add.s32 	%r933, %r923, 32768;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2883, %r2884, %r3331, %r3332}, [%r933];
	// end inline asm
	add.s32 	%r938, %r923, 49152;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3779, %r3780, %r4227, %r4228}, [%r938];
	// end inline asm
	add.s32 	%r943, %r4749, %r4751;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1105, %r1106, %r1553, %r1554}, [%r943];
	// end inline asm
	add.s32 	%r948, %r4749, %r4752;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2001, %r2002, %r2449, %r2450}, [%r948];
	// end inline asm
	add.s32 	%r953, %r4749, %r4753;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2897, %r2898, %r3345, %r3346}, [%r953];
	// end inline asm
	add.s32 	%r958, %r4749, %r4754;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3793, %r3794, %r4241, %r4242}, [%r958];
	// end inline asm
	add.s32 	%r963, %r4749, %r4755;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1119, %r1120, %r1567, %r1568}, [%r963];
	// end inline asm
	add.s32 	%r968, %r4749, %r4756;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2015, %r2016, %r2463, %r2464}, [%r968];
	// end inline asm
	add.s32 	%r973, %r4749, %r4757;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2911, %r2912, %r3359, %r3360}, [%r973];
	// end inline asm
	add.s32 	%r978, %r4749, %r4758;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3807, %r3808, %r4255, %r4256}, [%r978];
	// end inline asm
	add.s32 	%r983, %r4749, %r4759;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1133, %r1134, %r1581, %r1582}, [%r983];
	// end inline asm
	add.s32 	%r988, %r4749, %r4760;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2029, %r2030, %r2477, %r2478}, [%r988];
	// end inline asm
	add.s32 	%r993, %r4749, %r4761;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2925, %r2926, %r3373, %r3374}, [%r993];
	// end inline asm
	add.s32 	%r998, %r4749, %r4762;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3821, %r3822, %r4269, %r4270}, [%r998];
	// end inline asm
	add.s32 	%r1003, %r4749, %r4763;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1147, %r1148, %r1595, %r1596}, [%r1003];
	// end inline asm
	add.s32 	%r1008, %r4749, %r4764;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2043, %r2044, %r2491, %r2492}, [%r1008];
	// end inline asm
	add.s32 	%r1013, %r4749, %r4765;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2939, %r2940, %r3387, %r3388}, [%r1013];
	// end inline asm
	add.s32 	%r1018, %r4749, %r4766;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3835, %r3836, %r4283, %r4284}, [%r1018];
	// end inline asm
	add.s32 	%r1023, %r4749, %r4767;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1161, %r1162, %r1609, %r1610}, [%r1023];
	// end inline asm
	add.s32 	%r1028, %r4749, %r4768;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2057, %r2058, %r2505, %r2506}, [%r1028];
	// end inline asm
	add.s32 	%r1033, %r4749, %r4769;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2953, %r2954, %r3401, %r3402}, [%r1033];
	// end inline asm
	add.s32 	%r1038, %r4749, %r4770;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3849, %r3850, %r4297, %r4298}, [%r1038];
	// end inline asm
	add.s32 	%r1043, %r4749, %r4771;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1175, %r1176, %r1623, %r1624}, [%r1043];
	// end inline asm
	add.s32 	%r1048, %r4749, %r4772;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2071, %r2072, %r2519, %r2520}, [%r1048];
	// end inline asm
	add.s32 	%r1053, %r4749, %r4773;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2967, %r2968, %r3415, %r3416}, [%r1053];
	// end inline asm
	add.s32 	%r1058, %r4749, %r4774;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3863, %r3864, %r4311, %r4312}, [%r1058];
	// end inline asm
	add.s32 	%r1063, %r4749, %r4775;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1189, %r1190, %r1637, %r1638}, [%r1063];
	// end inline asm
	add.s32 	%r1068, %r4749, %r4776;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2085, %r2086, %r2533, %r2534}, [%r1068];
	// end inline asm
	add.s32 	%r1073, %r4749, %r4777;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r2981, %r2982, %r3429, %r3430}, [%r1073];
	// end inline asm
	add.s32 	%r1078, %r4749, %r4778;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r3877, %r3878, %r4325, %r4326}, [%r1078];
	// end inline asm
	.loc	1 126 35                        // gated_mlp.py:126:35
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1091, %r1092 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1105, %r1106 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1119, %r1120 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1133, %r1134 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1147, %r1148 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1161, %r1162 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1175, %r1176 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r1087, %r1088, %r1089, %r1090 }, { %r1189, %r1190 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1091, %r1092 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1105, %r1106 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1119, %r1120 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1133, %r1134 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1147, %r1148 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1161, %r1162 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1175, %r1176 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r1199, %r1200, %r1201, %r1202 }, { %r1189, %r1190 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1091, %r1092 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1105, %r1106 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1119, %r1120 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1133, %r1134 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1147, %r1148 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1161, %r1162 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1175, %r1176 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r1311, %r1312, %r1313, %r1314 }, { %r1189, %r1190 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1091, %r1092 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1105, %r1106 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1119, %r1120 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1133, %r1134 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1147, %r1148 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1161, %r1162 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1175, %r1176 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r1423, %r1424, %r1425, %r1426 }, { %r1189, %r1190 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1539, %r1540 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1553, %r1554 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1567, %r1568 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1581, %r1582 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1595, %r1596 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1609, %r1610 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1623, %r1624 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r1535, %r1536, %r1537, %r1538 }, { %r1637, %r1638 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1539, %r1540 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1553, %r1554 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1567, %r1568 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1581, %r1582 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1595, %r1596 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1609, %r1610 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1623, %r1624 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r1647, %r1648, %r1649, %r1650 }, { %r1637, %r1638 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1539, %r1540 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1553, %r1554 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1567, %r1568 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1581, %r1582 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1595, %r1596 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1609, %r1610 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1623, %r1624 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r1759, %r1760, %r1761, %r1762 }, { %r1637, %r1638 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1539, %r1540 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1553, %r1554 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1567, %r1568 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1581, %r1582 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1595, %r1596 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1609, %r1610 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1623, %r1624 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r1871, %r1872, %r1873, %r1874 }, { %r1637, %r1638 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r1983, %r1984, %r1985, %r1986 }, { %r1987, %r1988 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2001, %r2002 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2015, %r2016 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2029, %r2030 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2043, %r2044 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2057, %r2058 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2071, %r2072 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r1983, %r1984, %r1985, %r1986 }, { %r2085, %r2086 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r2095, %r2096, %r2097, %r2098 }, { %r1987, %r1988 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2001, %r2002 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2015, %r2016 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2029, %r2030 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2043, %r2044 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2057, %r2058 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2071, %r2072 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r2095, %r2096, %r2097, %r2098 }, { %r2085, %r2086 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r2207, %r2208, %r2209, %r2210 }, { %r1987, %r1988 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2001, %r2002 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2015, %r2016 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2029, %r2030 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2043, %r2044 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2057, %r2058 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2071, %r2072 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r2207, %r2208, %r2209, %r2210 }, { %r2085, %r2086 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r2319, %r2320, %r2321, %r2322 }, { %r1987, %r1988 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2001, %r2002 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2015, %r2016 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2029, %r2030 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2043, %r2044 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2057, %r2058 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2071, %r2072 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r2319, %r2320, %r2321, %r2322 }, { %r2085, %r2086 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2435, %r2436 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2449, %r2450 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2463, %r2464 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2477, %r2478 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2491, %r2492 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2505, %r2506 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2519, %r2520 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r2431, %r2432, %r2433, %r2434 }, { %r2533, %r2534 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2435, %r2436 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2449, %r2450 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2463, %r2464 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2477, %r2478 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2491, %r2492 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2505, %r2506 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2519, %r2520 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r2543, %r2544, %r2545, %r2546 }, { %r2533, %r2534 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2435, %r2436 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2449, %r2450 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2463, %r2464 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2477, %r2478 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2491, %r2492 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2505, %r2506 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2519, %r2520 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r2655, %r2656, %r2657, %r2658 }, { %r2533, %r2534 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2435, %r2436 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2449, %r2450 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2463, %r2464 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2477, %r2478 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2491, %r2492 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2505, %r2506 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2519, %r2520 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r2767, %r2768, %r2769, %r2770 }, { %r2533, %r2534 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2883, %r2884 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2897, %r2898 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2911, %r2912 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2925, %r2926 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2939, %r2940 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2953, %r2954 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2967, %r2968 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r2879, %r2880, %r2881, %r2882 }, { %r2981, %r2982 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2883, %r2884 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2897, %r2898 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2911, %r2912 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2925, %r2926 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2939, %r2940 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2953, %r2954 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2967, %r2968 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r2991, %r2992, %r2993, %r2994 }, { %r2981, %r2982 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2883, %r2884 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2897, %r2898 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2911, %r2912 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2925, %r2926 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2939, %r2940 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2953, %r2954 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2967, %r2968 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r3103, %r3104, %r3105, %r3106 }, { %r2981, %r2982 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2883, %r2884 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2897, %r2898 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2911, %r2912 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2925, %r2926 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2939, %r2940 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2953, %r2954 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2967, %r2968 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r3215, %r3216, %r3217, %r3218 }, { %r2981, %r2982 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3331, %r3332 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3345, %r3346 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3359, %r3360 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3373, %r3374 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3387, %r3388 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3401, %r3402 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3415, %r3416 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r3327, %r3328, %r3329, %r3330 }, { %r3429, %r3430 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3331, %r3332 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3345, %r3346 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3359, %r3360 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3373, %r3374 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3387, %r3388 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3401, %r3402 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3415, %r3416 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r3439, %r3440, %r3441, %r3442 }, { %r3429, %r3430 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3331, %r3332 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3345, %r3346 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3359, %r3360 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3373, %r3374 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3387, %r3388 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3401, %r3402 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3415, %r3416 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r3551, %r3552, %r3553, %r3554 }, { %r3429, %r3430 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3331, %r3332 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3345, %r3346 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3359, %r3360 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3373, %r3374 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3387, %r3388 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3401, %r3402 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3415, %r3416 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r3663, %r3664, %r3665, %r3666 }, { %r3429, %r3430 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3779, %r3780 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3793, %r3794 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3807, %r3808 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3821, %r3822 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3835, %r3836 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3849, %r3850 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3863, %r3864 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r3775, %r3776, %r3777, %r3778 }, { %r3877, %r3878 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3779, %r3780 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3793, %r3794 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3807, %r3808 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3821, %r3822 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3835, %r3836 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3849, %r3850 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3863, %r3864 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r3887, %r3888, %r3889, %r3890 }, { %r3877, %r3878 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3779, %r3780 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3793, %r3794 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3807, %r3808 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3821, %r3822 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3835, %r3836 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3849, %r3850 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3863, %r3864 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r3999, %r4000, %r4001, %r4002 }, { %r3877, %r3878 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3779, %r3780 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3793, %r3794 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3807, %r3808 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3821, %r3822 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3835, %r3836 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3849, %r3850 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3863, %r3864 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r4111, %r4112, %r4113, %r4114 }, { %r3877, %r3878 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4947, %r4948, %r4949, %r4950 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4227, %r4228 }, { %r4947, %r4948, %r4949, %r4950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4951, %r4952, %r4953, %r4954 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4241, %r4242 }, { %r4951, %r4952, %r4953, %r4954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4955, %r4956, %r4957, %r4958 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4255, %r4256 }, { %r4955, %r4956, %r4957, %r4958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4959, %r4960, %r4961, %r4962 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4269, %r4270 }, { %r4959, %r4960, %r4961, %r4962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4963, %r4964, %r4965, %r4966 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4283, %r4284 }, { %r4963, %r4964, %r4965, %r4966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4967, %r4968, %r4969, %r4970 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4297, %r4298 }, { %r4967, %r4968, %r4969, %r4970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4971, %r4972, %r4973, %r4974 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4311, %r4312 }, { %r4971, %r4972, %r4973, %r4974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4975, %r4976, %r4977, %r4978 }, { %r4223, %r4224, %r4225, %r4226 }, { %r4325, %r4326 }, { %r4975, %r4976, %r4977, %r4978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4979, %r4980, %r4981, %r4982 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4227, %r4228 }, { %r4979, %r4980, %r4981, %r4982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4983, %r4984, %r4985, %r4986 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4241, %r4242 }, { %r4983, %r4984, %r4985, %r4986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4987, %r4988, %r4989, %r4990 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4255, %r4256 }, { %r4987, %r4988, %r4989, %r4990 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4991, %r4992, %r4993, %r4994 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4269, %r4270 }, { %r4991, %r4992, %r4993, %r4994 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4995, %r4996, %r4997, %r4998 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4283, %r4284 }, { %r4995, %r4996, %r4997, %r4998 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r4999, %r5000, %r5001, %r5002 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4297, %r4298 }, { %r4999, %r5000, %r5001, %r5002 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5003, %r5004, %r5005, %r5006 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4311, %r4312 }, { %r5003, %r5004, %r5005, %r5006 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5007, %r5008, %r5009, %r5010 }, { %r4335, %r4336, %r4337, %r4338 }, { %r4325, %r4326 }, { %r5007, %r5008, %r5009, %r5010 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5011, %r5012, %r5013, %r5014 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4227, %r4228 }, { %r5011, %r5012, %r5013, %r5014 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5015, %r5016, %r5017, %r5018 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4241, %r4242 }, { %r5015, %r5016, %r5017, %r5018 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5019, %r5020, %r5021, %r5022 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4255, %r4256 }, { %r5019, %r5020, %r5021, %r5022 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5023, %r5024, %r5025, %r5026 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4269, %r4270 }, { %r5023, %r5024, %r5025, %r5026 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5027, %r5028, %r5029, %r5030 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4283, %r4284 }, { %r5027, %r5028, %r5029, %r5030 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5031, %r5032, %r5033, %r5034 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4297, %r4298 }, { %r5031, %r5032, %r5033, %r5034 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5035, %r5036, %r5037, %r5038 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4311, %r4312 }, { %r5035, %r5036, %r5037, %r5038 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5039, %r5040, %r5041, %r5042 }, { %r4447, %r4448, %r4449, %r4450 }, { %r4325, %r4326 }, { %r5039, %r5040, %r5041, %r5042 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5043, %r5044, %r5045, %r5046 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4227, %r4228 }, { %r5043, %r5044, %r5045, %r5046 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5047, %r5048, %r5049, %r5050 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4241, %r4242 }, { %r5047, %r5048, %r5049, %r5050 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5051, %r5052, %r5053, %r5054 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4255, %r4256 }, { %r5051, %r5052, %r5053, %r5054 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5055, %r5056, %r5057, %r5058 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4269, %r4270 }, { %r5055, %r5056, %r5057, %r5058 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5059, %r5060, %r5061, %r5062 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4283, %r4284 }, { %r5059, %r5060, %r5061, %r5062 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5063, %r5064, %r5065, %r5066 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4297, %r4298 }, { %r5063, %r5064, %r5065, %r5066 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5067, %r5068, %r5069, %r5070 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4311, %r4312 }, { %r5067, %r5068, %r5069, %r5070 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r5071, %r5072, %r5073, %r5074 }, { %r4559, %r4560, %r4561, %r4562 }, { %r4325, %r4326 }, { %r5071, %r5072, %r5073, %r5074 };
	// end inline asm
	.loc	1 129 18                        // gated_mlp.py:129:18
	add.s64 	%rd119, %rd185, %rd33;
	add.s64 	%rd120, %rd185, %rd32;
	add.s64 	%rd121, %rd185, %rd31;
	add.s64 	%rd122, %rd185, %rd30;
	add.s64 	%rd123, %rd185, %rd29;
	add.s64 	%rd124, %rd185, %rd28;
	add.s64 	%rd125, %rd185, %rd27;
	add.s64 	%rd126, %rd185, %rd26;
	add.s64 	%rd127, %rd185, %rd25;
	add.s64 	%rd128, %rd185, %rd24;
	add.s64 	%rd129, %rd185, %rd23;
	add.s64 	%rd130, %rd185, %rd22;
	add.s64 	%rd131, %rd185, %rd21;
	add.s64 	%rd132, %rd185, %rd20;
	add.s64 	%rd133, %rd185, %rd19;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s64 	%rd134, %rd185, %rd16;
	add.s32 	%r4779, %r4946, 1;
	setp.gt.s32 	%p39, %r4779, 1;
	selp.b32 	%r4946, 0, %r4779, %p39;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p40, %r7, %r4944;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shl.b32 	%r4780, %r4946, 15;
	add.s32 	%r4781, %r4714, %r4780;
	bar.sync 	0;
	add.s32 	%r4663, %r4781, %r644;
	add.s32 	%r4665, %r4663, 4096;
	add.s32 	%r4667, %r4663, 8192;
	add.s32 	%r4669, %r4663, 12288;
	add.s32 	%r4671, %r4663, 16384;
	add.s32 	%r4673, %r4663, 20480;
	add.s32 	%r4675, %r4663, 24576;
	add.s32 	%r4677, %r4663, 28672;
	selp.b32 	%r4783, 16, 0, %p40;
	selp.b32 	%r4666, %r4783, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4663 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4665 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4667 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4669 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4671 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4673 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4675 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4677 + 0 ], [ %rd184 + 0 ], 0x10, %r4666;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p41, %r12, %r4944;
	setp.lt.s32 	%p42, %r13, %r4944;
	setp.lt.s32 	%p43, %r14, %r4944;
	setp.lt.s32 	%p44, %r15, %r4944;
	setp.lt.s32 	%p45, %r16, %r4944;
	setp.lt.s32 	%p46, %r17, %r4944;
	setp.lt.s32 	%p47, %r18, %r4944;
	setp.lt.s32 	%p48, %r19, %r4944;
	setp.lt.s32 	%p49, %r20, %r4944;
	setp.lt.s32 	%p50, %r21, %r4944;
	setp.lt.s32 	%p51, %r22, %r4944;
	setp.lt.s32 	%p52, %r23, %r4944;
	setp.lt.s32 	%p53, %r24, %r4944;
	setp.lt.s32 	%p54, %r25, %r4944;
	setp.lt.s32 	%p55, %r26, %r4944;
	setp.lt.s32 	%p56, %r27, %r4944;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r4784, %r4946, 16;
	add.s32 	%r4785, %r645, %r4784;
	add.s32 	%r4679, %r4785, %r650;
	add.s32 	%r4681, %r4679, 4096;
	add.s32 	%r4683, %r4679, 8192;
	add.s32 	%r4685, %r4679, 12288;
	add.s32 	%r4687, %r4679, 16384;
	add.s32 	%r4689, %r4679, 20480;
	add.s32 	%r4691, %r4679, 24576;
	add.s32 	%r4693, %r4679, 28672;
	add.s32 	%r4695, %r4679, 32768;
	add.s32 	%r4697, %r4679, 36864;
	add.s32 	%r4699, %r4679, 40960;
	add.s32 	%r4701, %r4679, 45056;
	add.s32 	%r4703, %r4679, 49152;
	add.s32 	%r4705, %r4679, 53248;
	add.s32 	%r4707, %r4679, 57344;
	add.s32 	%r4709, %r4679, 61440;
	selp.b32 	%r4787, 16, 0, %p41;
	selp.b32 	%r4680, %r4787, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4679 + 0 ], [ %rd119 + 0 ], 0x10, %r4680;
	// end inline asm
	selp.b32 	%r4788, 16, 0, %p42;
	selp.b32 	%r4682, %r4788, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4681 + 0 ], [ %rd120 + 0 ], 0x10, %r4682;
	// end inline asm
	selp.b32 	%r4789, 16, 0, %p43;
	selp.b32 	%r4684, %r4789, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4683 + 0 ], [ %rd121 + 0 ], 0x10, %r4684;
	// end inline asm
	selp.b32 	%r4790, 16, 0, %p44;
	selp.b32 	%r4686, %r4790, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4685 + 0 ], [ %rd122 + 0 ], 0x10, %r4686;
	// end inline asm
	selp.b32 	%r4791, 16, 0, %p45;
	selp.b32 	%r4688, %r4791, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4687 + 0 ], [ %rd123 + 0 ], 0x10, %r4688;
	// end inline asm
	selp.b32 	%r4792, 16, 0, %p46;
	selp.b32 	%r4690, %r4792, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4689 + 0 ], [ %rd124 + 0 ], 0x10, %r4690;
	// end inline asm
	selp.b32 	%r4793, 16, 0, %p47;
	selp.b32 	%r4692, %r4793, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4691 + 0 ], [ %rd125 + 0 ], 0x10, %r4692;
	// end inline asm
	selp.b32 	%r4794, 16, 0, %p48;
	selp.b32 	%r4694, %r4794, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4693 + 0 ], [ %rd126 + 0 ], 0x10, %r4694;
	// end inline asm
	selp.b32 	%r4795, 16, 0, %p49;
	selp.b32 	%r4696, %r4795, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4695 + 0 ], [ %rd127 + 0 ], 0x10, %r4696;
	// end inline asm
	selp.b32 	%r4796, 16, 0, %p50;
	selp.b32 	%r4698, %r4796, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4697 + 0 ], [ %rd128 + 0 ], 0x10, %r4698;
	// end inline asm
	selp.b32 	%r4797, 16, 0, %p51;
	selp.b32 	%r4700, %r4797, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4699 + 0 ], [ %rd129 + 0 ], 0x10, %r4700;
	// end inline asm
	selp.b32 	%r4798, 16, 0, %p52;
	selp.b32 	%r4702, %r4798, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4701 + 0 ], [ %rd130 + 0 ], 0x10, %r4702;
	// end inline asm
	selp.b32 	%r4799, 16, 0, %p53;
	selp.b32 	%r4704, %r4799, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4703 + 0 ], [ %rd131 + 0 ], 0x10, %r4704;
	// end inline asm
	selp.b32 	%r4800, 16, 0, %p54;
	selp.b32 	%r4706, %r4800, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4705 + 0 ], [ %rd132 + 0 ], 0x10, %r4706;
	// end inline asm
	selp.b32 	%r4801, 16, 0, %p55;
	selp.b32 	%r4708, %r4801, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4707 + 0 ], [ %rd133 + 0 ], 0x10, %r4708;
	// end inline asm
	selp.b32 	%r4802, 16, 0, %p56;
	selp.b32 	%r4710, %r4802, 0, %p37;
	// begin inline asm
	cp.async.cg.shared.global [ %r4709 + 0 ], [ %rd134 + 0 ], 0x10, %r4710;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s32 	%r5075, %r5075, 1;
	add.s64 	%rd185, %rd185, %rd18;
	add.s64 	%rd184, %rd184, 256;
	add.s32 	%r4944, %r4944, -128;
	setp.ne.s32 	%p57, %r28, %r5075;
	@%p57 bra 	$L__BB0_3;
// %bb.4:                               // %._crit_edge.loopexit
	.loc	1 134 23                        // gated_mlp.py:134:23
	cvt.rn.f16x2.f32 	%r5140, %r5074, %r5073;
	cvt.rn.f16x2.f32 	%r5139, %r5072, %r5071;
	cvt.rn.f16x2.f32 	%r5138, %r5070, %r5069;
	cvt.rn.f16x2.f32 	%r5137, %r5068, %r5067;
	cvt.rn.f16x2.f32 	%r5136, %r5066, %r5065;
	cvt.rn.f16x2.f32 	%r5135, %r5064, %r5063;
	cvt.rn.f16x2.f32 	%r5134, %r5062, %r5061;
	cvt.rn.f16x2.f32 	%r5133, %r5060, %r5059;
	cvt.rn.f16x2.f32 	%r5132, %r5058, %r5057;
	cvt.rn.f16x2.f32 	%r5131, %r5056, %r5055;
	cvt.rn.f16x2.f32 	%r5130, %r5054, %r5053;
	cvt.rn.f16x2.f32 	%r5129, %r5052, %r5051;
	cvt.rn.f16x2.f32 	%r5128, %r5050, %r5049;
	cvt.rn.f16x2.f32 	%r5127, %r5048, %r5047;
	cvt.rn.f16x2.f32 	%r5126, %r5046, %r5045;
	cvt.rn.f16x2.f32 	%r5125, %r5044, %r5043;
	cvt.rn.f16x2.f32 	%r5124, %r5042, %r5041;
	cvt.rn.f16x2.f32 	%r5123, %r5040, %r5039;
	cvt.rn.f16x2.f32 	%r5122, %r5038, %r5037;
	cvt.rn.f16x2.f32 	%r5121, %r5036, %r5035;
	cvt.rn.f16x2.f32 	%r5120, %r5034, %r5033;
	cvt.rn.f16x2.f32 	%r5119, %r5032, %r5031;
	cvt.rn.f16x2.f32 	%r5118, %r5030, %r5029;
	cvt.rn.f16x2.f32 	%r5117, %r5028, %r5027;
	cvt.rn.f16x2.f32 	%r5116, %r5026, %r5025;
	cvt.rn.f16x2.f32 	%r5115, %r5024, %r5023;
	cvt.rn.f16x2.f32 	%r5114, %r5022, %r5021;
	cvt.rn.f16x2.f32 	%r5113, %r5020, %r5019;
	cvt.rn.f16x2.f32 	%r5112, %r5018, %r5017;
	cvt.rn.f16x2.f32 	%r5111, %r5016, %r5015;
	cvt.rn.f16x2.f32 	%r5110, %r5014, %r5013;
	cvt.rn.f16x2.f32 	%r5109, %r5012, %r5011;
	cvt.rn.f16x2.f32 	%r5108, %r5010, %r5009;
	cvt.rn.f16x2.f32 	%r5107, %r5008, %r5007;
	cvt.rn.f16x2.f32 	%r5106, %r5006, %r5005;
	cvt.rn.f16x2.f32 	%r5105, %r5004, %r5003;
	cvt.rn.f16x2.f32 	%r5104, %r5002, %r5001;
	cvt.rn.f16x2.f32 	%r5103, %r5000, %r4999;
	cvt.rn.f16x2.f32 	%r5102, %r4998, %r4997;
	cvt.rn.f16x2.f32 	%r5101, %r4996, %r4995;
	cvt.rn.f16x2.f32 	%r5100, %r4994, %r4993;
	cvt.rn.f16x2.f32 	%r5099, %r4992, %r4991;
	cvt.rn.f16x2.f32 	%r5098, %r4990, %r4989;
	cvt.rn.f16x2.f32 	%r5097, %r4988, %r4987;
	cvt.rn.f16x2.f32 	%r5096, %r4986, %r4985;
	cvt.rn.f16x2.f32 	%r5095, %r4984, %r4983;
	cvt.rn.f16x2.f32 	%r5094, %r4982, %r4981;
	cvt.rn.f16x2.f32 	%r5093, %r4980, %r4979;
	cvt.rn.f16x2.f32 	%r5092, %r4978, %r4977;
	cvt.rn.f16x2.f32 	%r5091, %r4976, %r4975;
	cvt.rn.f16x2.f32 	%r5090, %r4974, %r4973;
	cvt.rn.f16x2.f32 	%r5089, %r4972, %r4971;
	cvt.rn.f16x2.f32 	%r5088, %r4970, %r4969;
	cvt.rn.f16x2.f32 	%r5087, %r4968, %r4967;
	cvt.rn.f16x2.f32 	%r5086, %r4966, %r4965;
	cvt.rn.f16x2.f32 	%r5085, %r4964, %r4963;
	cvt.rn.f16x2.f32 	%r5084, %r4962, %r4961;
	cvt.rn.f16x2.f32 	%r5083, %r4960, %r4959;
	cvt.rn.f16x2.f32 	%r5082, %r4958, %r4957;
	cvt.rn.f16x2.f32 	%r5081, %r4956, %r4955;
	cvt.rn.f16x2.f32 	%r5080, %r4954, %r4953;
	cvt.rn.f16x2.f32 	%r5079, %r4952, %r4951;
	cvt.rn.f16x2.f32 	%r5078, %r4950, %r4949;
	cvt.rn.f16x2.f32 	%r5077, %r4948, %r4947;
	bra.uni 	$L__BB0_5;
$L__BB0_1:                              // %.._crit_edge_crit_edge
	.loc	1 142 21                        // gated_mlp.py:142:21
	and.b32 	%r5076, %r30, 24;
	mov.b32 	%r5077, 0;
	mov.b32 	%r5078, %r5077;
	mov.b32 	%r5079, %r5077;
	mov.b32 	%r5080, %r5077;
	mov.b32 	%r5081, %r5077;
	mov.b32 	%r5082, %r5077;
	mov.b32 	%r5083, %r5077;
	mov.b32 	%r5084, %r5077;
	mov.b32 	%r5085, %r5077;
	mov.b32 	%r5086, %r5077;
	mov.b32 	%r5087, %r5077;
	mov.b32 	%r5088, %r5077;
	mov.b32 	%r5089, %r5077;
	mov.b32 	%r5090, %r5077;
	mov.b32 	%r5091, %r5077;
	mov.b32 	%r5092, %r5077;
	mov.b32 	%r5093, %r5077;
	mov.b32 	%r5094, %r5077;
	mov.b32 	%r5095, %r5077;
	mov.b32 	%r5096, %r5077;
	mov.b32 	%r5097, %r5077;
	mov.b32 	%r5098, %r5077;
	mov.b32 	%r5099, %r5077;
	mov.b32 	%r5100, %r5077;
	mov.b32 	%r5101, %r5077;
	mov.b32 	%r5102, %r5077;
	mov.b32 	%r5103, %r5077;
	mov.b32 	%r5104, %r5077;
	mov.b32 	%r5105, %r5077;
	mov.b32 	%r5106, %r5077;
	mov.b32 	%r5107, %r5077;
	mov.b32 	%r5108, %r5077;
	mov.b32 	%r5109, %r5077;
	mov.b32 	%r5110, %r5077;
	mov.b32 	%r5111, %r5077;
	mov.b32 	%r5112, %r5077;
	mov.b32 	%r5113, %r5077;
	mov.b32 	%r5114, %r5077;
	mov.b32 	%r5115, %r5077;
	mov.b32 	%r5116, %r5077;
	mov.b32 	%r5117, %r5077;
	mov.b32 	%r5118, %r5077;
	mov.b32 	%r5119, %r5077;
	mov.b32 	%r5120, %r5077;
	mov.b32 	%r5121, %r5077;
	mov.b32 	%r5122, %r5077;
	mov.b32 	%r5123, %r5077;
	mov.b32 	%r5124, %r5077;
	mov.b32 	%r5125, %r5077;
	mov.b32 	%r5126, %r5077;
	mov.b32 	%r5127, %r5077;
	mov.b32 	%r5128, %r5077;
	mov.b32 	%r5129, %r5077;
	mov.b32 	%r5130, %r5077;
	mov.b32 	%r5131, %r5077;
	mov.b32 	%r5132, %r5077;
	mov.b32 	%r5133, %r5077;
	mov.b32 	%r5134, %r5077;
	mov.b32 	%r5135, %r5077;
	mov.b32 	%r5136, %r5077;
	mov.b32 	%r5137, %r5077;
	mov.b32 	%r5138, %r5077;
	mov.b32 	%r5139, %r5077;
	mov.b32 	%r5140, %r5077;
$L__BB0_5:                              // %._crit_edge
	.loc	1 98 54                         // gated_mlp.py:98:54
	mul.lo.s32 	%r4867, %r4, %r2;
	sub.s32 	%r4868, %r3, %r4867;
	.loc	1 98 27                         // gated_mlp.py:98:27
	add.s32 	%r4869, %r4868, %r1;
	.loc	1 120 22                        // gated_mlp.py:120:22
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 138 22                        // gated_mlp.py:138:22
	shl.b32 	%r4870, %r4869, 7;
	.loc	1 138 37                        // gated_mlp.py:138:37
	or.b32 	%r4871, %r4870, %r12;
	or.b32 	%r4872, %r4870, %r13;
	or.b32 	%r4873, %r4870, %r14;
	or.b32 	%r4874, %r4870, %r15;
	or.b32 	%r4875, %r4870, %r16;
	or.b32 	%r4876, %r4870, %r17;
	or.b32 	%r4877, %r4870, %r18;
	or.b32 	%r4878, %r4870, %r19;
	or.b32 	%r4879, %r4870, %r20;
	or.b32 	%r4880, %r4870, %r21;
	or.b32 	%r4881, %r4870, %r22;
	or.b32 	%r4882, %r4870, %r23;
	or.b32 	%r4883, %r4870, %r24;
	or.b32 	%r4884, %r4870, %r25;
	or.b32 	%r4885, %r4870, %r26;
	or.b32 	%r4886, %r4870, %r27;
	.loc	1 140 33                        // gated_mlp.py:140:33
	mul.lo.s32 	%r4887, %r4871, %r494;
	mul.lo.s32 	%r4888, %r4872, %r494;
	mul.lo.s32 	%r4889, %r4873, %r494;
	mul.lo.s32 	%r4890, %r4874, %r494;
	mul.lo.s32 	%r4891, %r4875, %r494;
	mul.lo.s32 	%r4892, %r4876, %r494;
	mul.lo.s32 	%r4893, %r4877, %r494;
	mul.lo.s32 	%r4894, %r4878, %r494;
	mul.lo.s32 	%r4895, %r4879, %r494;
	mul.lo.s32 	%r4896, %r4880, %r494;
	mul.lo.s32 	%r4897, %r4881, %r494;
	mul.lo.s32 	%r4898, %r4882, %r494;
	mul.lo.s32 	%r4899, %r4883, %r494;
	mul.lo.s32 	%r4900, %r4884, %r494;
	mul.lo.s32 	%r4901, %r4885, %r494;
	mul.lo.s32 	%r4902, %r4886, %r494;
	.loc	1 140 21                        // gated_mlp.py:140:21
	mul.wide.s32 	%rd151, %r4887, 2;
	add.s64 	%rd152, %rd41, %rd151;
	mul.wide.s32 	%rd153, %r4888, 2;
	add.s64 	%rd154, %rd41, %rd153;
	mul.wide.s32 	%rd155, %r4889, 2;
	add.s64 	%rd156, %rd41, %rd155;
	mul.wide.s32 	%rd157, %r4890, 2;
	add.s64 	%rd158, %rd41, %rd157;
	mul.wide.s32 	%rd159, %r4891, 2;
	add.s64 	%rd160, %rd41, %rd159;
	mul.wide.s32 	%rd161, %r4892, 2;
	add.s64 	%rd162, %rd41, %rd161;
	mul.wide.s32 	%rd163, %r4893, 2;
	add.s64 	%rd164, %rd41, %rd163;
	mul.wide.s32 	%rd165, %r4894, 2;
	add.s64 	%rd166, %rd41, %rd165;
	mul.wide.s32 	%rd167, %r4895, 2;
	add.s64 	%rd168, %rd41, %rd167;
	mul.wide.s32 	%rd169, %r4896, 2;
	add.s64 	%rd170, %rd41, %rd169;
	mul.wide.s32 	%rd171, %r4897, 2;
	add.s64 	%rd172, %rd41, %rd171;
	mul.wide.s32 	%rd173, %r4898, 2;
	add.s64 	%rd174, %rd41, %rd173;
	mul.wide.s32 	%rd175, %r4899, 2;
	add.s64 	%rd176, %rd41, %rd175;
	mul.wide.s32 	%rd177, %r4900, 2;
	add.s64 	%rd178, %rd41, %rd177;
	mul.wide.s32 	%rd179, %r4901, 2;
	add.s64 	%rd180, %rd41, %rd179;
	mul.wide.s32 	%rd181, %r4902, 2;
	add.s64 	%rd182, %rd41, %rd181;
	.loc	1 140 52                        // gated_mlp.py:140:52
	mul.wide.s32 	%rd183, %r9, 2;
	add.s64 	%rd135, %rd152, %rd183;
	add.s64 	%rd136, %rd154, %rd183;
	add.s64 	%rd137, %rd156, %rd183;
	add.s64 	%rd138, %rd158, %rd183;
	add.s64 	%rd139, %rd160, %rd183;
	add.s64 	%rd140, %rd162, %rd183;
	add.s64 	%rd141, %rd164, %rd183;
	add.s64 	%rd142, %rd166, %rd183;
	add.s64 	%rd143, %rd168, %rd183;
	add.s64 	%rd144, %rd170, %rd183;
	add.s64 	%rd145, %rd172, %rd183;
	add.s64 	%rd146, %rd174, %rd183;
	add.s64 	%rd147, %rd176, %rd183;
	add.s64 	%rd148, %rd178, %rd183;
	add.s64 	%rd149, %rd180, %rd183;
	add.s64 	%rd150, %rd182, %rd183;
	.loc	1 141 33                        // gated_mlp.py:141:33
	setp.lt.s32 	%p74, %r4871, 1;
	setp.lt.s32 	%p75, %r4872, 1;
	setp.lt.s32 	%p76, %r4873, 1;
	setp.lt.s32 	%p77, %r4874, 1;
	setp.lt.s32 	%p78, %r4875, 1;
	setp.lt.s32 	%p79, %r4876, 1;
	setp.lt.s32 	%p80, %r4877, 1;
	setp.lt.s32 	%p81, %r4878, 1;
	setp.lt.s32 	%p82, %r4879, 1;
	setp.lt.s32 	%p83, %r4880, 1;
	setp.lt.s32 	%p84, %r4881, 1;
	setp.lt.s32 	%p85, %r4882, 1;
	setp.lt.s32 	%p86, %r4883, 1;
	setp.lt.s32 	%p87, %r4884, 1;
	setp.lt.s32 	%p88, %r4885, 1;
	setp.lt.s32 	%p89, %r4886, 1;
	.loc	1 141 58                        // gated_mlp.py:141:58
	setp.lt.s32 	%p90, %r9, %r491;
	.loc	1 141 39                        // gated_mlp.py:141:39
	and.pred 	%p58, %p90, %p74;
	and.pred 	%p59, %p90, %p75;
	and.pred 	%p60, %p90, %p76;
	and.pred 	%p61, %p90, %p77;
	and.pred 	%p62, %p90, %p78;
	and.pred 	%p63, %p90, %p79;
	and.pred 	%p64, %p90, %p80;
	and.pred 	%p65, %p90, %p81;
	and.pred 	%p66, %p90, %p82;
	and.pred 	%p67, %p90, %p83;
	and.pred 	%p68, %p90, %p84;
	and.pred 	%p69, %p90, %p85;
	and.pred 	%p70, %p90, %p86;
	and.pred 	%p71, %p90, %p87;
	and.pred 	%p72, %p90, %p88;
	and.pred 	%p73, %p90, %p89;
	.loc	1 142 21                        // gated_mlp.py:142:21
	shl.b32 	%r4903, %r5, 1;
	and.b32 	%r4904, %r4903, 6;
	shl.b32 	%r4905, %r5, 6;
	and.b32 	%r4906, %r4905, 768;
	or.b32 	%r4907, %r4906, %r4904;
	shl.b32 	%r4908, %r8, 6;
	or.b32 	%r4909, %r4907, %r4908;
	shl.b32 	%r4910, %r11, 5;
	or.b32 	%r4911, %r4909, %r4910;
	or.b32 	%r4912, %r5076, %r4911;
	and.b32 	%r4913, %r6, 2040;
	shr.u32 	%r4914, %r4911, 4;
	add.s32 	%r4916, %r645, %r4914;
	shl.b32 	%r4917, %r4912, 1;
	add.s32 	%r4918, %r4916, %r4917;
	st.shared.b32 	[%r4918], %r5077;
	or.b32 	%r4919, %r4911, 2048;
	shr.u32 	%r4920, %r4919, 4;
	and.b32 	%r4921, %r4920, 496;
	add.s32 	%r4922, %r645, %r4921;
	add.s32 	%r4923, %r4922, %r4917;
	st.shared.b32 	[%r4923+4096], %r5078;
	st.shared.b32 	[%r4918+64], %r5079;
	st.shared.b32 	[%r4923+4160], %r5080;
	st.shared.b32 	[%r4918+128], %r5081;
	st.shared.b32 	[%r4923+4224], %r5082;
	st.shared.b32 	[%r4918+192], %r5083;
	st.shared.b32 	[%r4923+4288], %r5084;
	st.shared.b32 	[%r4918+256], %r5085;
	st.shared.b32 	[%r4923+4352], %r5086;
	st.shared.b32 	[%r4918+320], %r5087;
	st.shared.b32 	[%r4923+4416], %r5088;
	st.shared.b32 	[%r4918+384], %r5089;
	st.shared.b32 	[%r4923+4480], %r5090;
	st.shared.b32 	[%r4918+448], %r5091;
	st.shared.b32 	[%r4923+4544], %r5092;
	bar.sync 	0;
	shl.b32 	%r4924, %r31, 1;
	add.s32 	%r4925, %r645, %r4924;
	shl.b32 	%r4926, %r4913, 1;
	add.s32 	%r4927, %r4925, %r4926;
	ld.shared.v4.b32 	{%r4803, %r4804, %r4805, %r4806}, [%r4927];
	or.b32 	%r4928, %r4913, 2048;
	shr.u32 	%r4929, %r4928, 4;
	and.b32 	%r4930, %r4929, 240;
	add.s32 	%r4931, %r645, %r4930;
	add.s32 	%r4932, %r4931, %r4926;
	ld.shared.v4.b32 	{%r4807, %r4808, %r4809, %r4810}, [%r4932+4096];
	or.b32 	%r4933, %r4913, 4096;
	shr.u32 	%r4934, %r4933, 4;
	and.b32 	%r4935, %r4934, 368;
	add.s32 	%r4936, %r645, %r4935;
	add.s32 	%r4937, %r4936, %r4926;
	ld.shared.v4.b32 	{%r4811, %r4812, %r4813, %r4814}, [%r4937+8192];
	or.b32 	%r4938, %r6, 6144;
	shr.u32 	%r4939, %r4938, 4;
	and.b32 	%r4940, %r4939, 496;
	add.s32 	%r4941, %r645, %r4940;
	shl.b32 	%r4942, %r4938, 1;
	add.s32 	%r4943, %r4941, %r4942;
	ld.shared.v4.b32 	{%r4815, %r4816, %r4817, %r4818}, [%r4943];
	bar.sync 	0;
	st.shared.b32 	[%r4918], %r5093;
	st.shared.b32 	[%r4923+4096], %r5094;
	st.shared.b32 	[%r4918+64], %r5095;
	st.shared.b32 	[%r4923+4160], %r5096;
	st.shared.b32 	[%r4918+128], %r5097;
	st.shared.b32 	[%r4923+4224], %r5098;
	st.shared.b32 	[%r4918+192], %r5099;
	st.shared.b32 	[%r4923+4288], %r5100;
	st.shared.b32 	[%r4918+256], %r5101;
	st.shared.b32 	[%r4923+4352], %r5102;
	st.shared.b32 	[%r4918+320], %r5103;
	st.shared.b32 	[%r4923+4416], %r5104;
	st.shared.b32 	[%r4918+384], %r5105;
	st.shared.b32 	[%r4923+4480], %r5106;
	st.shared.b32 	[%r4918+448], %r5107;
	st.shared.b32 	[%r4923+4544], %r5108;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r4819, %r4820, %r4821, %r4822}, [%r4927];
	ld.shared.v4.b32 	{%r4823, %r4824, %r4825, %r4826}, [%r4932+4096];
	ld.shared.v4.b32 	{%r4827, %r4828, %r4829, %r4830}, [%r4937+8192];
	ld.shared.v4.b32 	{%r4831, %r4832, %r4833, %r4834}, [%r4943];
	bar.sync 	0;
	st.shared.b32 	[%r4918], %r5109;
	st.shared.b32 	[%r4923+4096], %r5110;
	st.shared.b32 	[%r4918+64], %r5111;
	st.shared.b32 	[%r4923+4160], %r5112;
	st.shared.b32 	[%r4918+128], %r5113;
	st.shared.b32 	[%r4923+4224], %r5114;
	st.shared.b32 	[%r4918+192], %r5115;
	st.shared.b32 	[%r4923+4288], %r5116;
	st.shared.b32 	[%r4918+256], %r5117;
	st.shared.b32 	[%r4923+4352], %r5118;
	st.shared.b32 	[%r4918+320], %r5119;
	st.shared.b32 	[%r4923+4416], %r5120;
	st.shared.b32 	[%r4918+384], %r5121;
	st.shared.b32 	[%r4923+4480], %r5122;
	st.shared.b32 	[%r4918+448], %r5123;
	st.shared.b32 	[%r4923+4544], %r5124;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r4835, %r4836, %r4837, %r4838}, [%r4927];
	ld.shared.v4.b32 	{%r4839, %r4840, %r4841, %r4842}, [%r4932+4096];
	ld.shared.v4.b32 	{%r4843, %r4844, %r4845, %r4846}, [%r4937+8192];
	ld.shared.v4.b32 	{%r4847, %r4848, %r4849, %r4850}, [%r4943];
	bar.sync 	0;
	st.shared.b32 	[%r4918], %r5125;
	st.shared.b32 	[%r4923+4096], %r5126;
	st.shared.b32 	[%r4918+64], %r5127;
	st.shared.b32 	[%r4923+4160], %r5128;
	st.shared.b32 	[%r4918+128], %r5129;
	st.shared.b32 	[%r4923+4224], %r5130;
	st.shared.b32 	[%r4918+192], %r5131;
	st.shared.b32 	[%r4923+4288], %r5132;
	st.shared.b32 	[%r4918+256], %r5133;
	st.shared.b32 	[%r4923+4352], %r5134;
	st.shared.b32 	[%r4918+320], %r5135;
	st.shared.b32 	[%r4923+4416], %r5136;
	st.shared.b32 	[%r4918+384], %r5137;
	st.shared.b32 	[%r4923+4480], %r5138;
	st.shared.b32 	[%r4918+448], %r5139;
	st.shared.b32 	[%r4923+4544], %r5140;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r4851, %r4852, %r4853, %r4854}, [%r4927];
	ld.shared.v4.b32 	{%r4855, %r4856, %r4857, %r4858}, [%r4932+4096];
	ld.shared.v4.b32 	{%r4859, %r4860, %r4861, %r4862}, [%r4937+8192];
	ld.shared.v4.b32 	{%r4863, %r4864, %r4865, %r4866}, [%r4943];
	// begin inline asm
	@%p58 st.global.v4.b32 [ %rd135 + 0 ], { %r4803, %r4804, %r4805, %r4806 };
	// end inline asm
	// begin inline asm
	@%p59 st.global.v4.b32 [ %rd136 + 0 ], { %r4807, %r4808, %r4809, %r4810 };
	// end inline asm
	// begin inline asm
	@%p60 st.global.v4.b32 [ %rd137 + 0 ], { %r4811, %r4812, %r4813, %r4814 };
	// end inline asm
	// begin inline asm
	@%p61 st.global.v4.b32 [ %rd138 + 0 ], { %r4815, %r4816, %r4817, %r4818 };
	// end inline asm
	// begin inline asm
	@%p62 st.global.v4.b32 [ %rd139 + 0 ], { %r4819, %r4820, %r4821, %r4822 };
	// end inline asm
	// begin inline asm
	@%p63 st.global.v4.b32 [ %rd140 + 0 ], { %r4823, %r4824, %r4825, %r4826 };
	// end inline asm
	// begin inline asm
	@%p64 st.global.v4.b32 [ %rd141 + 0 ], { %r4827, %r4828, %r4829, %r4830 };
	// end inline asm
	// begin inline asm
	@%p65 st.global.v4.b32 [ %rd142 + 0 ], { %r4831, %r4832, %r4833, %r4834 };
	// end inline asm
	// begin inline asm
	@%p66 st.global.v4.b32 [ %rd143 + 0 ], { %r4835, %r4836, %r4837, %r4838 };
	// end inline asm
	// begin inline asm
	@%p67 st.global.v4.b32 [ %rd144 + 0 ], { %r4839, %r4840, %r4841, %r4842 };
	// end inline asm
	// begin inline asm
	@%p68 st.global.v4.b32 [ %rd145 + 0 ], { %r4843, %r4844, %r4845, %r4846 };
	// end inline asm
	// begin inline asm
	@%p69 st.global.v4.b32 [ %rd146 + 0 ], { %r4847, %r4848, %r4849, %r4850 };
	// end inline asm
	// begin inline asm
	@%p70 st.global.v4.b32 [ %rd147 + 0 ], { %r4851, %r4852, %r4853, %r4854 };
	// end inline asm
	// begin inline asm
	@%p71 st.global.v4.b32 [ %rd148 + 0 ], { %r4855, %r4856, %r4857, %r4858 };
	// end inline asm
	// begin inline asm
	@%p72 st.global.v4.b32 [ %rd149 + 0 ], { %r4859, %r4860, %r4861, %r4862 };
	// end inline asm
	// begin inline asm
	@%p73 st.global.v4.b32 [ %rd150 + 0 ], { %r4863, %r4864, %r4865, %r4866 };
	// end inline asm
	.loc	1 142 4                         // gated_mlp.py:142:4
	ret;
$L__tmp5:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/anjiang/PTX_dataset/triton_ptx/gated_mlp.py"
	.file	2 "/mnt/efs/anjiang/miniconda3/envs/ptx/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 165                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x9e DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 103                                 // DW_AT_name
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 109
.b8 108
.b8 112
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 97
.b8 110
.b8 106
.b8 105
.b8 97
.b8 110
.b8 103
.b8 47
.b8 80
.b8 84
.b8 88
.b8 95
.b8 100
.b8 97
.b8 116
.b8 97
.b8 115
.b8 101
.b8 116
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 112
.b8 116
.b8 120
.b8 0
.b8 2                                   // Abbrev [2] 0x52:0x10 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x62:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 82                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x77:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 93                                  // DW_AT_call_line
.b8 27                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x8f:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp4                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 120                                 // DW_AT_call_line
.b8 33                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
