//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	matmul_kernel           // -- Begin function matmul_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel
.visible .entry matmul_kernel(
	.param .u64 .ptr .global .align 1 matmul_kernel_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_8
)
.reqntid 256
{
	.reg .pred 	%p<60>;
	.reg .b32 	%r<3008>;
	.reg .b64 	%rd<128>;
	.loc	1 68 0                          // gated_mlp.py:68:0
$L__func_begin0:
	.loc	1 68 0                          // gated_mlp.py:68:0

// %bb.0:
	ld.param.b32 	%r458, [matmul_kernel_param_7];
	ld.param.b32 	%r457, [matmul_kernel_param_4];
	ld.param.b32 	%r456, [matmul_kernel_param_3];
	ld.param.b64 	%rd27, [matmul_kernel_param_2];
	ld.param.b64 	%rd26, [matmul_kernel_param_1];
	ld.param.b64 	%rd25, [matmul_kernel_param_0];
$L__tmp0:
	.loc	1 91 24                         // gated_mlp.py:91:24
	mov.u32 	%r507, %ctaid.x;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:93:27 ]
	add.s32 	%r508, %r456, 255;
	.loc	2 40 28                         // standard.py:40:28 @[ gated_mlp.py:93:27 ]
	shr.s32 	%r509, %r508, 31;
	shr.u32 	%r510, %r509, 24;
	add.s32 	%r511, %r508, %r510;
	shr.s32 	%r512, %r511, 8;
$L__tmp2:
	.loc	1 94 38                         // gated_mlp.py:94:38
	shl.b32 	%r514, %r512, 3;
	.loc	1 95 22                         // gated_mlp.py:95:22
	div.s32 	%r515, %r507, %r514;
	ld.param.b32 	%r516, [matmul_kernel_param_6];
	.loc	1 96 29                         // gated_mlp.py:96:29
	shl.b32 	%r1, %r515, 3;
	.loc	1 97 35                         // gated_mlp.py:97:35
	sub.s32 	%r517, 1, %r1;
	.loc	1 97 48                         // gated_mlp.py:97:48
	min.s32 	%r2, %r517, 8;
	.loc	1 98 34                         // gated_mlp.py:98:34
	mul.lo.s32 	%r518, %r515, %r514;
	sub.s32 	%r3, %r507, %r518;
	.loc	1 99 40                         // gated_mlp.py:99:40
	div.s32 	%r4, %r3, %r2;
	.loc	1 109 23                        // gated_mlp.py:109:23
	shl.b32 	%r519, %r4, 8;
	.loc	1 109 51                        // gated_mlp.py:109:51
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r5, 3;
	and.b32 	%r7, %r6, 56;
	and.b32 	%r8, %r5, 16;
	and.b32 	%r520, %r6, 248;
	.loc	1 109 38                        // gated_mlp.py:109:38
	or.b32 	%r9, %r519, %r520;
	.loc	1 109 68                        // gated_mlp.py:109:68
	rem.s32 	%r521, %r9, %r456;
	.loc	1 111 22                        // gated_mlp.py:111:22
	mul.wide.u32 	%rd52, %r7, 2;
	add.s64 	%rd28, %rd25, %rd52;
	.loc	1 112 29                        // gated_mlp.py:112:29
	and.b32 	%r10, %r5, 128;
	shr.u32 	%r11, %r5, 5;
	bfe.u32 	%r12, %r5, 5, 3;
	or.b32 	%r13, %r12, 8;
	or.b32 	%r14, %r12, 16;
	or.b32 	%r15, %r11, 24;
	or.b32 	%r16, %r12, 32;
	or.b32 	%r17, %r12, 40;
	or.b32 	%r18, %r12, 48;
	or.b32 	%r19, %r11, 56;
	.loc	1 112 40                        // gated_mlp.py:112:40
	shl.b32 	%r522, %r516, 3;
	shl.b32 	%r523, %r516, 4;
	.loc	1 112 52                        // gated_mlp.py:112:52
	mad.lo.s32 	%r524, %r516, %r12, %r521;
	add.s32 	%r525, %r524, %r522;
	add.s32 	%r526, %r525, %r522;
	mad.lo.s32 	%r527, %r516, %r15, %r521;
	add.s32 	%r528, %r526, %r523;
	add.s32 	%r529, %r528, %r522;
	add.s32 	%r530, %r529, %r522;
	mad.lo.s32 	%r531, %r516, %r19, %r521;
	.loc	1 112 22                        // gated_mlp.py:112:22
	mul.wide.s32 	%rd53, %r524, 2;
	add.s64 	%rd32, %rd26, %rd53;
	mul.wide.s32 	%rd54, %r525, 2;
	add.s64 	%rd33, %rd26, %rd54;
	mul.wide.s32 	%rd55, %r526, 2;
	add.s64 	%rd34, %rd26, %rd55;
	mul.wide.s32 	%rd56, %r527, 2;
	add.s64 	%rd35, %rd26, %rd56;
	mul.wide.s32 	%rd57, %r528, 2;
	add.s64 	%rd36, %rd26, %rd57;
	mul.wide.s32 	%rd58, %r529, 2;
	add.s64 	%rd37, %rd26, %rd58;
	mul.wide.s32 	%rd59, %r530, 2;
	add.s64 	%rd38, %rd26, %rd59;
	mul.wide.s32 	%rd60, %r531, 2;
	add.s64 	%rd39, %rd26, %rd60;
$L__tmp3:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:120:33 ]
	add.s32 	%r532, %r457, 63;
$L__tmp4:
	.loc	1 129 33                        // gated_mlp.py:129:33
	shl.b32 	%r536, %r516, 6;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p1, %r532, 63;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p2, %r7, %r457;
	.loc	1 123 20                        // gated_mlp.py:123:20
	xor.b32 	%r537, %r6, %r5;
	and.b32 	%r538, %r537, 56;
	and.b32 	%r539, %r6, 1984;
	or.b32 	%r21, %r539, %r538;
	shl.b32 	%r540, %r21, 1;
	mov.b32 	%r541, global_smem;
	add.s32 	%r542, %r541, %r540;
	add.s32 	%r459, %r542, 65536;
	add.s32 	%r461, %r542, 69632;
	add.s32 	%r463, %r542, 73728;
	add.s32 	%r465, %r542, 77824;
	selp.b32 	%r543, 16, 0, %p1;
	selp.b32 	%r462, %r543, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r459 + 0 ], [ %rd28 + 0 ], 0x10, %r462;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r461 + 0 ], [ %rd28 + 0 ], 0x10, %r462;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r463 + 0 ], [ %rd28 + 0 ], 0x10, %r462;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r465 + 0 ], [ %rd28 + 0 ], 0x10, %r462;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p3, %r12, %r457;
	setp.lt.s32 	%p4, %r13, %r457;
	setp.lt.s32 	%p5, %r14, %r457;
	setp.lt.s32 	%p6, %r15, %r457;
	setp.lt.s32 	%p7, %r16, %r457;
	setp.lt.s32 	%p8, %r17, %r457;
	setp.lt.s32 	%p9, %r18, %r457;
	setp.lt.s32 	%p10, %r19, %r457;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shr.u32 	%r22, %r5, 2;
	and.b32 	%r23, %r22, 56;
	xor.b32 	%r544, %r23, %r520;
	shl.b32 	%r545, %r12, 8;
	or.b32 	%r24, %r544, %r545;
	shl.b32 	%r546, %r24, 1;
	add.s32 	%r467, %r541, %r546;
	add.s32 	%r469, %r467, 4096;
	add.s32 	%r471, %r467, 8192;
	add.s32 	%r473, %r467, 12288;
	add.s32 	%r475, %r467, 16384;
	add.s32 	%r477, %r467, 20480;
	add.s32 	%r479, %r467, 24576;
	add.s32 	%r481, %r467, 28672;
	selp.b32 	%r468, %r543, 0, %p3;
	// begin inline asm
	cp.async.cg.shared.global [ %r467 + 0 ], [ %rd32 + 0 ], 0x10, %r468;
	// end inline asm
	selp.b32 	%r470, %r543, 0, %p4;
	// begin inline asm
	cp.async.cg.shared.global [ %r469 + 0 ], [ %rd33 + 0 ], 0x10, %r470;
	// end inline asm
	selp.b32 	%r472, %r543, 0, %p5;
	// begin inline asm
	cp.async.cg.shared.global [ %r471 + 0 ], [ %rd34 + 0 ], 0x10, %r472;
	// end inline asm
	selp.b32 	%r474, %r543, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r473 + 0 ], [ %rd35 + 0 ], 0x10, %r474;
	// end inline asm
	selp.b32 	%r476, %r543, 0, %p7;
	// begin inline asm
	cp.async.cg.shared.global [ %r475 + 0 ], [ %rd36 + 0 ], 0x10, %r476;
	// end inline asm
	selp.b32 	%r478, %r543, 0, %p8;
	// begin inline asm
	cp.async.cg.shared.global [ %r477 + 0 ], [ %rd37 + 0 ], 0x10, %r478;
	// end inline asm
	selp.b32 	%r480, %r543, 0, %p9;
	// begin inline asm
	cp.async.cg.shared.global [ %r479 + 0 ], [ %rd38 + 0 ], 0x10, %r480;
	// end inline asm
	selp.b32 	%r482, %r543, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r481 + 0 ], [ %rd39 + 0 ], 0x10, %r482;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p11, %r532, 127;
	.loc	1 128 18                        // gated_mlp.py:128:18
	add.s64 	%rd40, %rd28, 128;
	.loc	1 129 18                        // gated_mlp.py:129:18
	mul.wide.s32 	%rd61, %r536, 2;
	add.s64 	%rd44, %rd32, %rd61;
	add.s64 	%rd45, %rd33, %rd61;
	add.s64 	%rd46, %rd34, %rd61;
	add.s64 	%rd47, %rd35, %rd61;
	add.s64 	%rd48, %rd36, %rd61;
	add.s64 	%rd49, %rd37, %rd61;
	add.s64 	%rd50, %rd38, %rd61;
	add.s64 	%rd51, %rd39, %rd61;
	.loc	1 123 55                        // gated_mlp.py:123:55
	add.s32 	%r547, %r457, -64;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p12, %r7, %r547;
	.loc	1 123 20                        // gated_mlp.py:123:20
	bar.sync 	0;
	add.s32 	%r483, %r542, 81920;
	add.s32 	%r485, %r542, 86016;
	add.s32 	%r487, %r542, 90112;
	add.s32 	%r489, %r542, 94208;
	selp.b32 	%r548, 16, 0, %p12;
	selp.b32 	%r486, %r548, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r483 + 0 ], [ %rd40 + 0 ], 0x10, %r486;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r485 + 0 ], [ %rd40 + 0 ], 0x10, %r486;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r487 + 0 ], [ %rd40 + 0 ], 0x10, %r486;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r489 + 0 ], [ %rd40 + 0 ], 0x10, %r486;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p13, %r12, %r547;
	setp.lt.s32 	%p14, %r13, %r547;
	setp.lt.s32 	%p15, %r14, %r547;
	setp.lt.s32 	%p16, %r15, %r547;
	setp.lt.s32 	%p17, %r16, %r547;
	setp.lt.s32 	%p18, %r17, %r547;
	setp.lt.s32 	%p19, %r18, %r547;
	setp.lt.s32 	%p20, %r19, %r547;
	.loc	1 124 20                        // gated_mlp.py:124:20
	add.s32 	%r491, %r467, 32768;
	add.s32 	%r493, %r467, 36864;
	add.s32 	%r495, %r467, 40960;
	add.s32 	%r497, %r467, 45056;
	add.s32 	%r499, %r467, 49152;
	add.s32 	%r501, %r467, 53248;
	add.s32 	%r503, %r467, 57344;
	add.s32 	%r505, %r467, 61440;
	selp.b32 	%r549, 16, 0, %p13;
	selp.b32 	%r492, %r549, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r491 + 0 ], [ %rd44 + 0 ], 0x10, %r492;
	// end inline asm
	selp.b32 	%r550, 16, 0, %p14;
	selp.b32 	%r494, %r550, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r493 + 0 ], [ %rd45 + 0 ], 0x10, %r494;
	// end inline asm
	selp.b32 	%r551, 16, 0, %p15;
	selp.b32 	%r496, %r551, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r495 + 0 ], [ %rd46 + 0 ], 0x10, %r496;
	// end inline asm
	selp.b32 	%r552, 16, 0, %p16;
	selp.b32 	%r498, %r552, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r497 + 0 ], [ %rd47 + 0 ], 0x10, %r498;
	// end inline asm
	selp.b32 	%r553, 16, 0, %p17;
	selp.b32 	%r500, %r553, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r499 + 0 ], [ %rd48 + 0 ], 0x10, %r500;
	// end inline asm
	selp.b32 	%r554, 16, 0, %p18;
	selp.b32 	%r502, %r554, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r501 + 0 ], [ %rd49 + 0 ], 0x10, %r502;
	// end inline asm
	selp.b32 	%r555, 16, 0, %p19;
	selp.b32 	%r504, %r555, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r503 + 0 ], [ %rd50 + 0 ], 0x10, %r504;
	// end inline asm
	selp.b32 	%r556, 16, 0, %p20;
	selp.b32 	%r506, %r556, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r505 + 0 ], [ %rd51 + 0 ], 0x10, %r506;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	@%p1 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:                              // %.lr.ph
	.loc	1 0 0                           // gated_mlp.py:0
	cvt.s64.s32 	%rd1, %r524;
	cvt.s64.s32 	%rd2, %r525;
	cvt.s64.s32 	%rd3, %r526;
	cvt.s64.s32 	%rd4, %r527;
	cvt.s64.s32 	%rd5, %r528;
	cvt.s64.s32 	%rd6, %r529;
	cvt.s64.s32 	%rd7, %r530;
	cvt.s64.s32 	%rd8, %r531;
	shr.s32 	%r533, %r532, 31;
	shr.u32 	%r534, %r533, 26;
	add.s32 	%r535, %r532, %r534;
	shr.s32 	%r20, %r535, 6;
	cvt.s64.s32 	%rd9, %r536;
	.loc	1 109 51                        // gated_mlp.py:109:51
	bfe.s32 	%r625, %r5, 2, 1;
	add.s32 	%r27, %r20, -2;
	and.b32 	%r626, %r5, 3;
	mul.lo.s32 	%r627, %r626, 72;
	and.b32 	%r628, %r625, 288;
	xor.b32 	%r629, %r628, %r627;
	shl.b32 	%r2943, %r5, 6;
	and.b32 	%r630, %r2943, 512;
	or.b32 	%r631, %r629, %r630;
	shr.u32 	%r632, %r8, 1;
	xor.b32 	%r633, %r631, %r632;
	shl.b32 	%r634, %r10, 3;
	or.b32 	%r29, %r633, %r634;
	xor.b32 	%r30, %r29, 16;
	xor.b32 	%r31, %r29, 32;
	xor.b32 	%r32, %r29, 48;
	or.b32 	%r33, %r29, 2048;
	xor.b32 	%r34, %r29, 2064;
	xor.b32 	%r35, %r29, 2080;
	xor.b32 	%r36, %r29, 2096;
	or.b32 	%r37, %r29, 4096;
	xor.b32 	%r38, %r29, 4112;
	xor.b32 	%r39, %r29, 4128;
	xor.b32 	%r40, %r29, 4144;
	or.b32 	%r41, %r29, 6144;
	xor.b32 	%r42, %r29, 6160;
	xor.b32 	%r43, %r29, 6176;
	xor.b32 	%r44, %r29, 6192;
	mul.lo.s32 	%r635, %r626, 264;
	and.b32 	%r636, %r625, 1056;
	xor.b32 	%r637, %r636, %r635;
	shl.b32 	%r638, %r5, 8;
	and.b32 	%r639, %r638, 6144;
	or.b32 	%r640, %r637, %r639;
	and.b32 	%r2942, %r22, 24;
	xor.b32 	%r46, %r2942, %r640;
	xor.b32 	%r47, %r46, 32;
	xor.b32 	%r48, %r46, 8224;
	xor.b32 	%r49, %r46, 64;
	xor.b32 	%r50, %r46, 8256;
	xor.b32 	%r51, %r46, 96;
	xor.b32 	%r52, %r46, 8288;
	xor.b32 	%r53, %r46, 128;
	xor.b32 	%r54, %r46, 8320;
	xor.b32 	%r55, %r46, 160;
	xor.b32 	%r56, %r46, 8352;
	xor.b32 	%r57, %r46, 192;
	xor.b32 	%r58, %r46, 8384;
	xor.b32 	%r59, %r46, 224;
	xor.b32 	%r60, %r46, 8416;
	add.s32 	%r2810, %r457, -128;
	.loc	1 120 22                        // gated_mlp.py:120:22
	shl.b64 	%rd10, %rd8, 1;
	shl.b64 	%rd62, %rd9, 2;
	add.s64 	%rd127, %rd26, %rd62;
	shl.b64 	%rd12, %rd9, 1;
	shl.b64 	%rd13, %rd7, 1;
	shl.b64 	%rd14, %rd6, 1;
	shl.b64 	%rd15, %rd5, 1;
	shl.b64 	%rd16, %rd4, 1;
	shl.b64 	%rd17, %rd3, 1;
	shl.b64 	%rd18, %rd2, 1;
	shl.b64 	%rd19, %rd1, 1;
	and.b32 	%r641, %r5, 7;
	mul.wide.u32 	%rd63, %r641, 16;
	add.s64 	%rd64, %rd63, %rd25;
	add.s64 	%rd126, %rd64, 256;
	mov.b32 	%r2941, 0;
	mov.b32 	%r2813, 0f00000000;
	mov.b32 	%r2812, 1;
	mov.b32 	%r2811, -1;
	shl.b32 	%r2624, %r30, 1;
	shl.b32 	%r2625, %r31, 1;
	shl.b32 	%r2626, %r32, 1;
	shl.b32 	%r2627, %r33, 1;
	shl.b32 	%r2628, %r34, 1;
	shl.b32 	%r2629, %r35, 1;
	shl.b32 	%r2630, %r36, 1;
	shl.b32 	%r2631, %r37, 1;
	shl.b32 	%r2632, %r38, 1;
	shl.b32 	%r2633, %r39, 1;
	shl.b32 	%r2634, %r40, 1;
	shl.b32 	%r2635, %r41, 1;
	shl.b32 	%r2636, %r42, 1;
	shl.b32 	%r2637, %r43, 1;
	shl.b32 	%r2638, %r44, 1;
	shl.b32 	%r2642, %r47, 1;
	shl.b32 	%r2643, %r48, 1;
	shl.b32 	%r2644, %r49, 1;
	shl.b32 	%r2645, %r50, 1;
	shl.b32 	%r2646, %r51, 1;
	shl.b32 	%r2647, %r52, 1;
	shl.b32 	%r2648, %r53, 1;
	shl.b32 	%r2649, %r54, 1;
	shl.b32 	%r2650, %r55, 1;
	shl.b32 	%r2651, %r56, 1;
	shl.b32 	%r2652, %r57, 1;
	shl.b32 	%r2653, %r58, 1;
	shl.b32 	%r2654, %r59, 1;
	shl.b32 	%r2655, %r60, 1;
	mov.b32 	%r2814, %r2813;
	mov.b32 	%r2815, %r2813;
	mov.b32 	%r2816, %r2813;
	mov.b32 	%r2817, %r2813;
	mov.b32 	%r2818, %r2813;
	mov.b32 	%r2819, %r2813;
	mov.b32 	%r2820, %r2813;
	mov.b32 	%r2821, %r2813;
	mov.b32 	%r2822, %r2813;
	mov.b32 	%r2823, %r2813;
	mov.b32 	%r2824, %r2813;
	mov.b32 	%r2825, %r2813;
	mov.b32 	%r2826, %r2813;
	mov.b32 	%r2827, %r2813;
	mov.b32 	%r2828, %r2813;
	mov.b32 	%r2829, %r2813;
	mov.b32 	%r2830, %r2813;
	mov.b32 	%r2831, %r2813;
	mov.b32 	%r2832, %r2813;
	mov.b32 	%r2833, %r2813;
	mov.b32 	%r2834, %r2813;
	mov.b32 	%r2835, %r2813;
	mov.b32 	%r2836, %r2813;
	mov.b32 	%r2837, %r2813;
	mov.b32 	%r2838, %r2813;
	mov.b32 	%r2839, %r2813;
	mov.b32 	%r2840, %r2813;
	mov.b32 	%r2841, %r2813;
	mov.b32 	%r2842, %r2813;
	mov.b32 	%r2843, %r2813;
	mov.b32 	%r2844, %r2813;
	mov.b32 	%r2845, %r2813;
	mov.b32 	%r2846, %r2813;
	mov.b32 	%r2847, %r2813;
	mov.b32 	%r2848, %r2813;
	mov.b32 	%r2849, %r2813;
	mov.b32 	%r2850, %r2813;
	mov.b32 	%r2851, %r2813;
	mov.b32 	%r2852, %r2813;
	mov.b32 	%r2853, %r2813;
	mov.b32 	%r2854, %r2813;
	mov.b32 	%r2855, %r2813;
	mov.b32 	%r2856, %r2813;
	mov.b32 	%r2857, %r2813;
	mov.b32 	%r2858, %r2813;
	mov.b32 	%r2859, %r2813;
	mov.b32 	%r2860, %r2813;
	mov.b32 	%r2861, %r2813;
	mov.b32 	%r2862, %r2813;
	mov.b32 	%r2863, %r2813;
	mov.b32 	%r2864, %r2813;
	mov.b32 	%r2865, %r2813;
	mov.b32 	%r2866, %r2813;
	mov.b32 	%r2867, %r2813;
	mov.b32 	%r2868, %r2813;
	mov.b32 	%r2869, %r2813;
	mov.b32 	%r2870, %r2813;
	mov.b32 	%r2871, %r2813;
	mov.b32 	%r2872, %r2813;
	mov.b32 	%r2873, %r2813;
	mov.b32 	%r2874, %r2813;
	mov.b32 	%r2875, %r2813;
	mov.b32 	%r2876, %r2813;
	mov.b32 	%r2877, %r2813;
	mov.b32 	%r2878, %r2813;
	mov.b32 	%r2879, %r2813;
	mov.b32 	%r2880, %r2813;
	mov.b32 	%r2881, %r2813;
	mov.b32 	%r2882, %r2813;
	mov.b32 	%r2883, %r2813;
	mov.b32 	%r2884, %r2813;
	mov.b32 	%r2885, %r2813;
	mov.b32 	%r2886, %r2813;
	mov.b32 	%r2887, %r2813;
	mov.b32 	%r2888, %r2813;
	mov.b32 	%r2889, %r2813;
	mov.b32 	%r2890, %r2813;
	mov.b32 	%r2891, %r2813;
	mov.b32 	%r2892, %r2813;
	mov.b32 	%r2893, %r2813;
	mov.b32 	%r2894, %r2813;
	mov.b32 	%r2895, %r2813;
	mov.b32 	%r2896, %r2813;
	mov.b32 	%r2897, %r2813;
	mov.b32 	%r2898, %r2813;
	mov.b32 	%r2899, %r2813;
	mov.b32 	%r2900, %r2813;
	mov.b32 	%r2901, %r2813;
	mov.b32 	%r2902, %r2813;
	mov.b32 	%r2903, %r2813;
	mov.b32 	%r2904, %r2813;
	mov.b32 	%r2905, %r2813;
	mov.b32 	%r2906, %r2813;
	mov.b32 	%r2907, %r2813;
	mov.b32 	%r2908, %r2813;
	mov.b32 	%r2909, %r2813;
	mov.b32 	%r2910, %r2813;
	mov.b32 	%r2911, %r2813;
	mov.b32 	%r2912, %r2813;
	mov.b32 	%r2913, %r2813;
	mov.b32 	%r2914, %r2813;
	mov.b32 	%r2915, %r2813;
	mov.b32 	%r2916, %r2813;
	mov.b32 	%r2917, %r2813;
	mov.b32 	%r2918, %r2813;
	mov.b32 	%r2919, %r2813;
	mov.b32 	%r2920, %r2813;
	mov.b32 	%r2921, %r2813;
	mov.b32 	%r2922, %r2813;
	mov.b32 	%r2923, %r2813;
	mov.b32 	%r2924, %r2813;
	mov.b32 	%r2925, %r2813;
	mov.b32 	%r2926, %r2813;
	mov.b32 	%r2927, %r2813;
	mov.b32 	%r2928, %r2813;
	mov.b32 	%r2929, %r2813;
	mov.b32 	%r2930, %r2813;
	mov.b32 	%r2931, %r2813;
	mov.b32 	%r2932, %r2813;
	mov.b32 	%r2933, %r2813;
	mov.b32 	%r2934, %r2813;
	mov.b32 	%r2935, %r2813;
	mov.b32 	%r2936, %r2813;
	mov.b32 	%r2937, %r2813;
	mov.b32 	%r2938, %r2813;
	mov.b32 	%r2939, %r2813;
	mov.b32 	%r2940, %r2813;
$L__BB0_3:                              // =>This Inner Loop Header: Depth=1
	setp.lt.s32 	%p21, %r2941, %r27;
	add.s32 	%r2618, %r2811, 1;
	setp.gt.s32 	%p22, %r2618, 1;
	selp.b32 	%r2811, 0, %r2618, %p22;
	.loc	1 123 20                        // gated_mlp.py:123:20
	cp.async.wait_group 	2;
	bar.sync 	0;
	shl.b32 	%r2619, %r2811, 14;
	add.s32 	%r2621, %r541, 65536;
	add.s32 	%r2622, %r2621, %r2619;
	shl.b32 	%r2623, %r29, 1;
	add.s32 	%r646, %r2622, %r2623;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r810, %r811, %r812, %r813}, [%r646];
	// end inline asm
	add.s32 	%r651, %r2622, %r2624;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1258, %r1259, %r1260, %r1261}, [%r651];
	// end inline asm
	add.s32 	%r656, %r2622, %r2625;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1706, %r1707, %r1708, %r1709}, [%r656];
	// end inline asm
	add.s32 	%r661, %r2622, %r2626;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2154, %r2155, %r2156, %r2157}, [%r661];
	// end inline asm
	add.s32 	%r666, %r2622, %r2627;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r922, %r923, %r924, %r925}, [%r666];
	// end inline asm
	add.s32 	%r671, %r2622, %r2628;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1370, %r1371, %r1372, %r1373}, [%r671];
	// end inline asm
	add.s32 	%r676, %r2622, %r2629;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1818, %r1819, %r1820, %r1821}, [%r676];
	// end inline asm
	add.s32 	%r681, %r2622, %r2630;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2266, %r2267, %r2268, %r2269}, [%r681];
	// end inline asm
	add.s32 	%r686, %r2622, %r2631;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1034, %r1035, %r1036, %r1037}, [%r686];
	// end inline asm
	add.s32 	%r691, %r2622, %r2632;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1482, %r1483, %r1484, %r1485}, [%r691];
	// end inline asm
	add.s32 	%r696, %r2622, %r2633;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1930, %r1931, %r1932, %r1933}, [%r696];
	// end inline asm
	add.s32 	%r701, %r2622, %r2634;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2378, %r2379, %r2380, %r2381}, [%r701];
	// end inline asm
	add.s32 	%r706, %r2622, %r2635;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1146, %r1147, %r1148, %r1149}, [%r706];
	// end inline asm
	add.s32 	%r711, %r2622, %r2636;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1594, %r1595, %r1596, %r1597}, [%r711];
	// end inline asm
	add.s32 	%r716, %r2622, %r2637;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2042, %r2043, %r2044, %r2045}, [%r716];
	// end inline asm
	add.s32 	%r721, %r2622, %r2638;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2490, %r2491, %r2492, %r2493}, [%r721];
	// end inline asm
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r2639, %r2811, 15;
	add.s32 	%r2640, %r541, %r2639;
	shl.b32 	%r2641, %r46, 1;
	add.s32 	%r726, %r2640, %r2641;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r814, %r815, %r1262, %r1263}, [%r726];
	// end inline asm
	add.s32 	%r731, %r726, 16384;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1710, %r1711, %r2158, %r2159}, [%r731];
	// end inline asm
	add.s32 	%r736, %r2640, %r2642;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r828, %r829, %r1276, %r1277}, [%r736];
	// end inline asm
	add.s32 	%r741, %r2640, %r2643;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1724, %r1725, %r2172, %r2173}, [%r741];
	// end inline asm
	add.s32 	%r746, %r2640, %r2644;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r842, %r843, %r1290, %r1291}, [%r746];
	// end inline asm
	add.s32 	%r751, %r2640, %r2645;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1738, %r1739, %r2186, %r2187}, [%r751];
	// end inline asm
	add.s32 	%r756, %r2640, %r2646;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r856, %r857, %r1304, %r1305}, [%r756];
	// end inline asm
	add.s32 	%r761, %r2640, %r2647;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1752, %r1753, %r2200, %r2201}, [%r761];
	// end inline asm
	add.s32 	%r766, %r2640, %r2648;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r870, %r871, %r1318, %r1319}, [%r766];
	// end inline asm
	add.s32 	%r771, %r2640, %r2649;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1766, %r1767, %r2214, %r2215}, [%r771];
	// end inline asm
	add.s32 	%r776, %r2640, %r2650;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r884, %r885, %r1332, %r1333}, [%r776];
	// end inline asm
	add.s32 	%r781, %r2640, %r2651;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1780, %r1781, %r2228, %r2229}, [%r781];
	// end inline asm
	add.s32 	%r786, %r2640, %r2652;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r898, %r899, %r1346, %r1347}, [%r786];
	// end inline asm
	add.s32 	%r791, %r2640, %r2653;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1794, %r1795, %r2242, %r2243}, [%r791];
	// end inline asm
	add.s32 	%r796, %r2640, %r2654;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r912, %r913, %r1360, %r1361}, [%r796];
	// end inline asm
	add.s32 	%r801, %r2640, %r2655;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 {%r1808, %r1809, %r2256, %r2257}, [%r801];
	// end inline asm
	.loc	1 126 35                        // gated_mlp.py:126:35
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2813, %r2814, %r2815, %r2816 }, { %r810, %r811, %r812, %r813 }, { %r814, %r815 }, { %r2813, %r2814, %r2815, %r2816 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2817, %r2818, %r2819, %r2820 }, { %r810, %r811, %r812, %r813 }, { %r828, %r829 }, { %r2817, %r2818, %r2819, %r2820 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2821, %r2822, %r2823, %r2824 }, { %r810, %r811, %r812, %r813 }, { %r842, %r843 }, { %r2821, %r2822, %r2823, %r2824 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2825, %r2826, %r2827, %r2828 }, { %r810, %r811, %r812, %r813 }, { %r856, %r857 }, { %r2825, %r2826, %r2827, %r2828 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2829, %r2830, %r2831, %r2832 }, { %r810, %r811, %r812, %r813 }, { %r870, %r871 }, { %r2829, %r2830, %r2831, %r2832 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2833, %r2834, %r2835, %r2836 }, { %r810, %r811, %r812, %r813 }, { %r884, %r885 }, { %r2833, %r2834, %r2835, %r2836 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2837, %r2838, %r2839, %r2840 }, { %r810, %r811, %r812, %r813 }, { %r898, %r899 }, { %r2837, %r2838, %r2839, %r2840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2841, %r2842, %r2843, %r2844 }, { %r810, %r811, %r812, %r813 }, { %r912, %r913 }, { %r2841, %r2842, %r2843, %r2844 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2845, %r2846, %r2847, %r2848 }, { %r922, %r923, %r924, %r925 }, { %r814, %r815 }, { %r2845, %r2846, %r2847, %r2848 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2849, %r2850, %r2851, %r2852 }, { %r922, %r923, %r924, %r925 }, { %r828, %r829 }, { %r2849, %r2850, %r2851, %r2852 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2853, %r2854, %r2855, %r2856 }, { %r922, %r923, %r924, %r925 }, { %r842, %r843 }, { %r2853, %r2854, %r2855, %r2856 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2857, %r2858, %r2859, %r2860 }, { %r922, %r923, %r924, %r925 }, { %r856, %r857 }, { %r2857, %r2858, %r2859, %r2860 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2861, %r2862, %r2863, %r2864 }, { %r922, %r923, %r924, %r925 }, { %r870, %r871 }, { %r2861, %r2862, %r2863, %r2864 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2865, %r2866, %r2867, %r2868 }, { %r922, %r923, %r924, %r925 }, { %r884, %r885 }, { %r2865, %r2866, %r2867, %r2868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2869, %r2870, %r2871, %r2872 }, { %r922, %r923, %r924, %r925 }, { %r898, %r899 }, { %r2869, %r2870, %r2871, %r2872 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2873, %r2874, %r2875, %r2876 }, { %r922, %r923, %r924, %r925 }, { %r912, %r913 }, { %r2873, %r2874, %r2875, %r2876 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2877, %r2878, %r2879, %r2880 }, { %r1034, %r1035, %r1036, %r1037 }, { %r814, %r815 }, { %r2877, %r2878, %r2879, %r2880 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2881, %r2882, %r2883, %r2884 }, { %r1034, %r1035, %r1036, %r1037 }, { %r828, %r829 }, { %r2881, %r2882, %r2883, %r2884 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2885, %r2886, %r2887, %r2888 }, { %r1034, %r1035, %r1036, %r1037 }, { %r842, %r843 }, { %r2885, %r2886, %r2887, %r2888 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2889, %r2890, %r2891, %r2892 }, { %r1034, %r1035, %r1036, %r1037 }, { %r856, %r857 }, { %r2889, %r2890, %r2891, %r2892 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2893, %r2894, %r2895, %r2896 }, { %r1034, %r1035, %r1036, %r1037 }, { %r870, %r871 }, { %r2893, %r2894, %r2895, %r2896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2897, %r2898, %r2899, %r2900 }, { %r1034, %r1035, %r1036, %r1037 }, { %r884, %r885 }, { %r2897, %r2898, %r2899, %r2900 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2901, %r2902, %r2903, %r2904 }, { %r1034, %r1035, %r1036, %r1037 }, { %r898, %r899 }, { %r2901, %r2902, %r2903, %r2904 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2905, %r2906, %r2907, %r2908 }, { %r1034, %r1035, %r1036, %r1037 }, { %r912, %r913 }, { %r2905, %r2906, %r2907, %r2908 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2909, %r2910, %r2911, %r2912 }, { %r1146, %r1147, %r1148, %r1149 }, { %r814, %r815 }, { %r2909, %r2910, %r2911, %r2912 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2913, %r2914, %r2915, %r2916 }, { %r1146, %r1147, %r1148, %r1149 }, { %r828, %r829 }, { %r2913, %r2914, %r2915, %r2916 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2917, %r2918, %r2919, %r2920 }, { %r1146, %r1147, %r1148, %r1149 }, { %r842, %r843 }, { %r2917, %r2918, %r2919, %r2920 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2921, %r2922, %r2923, %r2924 }, { %r1146, %r1147, %r1148, %r1149 }, { %r856, %r857 }, { %r2921, %r2922, %r2923, %r2924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2925, %r2926, %r2927, %r2928 }, { %r1146, %r1147, %r1148, %r1149 }, { %r870, %r871 }, { %r2925, %r2926, %r2927, %r2928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2929, %r2930, %r2931, %r2932 }, { %r1146, %r1147, %r1148, %r1149 }, { %r884, %r885 }, { %r2929, %r2930, %r2931, %r2932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2933, %r2934, %r2935, %r2936 }, { %r1146, %r1147, %r1148, %r1149 }, { %r898, %r899 }, { %r2933, %r2934, %r2935, %r2936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2937, %r2938, %r2939, %r2940 }, { %r1146, %r1147, %r1148, %r1149 }, { %r912, %r913 }, { %r2937, %r2938, %r2939, %r2940 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2813, %r2814, %r2815, %r2816 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1262, %r1263 }, { %r2813, %r2814, %r2815, %r2816 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2817, %r2818, %r2819, %r2820 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1276, %r1277 }, { %r2817, %r2818, %r2819, %r2820 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2821, %r2822, %r2823, %r2824 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1290, %r1291 }, { %r2821, %r2822, %r2823, %r2824 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2825, %r2826, %r2827, %r2828 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1304, %r1305 }, { %r2825, %r2826, %r2827, %r2828 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2829, %r2830, %r2831, %r2832 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1318, %r1319 }, { %r2829, %r2830, %r2831, %r2832 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2833, %r2834, %r2835, %r2836 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1332, %r1333 }, { %r2833, %r2834, %r2835, %r2836 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2837, %r2838, %r2839, %r2840 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1346, %r1347 }, { %r2837, %r2838, %r2839, %r2840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2841, %r2842, %r2843, %r2844 }, { %r1258, %r1259, %r1260, %r1261 }, { %r1360, %r1361 }, { %r2841, %r2842, %r2843, %r2844 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2845, %r2846, %r2847, %r2848 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1262, %r1263 }, { %r2845, %r2846, %r2847, %r2848 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2849, %r2850, %r2851, %r2852 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1276, %r1277 }, { %r2849, %r2850, %r2851, %r2852 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2853, %r2854, %r2855, %r2856 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1290, %r1291 }, { %r2853, %r2854, %r2855, %r2856 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2857, %r2858, %r2859, %r2860 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1304, %r1305 }, { %r2857, %r2858, %r2859, %r2860 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2861, %r2862, %r2863, %r2864 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1318, %r1319 }, { %r2861, %r2862, %r2863, %r2864 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2865, %r2866, %r2867, %r2868 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1332, %r1333 }, { %r2865, %r2866, %r2867, %r2868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2869, %r2870, %r2871, %r2872 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1346, %r1347 }, { %r2869, %r2870, %r2871, %r2872 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2873, %r2874, %r2875, %r2876 }, { %r1370, %r1371, %r1372, %r1373 }, { %r1360, %r1361 }, { %r2873, %r2874, %r2875, %r2876 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2877, %r2878, %r2879, %r2880 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1262, %r1263 }, { %r2877, %r2878, %r2879, %r2880 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2881, %r2882, %r2883, %r2884 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1276, %r1277 }, { %r2881, %r2882, %r2883, %r2884 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2885, %r2886, %r2887, %r2888 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1290, %r1291 }, { %r2885, %r2886, %r2887, %r2888 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2889, %r2890, %r2891, %r2892 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1304, %r1305 }, { %r2889, %r2890, %r2891, %r2892 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2893, %r2894, %r2895, %r2896 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1318, %r1319 }, { %r2893, %r2894, %r2895, %r2896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2897, %r2898, %r2899, %r2900 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1332, %r1333 }, { %r2897, %r2898, %r2899, %r2900 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2901, %r2902, %r2903, %r2904 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1346, %r1347 }, { %r2901, %r2902, %r2903, %r2904 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2905, %r2906, %r2907, %r2908 }, { %r1482, %r1483, %r1484, %r1485 }, { %r1360, %r1361 }, { %r2905, %r2906, %r2907, %r2908 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2909, %r2910, %r2911, %r2912 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1262, %r1263 }, { %r2909, %r2910, %r2911, %r2912 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2913, %r2914, %r2915, %r2916 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1276, %r1277 }, { %r2913, %r2914, %r2915, %r2916 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2917, %r2918, %r2919, %r2920 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1290, %r1291 }, { %r2917, %r2918, %r2919, %r2920 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2921, %r2922, %r2923, %r2924 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1304, %r1305 }, { %r2921, %r2922, %r2923, %r2924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2925, %r2926, %r2927, %r2928 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1318, %r1319 }, { %r2925, %r2926, %r2927, %r2928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2929, %r2930, %r2931, %r2932 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1332, %r1333 }, { %r2929, %r2930, %r2931, %r2932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2933, %r2934, %r2935, %r2936 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1346, %r1347 }, { %r2933, %r2934, %r2935, %r2936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2937, %r2938, %r2939, %r2940 }, { %r1594, %r1595, %r1596, %r1597 }, { %r1360, %r1361 }, { %r2937, %r2938, %r2939, %r2940 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2813, %r2814, %r2815, %r2816 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1710, %r1711 }, { %r2813, %r2814, %r2815, %r2816 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2817, %r2818, %r2819, %r2820 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1724, %r1725 }, { %r2817, %r2818, %r2819, %r2820 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2821, %r2822, %r2823, %r2824 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1738, %r1739 }, { %r2821, %r2822, %r2823, %r2824 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2825, %r2826, %r2827, %r2828 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1752, %r1753 }, { %r2825, %r2826, %r2827, %r2828 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2829, %r2830, %r2831, %r2832 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1766, %r1767 }, { %r2829, %r2830, %r2831, %r2832 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2833, %r2834, %r2835, %r2836 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1780, %r1781 }, { %r2833, %r2834, %r2835, %r2836 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2837, %r2838, %r2839, %r2840 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1794, %r1795 }, { %r2837, %r2838, %r2839, %r2840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2841, %r2842, %r2843, %r2844 }, { %r1706, %r1707, %r1708, %r1709 }, { %r1808, %r1809 }, { %r2841, %r2842, %r2843, %r2844 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2845, %r2846, %r2847, %r2848 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1710, %r1711 }, { %r2845, %r2846, %r2847, %r2848 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2849, %r2850, %r2851, %r2852 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1724, %r1725 }, { %r2849, %r2850, %r2851, %r2852 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2853, %r2854, %r2855, %r2856 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1738, %r1739 }, { %r2853, %r2854, %r2855, %r2856 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2857, %r2858, %r2859, %r2860 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1752, %r1753 }, { %r2857, %r2858, %r2859, %r2860 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2861, %r2862, %r2863, %r2864 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1766, %r1767 }, { %r2861, %r2862, %r2863, %r2864 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2865, %r2866, %r2867, %r2868 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1780, %r1781 }, { %r2865, %r2866, %r2867, %r2868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2869, %r2870, %r2871, %r2872 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1794, %r1795 }, { %r2869, %r2870, %r2871, %r2872 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2873, %r2874, %r2875, %r2876 }, { %r1818, %r1819, %r1820, %r1821 }, { %r1808, %r1809 }, { %r2873, %r2874, %r2875, %r2876 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2877, %r2878, %r2879, %r2880 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1710, %r1711 }, { %r2877, %r2878, %r2879, %r2880 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2881, %r2882, %r2883, %r2884 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1724, %r1725 }, { %r2881, %r2882, %r2883, %r2884 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2885, %r2886, %r2887, %r2888 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1738, %r1739 }, { %r2885, %r2886, %r2887, %r2888 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2889, %r2890, %r2891, %r2892 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1752, %r1753 }, { %r2889, %r2890, %r2891, %r2892 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2893, %r2894, %r2895, %r2896 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1766, %r1767 }, { %r2893, %r2894, %r2895, %r2896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2897, %r2898, %r2899, %r2900 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1780, %r1781 }, { %r2897, %r2898, %r2899, %r2900 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2901, %r2902, %r2903, %r2904 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1794, %r1795 }, { %r2901, %r2902, %r2903, %r2904 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2905, %r2906, %r2907, %r2908 }, { %r1930, %r1931, %r1932, %r1933 }, { %r1808, %r1809 }, { %r2905, %r2906, %r2907, %r2908 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2909, %r2910, %r2911, %r2912 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1710, %r1711 }, { %r2909, %r2910, %r2911, %r2912 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2913, %r2914, %r2915, %r2916 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1724, %r1725 }, { %r2913, %r2914, %r2915, %r2916 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2917, %r2918, %r2919, %r2920 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1738, %r1739 }, { %r2917, %r2918, %r2919, %r2920 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2921, %r2922, %r2923, %r2924 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1752, %r1753 }, { %r2921, %r2922, %r2923, %r2924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2925, %r2926, %r2927, %r2928 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1766, %r1767 }, { %r2925, %r2926, %r2927, %r2928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2929, %r2930, %r2931, %r2932 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1780, %r1781 }, { %r2929, %r2930, %r2931, %r2932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2933, %r2934, %r2935, %r2936 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1794, %r1795 }, { %r2933, %r2934, %r2935, %r2936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2937, %r2938, %r2939, %r2940 }, { %r2042, %r2043, %r2044, %r2045 }, { %r1808, %r1809 }, { %r2937, %r2938, %r2939, %r2940 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2813, %r2814, %r2815, %r2816 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2158, %r2159 }, { %r2813, %r2814, %r2815, %r2816 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2817, %r2818, %r2819, %r2820 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2172, %r2173 }, { %r2817, %r2818, %r2819, %r2820 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2821, %r2822, %r2823, %r2824 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2186, %r2187 }, { %r2821, %r2822, %r2823, %r2824 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2825, %r2826, %r2827, %r2828 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2200, %r2201 }, { %r2825, %r2826, %r2827, %r2828 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2829, %r2830, %r2831, %r2832 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2214, %r2215 }, { %r2829, %r2830, %r2831, %r2832 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2833, %r2834, %r2835, %r2836 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2228, %r2229 }, { %r2833, %r2834, %r2835, %r2836 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2837, %r2838, %r2839, %r2840 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2242, %r2243 }, { %r2837, %r2838, %r2839, %r2840 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2841, %r2842, %r2843, %r2844 }, { %r2154, %r2155, %r2156, %r2157 }, { %r2256, %r2257 }, { %r2841, %r2842, %r2843, %r2844 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2845, %r2846, %r2847, %r2848 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2158, %r2159 }, { %r2845, %r2846, %r2847, %r2848 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2849, %r2850, %r2851, %r2852 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2172, %r2173 }, { %r2849, %r2850, %r2851, %r2852 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2853, %r2854, %r2855, %r2856 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2186, %r2187 }, { %r2853, %r2854, %r2855, %r2856 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2857, %r2858, %r2859, %r2860 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2200, %r2201 }, { %r2857, %r2858, %r2859, %r2860 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2861, %r2862, %r2863, %r2864 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2214, %r2215 }, { %r2861, %r2862, %r2863, %r2864 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2865, %r2866, %r2867, %r2868 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2228, %r2229 }, { %r2865, %r2866, %r2867, %r2868 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2869, %r2870, %r2871, %r2872 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2242, %r2243 }, { %r2869, %r2870, %r2871, %r2872 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2873, %r2874, %r2875, %r2876 }, { %r2266, %r2267, %r2268, %r2269 }, { %r2256, %r2257 }, { %r2873, %r2874, %r2875, %r2876 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2877, %r2878, %r2879, %r2880 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2158, %r2159 }, { %r2877, %r2878, %r2879, %r2880 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2881, %r2882, %r2883, %r2884 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2172, %r2173 }, { %r2881, %r2882, %r2883, %r2884 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2885, %r2886, %r2887, %r2888 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2186, %r2187 }, { %r2885, %r2886, %r2887, %r2888 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2889, %r2890, %r2891, %r2892 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2200, %r2201 }, { %r2889, %r2890, %r2891, %r2892 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2893, %r2894, %r2895, %r2896 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2214, %r2215 }, { %r2893, %r2894, %r2895, %r2896 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2897, %r2898, %r2899, %r2900 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2228, %r2229 }, { %r2897, %r2898, %r2899, %r2900 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2901, %r2902, %r2903, %r2904 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2242, %r2243 }, { %r2901, %r2902, %r2903, %r2904 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2905, %r2906, %r2907, %r2908 }, { %r2378, %r2379, %r2380, %r2381 }, { %r2256, %r2257 }, { %r2905, %r2906, %r2907, %r2908 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2909, %r2910, %r2911, %r2912 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2158, %r2159 }, { %r2909, %r2910, %r2911, %r2912 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2913, %r2914, %r2915, %r2916 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2172, %r2173 }, { %r2913, %r2914, %r2915, %r2916 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2917, %r2918, %r2919, %r2920 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2186, %r2187 }, { %r2917, %r2918, %r2919, %r2920 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2921, %r2922, %r2923, %r2924 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2200, %r2201 }, { %r2921, %r2922, %r2923, %r2924 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2925, %r2926, %r2927, %r2928 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2214, %r2215 }, { %r2925, %r2926, %r2927, %r2928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2929, %r2930, %r2931, %r2932 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2228, %r2229 }, { %r2929, %r2930, %r2931, %r2932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2933, %r2934, %r2935, %r2936 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2242, %r2243 }, { %r2933, %r2934, %r2935, %r2936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %r2937, %r2938, %r2939, %r2940 }, { %r2490, %r2491, %r2492, %r2493 }, { %r2256, %r2257 }, { %r2937, %r2938, %r2939, %r2940 };
	// end inline asm
	.loc	1 129 18                        // gated_mlp.py:129:18
	add.s64 	%rd69, %rd127, %rd19;
	add.s64 	%rd70, %rd127, %rd18;
	add.s64 	%rd71, %rd127, %rd17;
	add.s64 	%rd72, %rd127, %rd16;
	add.s64 	%rd73, %rd127, %rd15;
	add.s64 	%rd74, %rd127, %rd14;
	add.s64 	%rd75, %rd127, %rd13;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s64 	%rd76, %rd127, %rd10;
	add.s32 	%r2656, %r2812, 1;
	setp.gt.s32 	%p23, %r2656, 1;
	selp.b32 	%r2812, 0, %r2656, %p23;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p24, %r7, %r2810;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shl.b32 	%r2657, %r2812, 14;
	add.s32 	%r2658, %r2621, %r2657;
	bar.sync 	0;
	add.s32 	%r2594, %r2658, %r540;
	add.s32 	%r2596, %r2594, 4096;
	add.s32 	%r2598, %r2594, 8192;
	add.s32 	%r2600, %r2594, 12288;
	selp.b32 	%r2660, 16, 0, %p24;
	selp.b32 	%r2597, %r2660, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2594 + 0 ], [ %rd126 + 0 ], 0x10, %r2597;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2596 + 0 ], [ %rd126 + 0 ], 0x10, %r2597;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2598 + 0 ], [ %rd126 + 0 ], 0x10, %r2597;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2600 + 0 ], [ %rd126 + 0 ], 0x10, %r2597;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p25, %r12, %r2810;
	setp.lt.s32 	%p26, %r13, %r2810;
	setp.lt.s32 	%p27, %r14, %r2810;
	setp.lt.s32 	%p28, %r15, %r2810;
	setp.lt.s32 	%p29, %r16, %r2810;
	setp.lt.s32 	%p30, %r17, %r2810;
	setp.lt.s32 	%p31, %r18, %r2810;
	setp.lt.s32 	%p32, %r19, %r2810;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r2661, %r2812, 15;
	add.s32 	%r2662, %r541, %r2661;
	add.s32 	%r2602, %r2662, %r546;
	add.s32 	%r2604, %r2602, 4096;
	add.s32 	%r2606, %r2602, 8192;
	add.s32 	%r2608, %r2602, 12288;
	add.s32 	%r2610, %r2602, 16384;
	add.s32 	%r2612, %r2602, 20480;
	add.s32 	%r2614, %r2602, 24576;
	add.s32 	%r2616, %r2602, 28672;
	selp.b32 	%r2664, 16, 0, %p25;
	selp.b32 	%r2603, %r2664, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2602 + 0 ], [ %rd69 + 0 ], 0x10, %r2603;
	// end inline asm
	selp.b32 	%r2665, 16, 0, %p26;
	selp.b32 	%r2605, %r2665, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2604 + 0 ], [ %rd70 + 0 ], 0x10, %r2605;
	// end inline asm
	selp.b32 	%r2666, 16, 0, %p27;
	selp.b32 	%r2607, %r2666, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2606 + 0 ], [ %rd71 + 0 ], 0x10, %r2607;
	// end inline asm
	selp.b32 	%r2667, 16, 0, %p28;
	selp.b32 	%r2609, %r2667, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2608 + 0 ], [ %rd72 + 0 ], 0x10, %r2609;
	// end inline asm
	selp.b32 	%r2668, 16, 0, %p29;
	selp.b32 	%r2611, %r2668, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2610 + 0 ], [ %rd73 + 0 ], 0x10, %r2611;
	// end inline asm
	selp.b32 	%r2669, 16, 0, %p30;
	selp.b32 	%r2613, %r2669, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2612 + 0 ], [ %rd74 + 0 ], 0x10, %r2613;
	// end inline asm
	selp.b32 	%r2670, 16, 0, %p31;
	selp.b32 	%r2615, %r2670, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2614 + 0 ], [ %rd75 + 0 ], 0x10, %r2615;
	// end inline asm
	selp.b32 	%r2671, 16, 0, %p32;
	selp.b32 	%r2617, %r2671, 0, %p21;
	// begin inline asm
	cp.async.cg.shared.global [ %r2616 + 0 ], [ %rd76 + 0 ], 0x10, %r2617;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s32 	%r2941, %r2941, 1;
	add.s64 	%rd127, %rd127, %rd12;
	add.s64 	%rd126, %rd126, 128;
	add.s32 	%r2810, %r2810, -64;
	setp.ne.s32 	%p33, %r20, %r2941;
	@%p33 bra 	$L__BB0_3;
// %bb.4:                               // %._crit_edge.loopexit
	.loc	1 134 23                        // gated_mlp.py:134:23
	cvt.rn.f16x2.f32 	%r3007, %r2940, %r2939;
	cvt.rn.f16x2.f32 	%r3006, %r2938, %r2937;
	cvt.rn.f16x2.f32 	%r3005, %r2936, %r2935;
	cvt.rn.f16x2.f32 	%r3004, %r2934, %r2933;
	cvt.rn.f16x2.f32 	%r3003, %r2932, %r2931;
	cvt.rn.f16x2.f32 	%r3002, %r2930, %r2929;
	cvt.rn.f16x2.f32 	%r3001, %r2928, %r2927;
	cvt.rn.f16x2.f32 	%r3000, %r2926, %r2925;
	cvt.rn.f16x2.f32 	%r2999, %r2924, %r2923;
	cvt.rn.f16x2.f32 	%r2998, %r2922, %r2921;
	cvt.rn.f16x2.f32 	%r2997, %r2920, %r2919;
	cvt.rn.f16x2.f32 	%r2996, %r2918, %r2917;
	cvt.rn.f16x2.f32 	%r2995, %r2916, %r2915;
	cvt.rn.f16x2.f32 	%r2994, %r2914, %r2913;
	cvt.rn.f16x2.f32 	%r2993, %r2912, %r2911;
	cvt.rn.f16x2.f32 	%r2992, %r2910, %r2909;
	cvt.rn.f16x2.f32 	%r2991, %r2908, %r2907;
	cvt.rn.f16x2.f32 	%r2990, %r2906, %r2905;
	cvt.rn.f16x2.f32 	%r2989, %r2904, %r2903;
	cvt.rn.f16x2.f32 	%r2988, %r2902, %r2901;
	cvt.rn.f16x2.f32 	%r2987, %r2900, %r2899;
	cvt.rn.f16x2.f32 	%r2986, %r2898, %r2897;
	cvt.rn.f16x2.f32 	%r2985, %r2896, %r2895;
	cvt.rn.f16x2.f32 	%r2984, %r2894, %r2893;
	cvt.rn.f16x2.f32 	%r2983, %r2892, %r2891;
	cvt.rn.f16x2.f32 	%r2982, %r2890, %r2889;
	cvt.rn.f16x2.f32 	%r2981, %r2888, %r2887;
	cvt.rn.f16x2.f32 	%r2980, %r2886, %r2885;
	cvt.rn.f16x2.f32 	%r2979, %r2884, %r2883;
	cvt.rn.f16x2.f32 	%r2978, %r2882, %r2881;
	cvt.rn.f16x2.f32 	%r2977, %r2880, %r2879;
	cvt.rn.f16x2.f32 	%r2976, %r2878, %r2877;
	cvt.rn.f16x2.f32 	%r2975, %r2876, %r2875;
	cvt.rn.f16x2.f32 	%r2974, %r2874, %r2873;
	cvt.rn.f16x2.f32 	%r2973, %r2872, %r2871;
	cvt.rn.f16x2.f32 	%r2972, %r2870, %r2869;
	cvt.rn.f16x2.f32 	%r2971, %r2868, %r2867;
	cvt.rn.f16x2.f32 	%r2970, %r2866, %r2865;
	cvt.rn.f16x2.f32 	%r2969, %r2864, %r2863;
	cvt.rn.f16x2.f32 	%r2968, %r2862, %r2861;
	cvt.rn.f16x2.f32 	%r2967, %r2860, %r2859;
	cvt.rn.f16x2.f32 	%r2966, %r2858, %r2857;
	cvt.rn.f16x2.f32 	%r2965, %r2856, %r2855;
	cvt.rn.f16x2.f32 	%r2964, %r2854, %r2853;
	cvt.rn.f16x2.f32 	%r2963, %r2852, %r2851;
	cvt.rn.f16x2.f32 	%r2962, %r2850, %r2849;
	cvt.rn.f16x2.f32 	%r2961, %r2848, %r2847;
	cvt.rn.f16x2.f32 	%r2960, %r2846, %r2845;
	cvt.rn.f16x2.f32 	%r2959, %r2844, %r2843;
	cvt.rn.f16x2.f32 	%r2958, %r2842, %r2841;
	cvt.rn.f16x2.f32 	%r2957, %r2840, %r2839;
	cvt.rn.f16x2.f32 	%r2956, %r2838, %r2837;
	cvt.rn.f16x2.f32 	%r2955, %r2836, %r2835;
	cvt.rn.f16x2.f32 	%r2954, %r2834, %r2833;
	cvt.rn.f16x2.f32 	%r2953, %r2832, %r2831;
	cvt.rn.f16x2.f32 	%r2952, %r2830, %r2829;
	cvt.rn.f16x2.f32 	%r2951, %r2828, %r2827;
	cvt.rn.f16x2.f32 	%r2950, %r2826, %r2825;
	cvt.rn.f16x2.f32 	%r2949, %r2824, %r2823;
	cvt.rn.f16x2.f32 	%r2948, %r2822, %r2821;
	cvt.rn.f16x2.f32 	%r2947, %r2820, %r2819;
	cvt.rn.f16x2.f32 	%r2946, %r2818, %r2817;
	cvt.rn.f16x2.f32 	%r2945, %r2816, %r2815;
	cvt.rn.f16x2.f32 	%r2944, %r2814, %r2813;
	bra.uni 	$L__BB0_5;
$L__BB0_1:                              // %.._crit_edge_crit_edge
	.loc	1 142 21                        // gated_mlp.py:142:21
	shl.b32 	%r2943, %r5, 6;
	and.b32 	%r2942, %r22, 24;
	mov.b32 	%r2944, 0;
	mov.b32 	%r2945, %r2944;
	mov.b32 	%r2946, %r2944;
	mov.b32 	%r2947, %r2944;
	mov.b32 	%r2948, %r2944;
	mov.b32 	%r2949, %r2944;
	mov.b32 	%r2950, %r2944;
	mov.b32 	%r2951, %r2944;
	mov.b32 	%r2952, %r2944;
	mov.b32 	%r2953, %r2944;
	mov.b32 	%r2954, %r2944;
	mov.b32 	%r2955, %r2944;
	mov.b32 	%r2956, %r2944;
	mov.b32 	%r2957, %r2944;
	mov.b32 	%r2958, %r2944;
	mov.b32 	%r2959, %r2944;
	mov.b32 	%r2960, %r2944;
	mov.b32 	%r2961, %r2944;
	mov.b32 	%r2962, %r2944;
	mov.b32 	%r2963, %r2944;
	mov.b32 	%r2964, %r2944;
	mov.b32 	%r2965, %r2944;
	mov.b32 	%r2966, %r2944;
	mov.b32 	%r2967, %r2944;
	mov.b32 	%r2968, %r2944;
	mov.b32 	%r2969, %r2944;
	mov.b32 	%r2970, %r2944;
	mov.b32 	%r2971, %r2944;
	mov.b32 	%r2972, %r2944;
	mov.b32 	%r2973, %r2944;
	mov.b32 	%r2974, %r2944;
	mov.b32 	%r2975, %r2944;
	mov.b32 	%r2976, %r2944;
	mov.b32 	%r2977, %r2944;
	mov.b32 	%r2978, %r2944;
	mov.b32 	%r2979, %r2944;
	mov.b32 	%r2980, %r2944;
	mov.b32 	%r2981, %r2944;
	mov.b32 	%r2982, %r2944;
	mov.b32 	%r2983, %r2944;
	mov.b32 	%r2984, %r2944;
	mov.b32 	%r2985, %r2944;
	mov.b32 	%r2986, %r2944;
	mov.b32 	%r2987, %r2944;
	mov.b32 	%r2988, %r2944;
	mov.b32 	%r2989, %r2944;
	mov.b32 	%r2990, %r2944;
	mov.b32 	%r2991, %r2944;
	mov.b32 	%r2992, %r2944;
	mov.b32 	%r2993, %r2944;
	mov.b32 	%r2994, %r2944;
	mov.b32 	%r2995, %r2944;
	mov.b32 	%r2996, %r2944;
	mov.b32 	%r2997, %r2944;
	mov.b32 	%r2998, %r2944;
	mov.b32 	%r2999, %r2944;
	mov.b32 	%r3000, %r2944;
	mov.b32 	%r3001, %r2944;
	mov.b32 	%r3002, %r2944;
	mov.b32 	%r3003, %r2944;
	mov.b32 	%r3004, %r2944;
	mov.b32 	%r3005, %r2944;
	mov.b32 	%r3006, %r2944;
	mov.b32 	%r3007, %r2944;
$L__BB0_5:                              // %._crit_edge
	.loc	1 98 54                         // gated_mlp.py:98:54
	mul.lo.s32 	%r2736, %r4, %r2;
	sub.s32 	%r2737, %r3, %r2736;
	.loc	1 98 27                         // gated_mlp.py:98:27
	add.s32 	%r2738, %r2737, %r1;
	.loc	1 120 22                        // gated_mlp.py:120:22
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 138 22                        // gated_mlp.py:138:22
	shl.b32 	%r2739, %r2738, 7;
	.loc	1 138 37                        // gated_mlp.py:138:37
	or.b32 	%r2740, %r2739, %r12;
	or.b32 	%r2741, %r2739, %r13;
	or.b32 	%r2742, %r2739, %r14;
	or.b32 	%r2743, %r2739, %r15;
	or.b32 	%r2744, %r2739, %r16;
	or.b32 	%r2745, %r2739, %r17;
	or.b32 	%r2746, %r2739, %r18;
	or.b32 	%r2747, %r2739, %r19;
	or.b32 	%r2748, %r11, %r2739;
	or.b32 	%r2749, %r2748, 88;
	or.b32 	%r2750, %r2748, 120;
	.loc	1 140 33                        // gated_mlp.py:140:33
	mul.lo.s32 	%r2751, %r2740, %r458;
	mul.lo.s32 	%r2752, %r2741, %r458;
	mul.lo.s32 	%r2753, %r2742, %r458;
	mul.lo.s32 	%r2754, %r2743, %r458;
	mul.lo.s32 	%r2755, %r2744, %r458;
	mul.lo.s32 	%r2756, %r2745, %r458;
	mul.lo.s32 	%r2757, %r2746, %r458;
	mul.lo.s32 	%r2758, %r2747, %r458;
	shl.b32 	%r2759, %r458, 6;
	add.s32 	%r2760, %r2751, %r2759;
	shl.b32 	%r2761, %r458, 3;
	add.s32 	%r2762, %r2760, %r2761;
	add.s32 	%r2763, %r2762, %r2761;
	mul.lo.s32 	%r2764, %r2749, %r458;
	shl.b32 	%r2765, %r458, 4;
	add.s32 	%r2766, %r2763, %r2765;
	add.s32 	%r2767, %r2766, %r2761;
	add.s32 	%r2768, %r2767, %r2761;
	mul.lo.s32 	%r2769, %r2750, %r458;
	.loc	1 140 21                        // gated_mlp.py:140:21
	mul.wide.s32 	%rd93, %r2751, 2;
	add.s64 	%rd94, %rd27, %rd93;
	mul.wide.s32 	%rd95, %r2752, 2;
	add.s64 	%rd96, %rd27, %rd95;
	mul.wide.s32 	%rd97, %r2753, 2;
	add.s64 	%rd98, %rd27, %rd97;
	mul.wide.s32 	%rd99, %r2754, 2;
	add.s64 	%rd100, %rd27, %rd99;
	mul.wide.s32 	%rd101, %r2755, 2;
	add.s64 	%rd102, %rd27, %rd101;
	mul.wide.s32 	%rd103, %r2756, 2;
	add.s64 	%rd104, %rd27, %rd103;
	mul.wide.s32 	%rd105, %r2757, 2;
	add.s64 	%rd106, %rd27, %rd105;
	mul.wide.s32 	%rd107, %r2758, 2;
	add.s64 	%rd108, %rd27, %rd107;
	mul.wide.s32 	%rd109, %r2760, 2;
	add.s64 	%rd110, %rd27, %rd109;
	mul.wide.s32 	%rd111, %r2762, 2;
	add.s64 	%rd112, %rd27, %rd111;
	mul.wide.s32 	%rd113, %r2763, 2;
	add.s64 	%rd114, %rd27, %rd113;
	mul.wide.s32 	%rd115, %r2764, 2;
	add.s64 	%rd116, %rd27, %rd115;
	mul.wide.s32 	%rd117, %r2766, 2;
	add.s64 	%rd118, %rd27, %rd117;
	mul.wide.s32 	%rd119, %r2767, 2;
	add.s64 	%rd120, %rd27, %rd119;
	mul.wide.s32 	%rd121, %r2768, 2;
	add.s64 	%rd122, %rd27, %rd121;
	mul.wide.s32 	%rd123, %r2769, 2;
	add.s64 	%rd124, %rd27, %rd123;
	.loc	1 140 52                        // gated_mlp.py:140:52
	mul.wide.s32 	%rd125, %r9, 2;
	add.s64 	%rd77, %rd94, %rd125;
	add.s64 	%rd78, %rd96, %rd125;
	add.s64 	%rd79, %rd98, %rd125;
	add.s64 	%rd80, %rd100, %rd125;
	add.s64 	%rd81, %rd102, %rd125;
	add.s64 	%rd82, %rd104, %rd125;
	add.s64 	%rd83, %rd106, %rd125;
	add.s64 	%rd84, %rd108, %rd125;
	add.s64 	%rd85, %rd110, %rd125;
	add.s64 	%rd86, %rd112, %rd125;
	add.s64 	%rd87, %rd114, %rd125;
	add.s64 	%rd88, %rd116, %rd125;
	add.s64 	%rd89, %rd118, %rd125;
	add.s64 	%rd90, %rd120, %rd125;
	add.s64 	%rd91, %rd122, %rd125;
	add.s64 	%rd92, %rd124, %rd125;
	.loc	1 141 33                        // gated_mlp.py:141:33
	setp.lt.s32 	%p50, %r2740, 1;
	setp.lt.s32 	%p51, %r2741, 1;
	setp.lt.s32 	%p52, %r2742, 1;
	setp.lt.s32 	%p53, %r2743, 1;
	setp.lt.s32 	%p54, %r2744, 1;
	setp.lt.s32 	%p55, %r2745, 1;
	setp.lt.s32 	%p56, %r2746, 1;
	setp.lt.s32 	%p57, %r2747, 1;
	setp.lt.s32 	%p58, %r2739, 0;
	.loc	1 141 58                        // gated_mlp.py:141:58
	setp.lt.s32 	%p59, %r9, %r456;
	.loc	1 141 39                        // gated_mlp.py:141:39
	and.pred 	%p34, %p59, %p50;
	and.pred 	%p35, %p59, %p51;
	and.pred 	%p36, %p59, %p52;
	and.pred 	%p37, %p59, %p53;
	and.pred 	%p38, %p59, %p54;
	and.pred 	%p39, %p59, %p55;
	and.pred 	%p40, %p59, %p56;
	and.pred 	%p41, %p59, %p57;
	and.pred 	%p42, %p59, %p58;
	.loc	1 142 21                        // gated_mlp.py:142:21
	shl.b32 	%r2770, %r5, 1;
	and.b32 	%r2771, %r2770, 6;
	and.b32 	%r2772, %r2943, 768;
	or.b32 	%r2773, %r2772, %r2771;
	shl.b32 	%r2774, %r8, 6;
	or.b32 	%r2775, %r2773, %r2774;
	shl.b32 	%r2776, %r10, 5;
	or.b32 	%r2777, %r2775, %r2776;
	or.b32 	%r2778, %r2942, %r2777;
	and.b32 	%r2779, %r6, 2040;
	shr.u32 	%r2780, %r2777, 4;
	add.s32 	%r2782, %r541, %r2780;
	shl.b32 	%r2783, %r2778, 1;
	add.s32 	%r2784, %r2782, %r2783;
	st.shared.b32 	[%r2784], %r2944;
	or.b32 	%r2785, %r2777, 2048;
	shr.u32 	%r2786, %r2785, 4;
	and.b32 	%r2787, %r2786, 496;
	add.s32 	%r2788, %r541, %r2787;
	add.s32 	%r2789, %r2788, %r2783;
	st.shared.b32 	[%r2789+4096], %r2945;
	st.shared.b32 	[%r2784+64], %r2946;
	st.shared.b32 	[%r2789+4160], %r2947;
	st.shared.b32 	[%r2784+128], %r2948;
	st.shared.b32 	[%r2789+4224], %r2949;
	st.shared.b32 	[%r2784+192], %r2950;
	st.shared.b32 	[%r2789+4288], %r2951;
	st.shared.b32 	[%r2784+256], %r2952;
	st.shared.b32 	[%r2789+4352], %r2953;
	st.shared.b32 	[%r2784+320], %r2954;
	st.shared.b32 	[%r2789+4416], %r2955;
	st.shared.b32 	[%r2784+384], %r2956;
	st.shared.b32 	[%r2789+4480], %r2957;
	st.shared.b32 	[%r2784+448], %r2958;
	st.shared.b32 	[%r2789+4544], %r2959;
	bar.sync 	0;
	shl.b32 	%r2790, %r23, 1;
	add.s32 	%r2791, %r541, %r2790;
	shl.b32 	%r2792, %r2779, 1;
	add.s32 	%r2793, %r2791, %r2792;
	ld.shared.v4.b32 	{%r2672, %r2673, %r2674, %r2675}, [%r2793];
	or.b32 	%r2794, %r2779, 2048;
	shr.u32 	%r2795, %r2794, 4;
	and.b32 	%r2796, %r2795, 240;
	add.s32 	%r2797, %r541, %r2796;
	add.s32 	%r2798, %r2797, %r2792;
	ld.shared.v4.b32 	{%r2676, %r2677, %r2678, %r2679}, [%r2798+4096];
	or.b32 	%r2799, %r2779, 4096;
	shr.u32 	%r2800, %r2799, 4;
	and.b32 	%r2801, %r2800, 368;
	add.s32 	%r2802, %r541, %r2801;
	add.s32 	%r2803, %r2802, %r2792;
	ld.shared.v4.b32 	{%r2680, %r2681, %r2682, %r2683}, [%r2803+8192];
	or.b32 	%r2804, %r6, 6144;
	shr.u32 	%r2805, %r2804, 4;
	and.b32 	%r2806, %r2805, 496;
	add.s32 	%r2807, %r541, %r2806;
	shl.b32 	%r2808, %r2804, 1;
	add.s32 	%r2809, %r2807, %r2808;
	ld.shared.v4.b32 	{%r2684, %r2685, %r2686, %r2687}, [%r2809];
	bar.sync 	0;
	st.shared.b32 	[%r2784], %r2960;
	st.shared.b32 	[%r2789+4096], %r2961;
	st.shared.b32 	[%r2784+64], %r2962;
	st.shared.b32 	[%r2789+4160], %r2963;
	st.shared.b32 	[%r2784+128], %r2964;
	st.shared.b32 	[%r2789+4224], %r2965;
	st.shared.b32 	[%r2784+192], %r2966;
	st.shared.b32 	[%r2789+4288], %r2967;
	st.shared.b32 	[%r2784+256], %r2968;
	st.shared.b32 	[%r2789+4352], %r2969;
	st.shared.b32 	[%r2784+320], %r2970;
	st.shared.b32 	[%r2789+4416], %r2971;
	st.shared.b32 	[%r2784+384], %r2972;
	st.shared.b32 	[%r2789+4480], %r2973;
	st.shared.b32 	[%r2784+448], %r2974;
	st.shared.b32 	[%r2789+4544], %r2975;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2688, %r2689, %r2690, %r2691}, [%r2793];
	ld.shared.v4.b32 	{%r2692, %r2693, %r2694, %r2695}, [%r2798+4096];
	ld.shared.v4.b32 	{%r2696, %r2697, %r2698, %r2699}, [%r2803+8192];
	ld.shared.v4.b32 	{%r2700, %r2701, %r2702, %r2703}, [%r2809];
	bar.sync 	0;
	st.shared.b32 	[%r2784], %r2976;
	st.shared.b32 	[%r2789+4096], %r2977;
	st.shared.b32 	[%r2784+64], %r2978;
	st.shared.b32 	[%r2789+4160], %r2979;
	st.shared.b32 	[%r2784+128], %r2980;
	st.shared.b32 	[%r2789+4224], %r2981;
	st.shared.b32 	[%r2784+192], %r2982;
	st.shared.b32 	[%r2789+4288], %r2983;
	st.shared.b32 	[%r2784+256], %r2984;
	st.shared.b32 	[%r2789+4352], %r2985;
	st.shared.b32 	[%r2784+320], %r2986;
	st.shared.b32 	[%r2789+4416], %r2987;
	st.shared.b32 	[%r2784+384], %r2988;
	st.shared.b32 	[%r2789+4480], %r2989;
	st.shared.b32 	[%r2784+448], %r2990;
	st.shared.b32 	[%r2789+4544], %r2991;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2704, %r2705, %r2706, %r2707}, [%r2793];
	ld.shared.v4.b32 	{%r2708, %r2709, %r2710, %r2711}, [%r2798+4096];
	ld.shared.v4.b32 	{%r2712, %r2713, %r2714, %r2715}, [%r2803+8192];
	ld.shared.v4.b32 	{%r2716, %r2717, %r2718, %r2719}, [%r2809];
	bar.sync 	0;
	st.shared.b32 	[%r2784], %r2992;
	st.shared.b32 	[%r2789+4096], %r2993;
	st.shared.b32 	[%r2784+64], %r2994;
	st.shared.b32 	[%r2789+4160], %r2995;
	st.shared.b32 	[%r2784+128], %r2996;
	st.shared.b32 	[%r2789+4224], %r2997;
	st.shared.b32 	[%r2784+192], %r2998;
	st.shared.b32 	[%r2789+4288], %r2999;
	st.shared.b32 	[%r2784+256], %r3000;
	st.shared.b32 	[%r2789+4352], %r3001;
	st.shared.b32 	[%r2784+320], %r3002;
	st.shared.b32 	[%r2789+4416], %r3003;
	st.shared.b32 	[%r2784+384], %r3004;
	st.shared.b32 	[%r2789+4480], %r3005;
	st.shared.b32 	[%r2784+448], %r3006;
	st.shared.b32 	[%r2789+4544], %r3007;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2720, %r2721, %r2722, %r2723}, [%r2793];
	ld.shared.v4.b32 	{%r2724, %r2725, %r2726, %r2727}, [%r2798+4096];
	ld.shared.v4.b32 	{%r2728, %r2729, %r2730, %r2731}, [%r2803+8192];
	ld.shared.v4.b32 	{%r2732, %r2733, %r2734, %r2735}, [%r2809];
	// begin inline asm
	@%p34 st.global.v4.b32 [ %rd77 + 0 ], { %r2672, %r2673, %r2674, %r2675 };
	// end inline asm
	// begin inline asm
	@%p35 st.global.v4.b32 [ %rd78 + 0 ], { %r2676, %r2677, %r2678, %r2679 };
	// end inline asm
	// begin inline asm
	@%p36 st.global.v4.b32 [ %rd79 + 0 ], { %r2680, %r2681, %r2682, %r2683 };
	// end inline asm
	// begin inline asm
	@%p37 st.global.v4.b32 [ %rd80 + 0 ], { %r2684, %r2685, %r2686, %r2687 };
	// end inline asm
	// begin inline asm
	@%p38 st.global.v4.b32 [ %rd81 + 0 ], { %r2688, %r2689, %r2690, %r2691 };
	// end inline asm
	// begin inline asm
	@%p39 st.global.v4.b32 [ %rd82 + 0 ], { %r2692, %r2693, %r2694, %r2695 };
	// end inline asm
	// begin inline asm
	@%p40 st.global.v4.b32 [ %rd83 + 0 ], { %r2696, %r2697, %r2698, %r2699 };
	// end inline asm
	// begin inline asm
	@%p41 st.global.v4.b32 [ %rd84 + 0 ], { %r2700, %r2701, %r2702, %r2703 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd85 + 0 ], { %r2704, %r2705, %r2706, %r2707 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd86 + 0 ], { %r2708, %r2709, %r2710, %r2711 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd87 + 0 ], { %r2712, %r2713, %r2714, %r2715 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd88 + 0 ], { %r2716, %r2717, %r2718, %r2719 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd89 + 0 ], { %r2720, %r2721, %r2722, %r2723 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd90 + 0 ], { %r2724, %r2725, %r2726, %r2727 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd91 + 0 ], { %r2728, %r2729, %r2730, %r2731 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd92 + 0 ], { %r2732, %r2733, %r2734, %r2735 };
	// end inline asm
	.loc	1 142 4                         // gated_mlp.py:142:4
	ret;
$L__tmp5:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/anjiang/PTX_dataset/triton_ptx/gated_mlp.py"
	.file	2 "/mnt/efs/anjiang/miniconda3/envs/ptx/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 165                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x9e DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 103                                 // DW_AT_name
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 109
.b8 108
.b8 112
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 97
.b8 110
.b8 106
.b8 105
.b8 97
.b8 110
.b8 103
.b8 47
.b8 80
.b8 84
.b8 88
.b8 95
.b8 100
.b8 97
.b8 116
.b8 97
.b8 115
.b8 101
.b8 116
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 112
.b8 116
.b8 120
.b8 0
.b8 2                                   // Abbrev [2] 0x52:0x10 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x62:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 82                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x77:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 93                                  // DW_AT_call_line
.b8 27                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x8f:0x18 DW_TAG_inlined_subroutine
.b32 82                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp4                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 120                                 // DW_AT_call_line
.b8 33                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
