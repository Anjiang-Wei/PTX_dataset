//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	matmul_kernel           // -- Begin function matmul_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel
.visible .entry matmul_kernel(
	.param .u64 .ptr .global .align 1 matmul_kernel_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_8
)
.reqntid 128
{
	.reg .pred 	%p<37>;
	.reg .b32 	%r<884>;
	.reg .b64 	%rd<103>;
	.loc	1 68 0                          // gated_mlp.py:68:0
$L__func_begin0:
	.loc	1 68 0                          // gated_mlp.py:68:0

// %bb.0:
	ld.param.b32 	%r135, [matmul_kernel_param_7];
	ld.param.b32 	%r134, [matmul_kernel_param_4];
	ld.param.b32 	%r133, [matmul_kernel_param_3];
	ld.param.b64 	%rd12, [matmul_kernel_param_2];
	ld.param.b64 	%rd11, [matmul_kernel_param_0];
	ld.param.b64 	%rd43, [matmul_kernel_param_1];
$L__tmp0:
	.loc	1 91 24                         // gated_mlp.py:91:24
	mov.u32 	%r197, %ctaid.x;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:93:27 ]
	add.s32 	%r198, %r133, 31;
	.loc	2 40 28                         // standard.py:40:28 @[ gated_mlp.py:93:27 ]
	shr.s32 	%r199, %r198, 31;
	shr.u32 	%r200, %r199, 27;
	add.s32 	%r201, %r198, %r200;
	shr.s32 	%r202, %r201, 5;
$L__tmp2:
	.loc	1 94 38                         // gated_mlp.py:94:38
	shl.b32 	%r204, %r202, 3;
	.loc	1 95 22                         // gated_mlp.py:95:22
	div.s32 	%r205, %r197, %r204;
	ld.param.b32 	%r206, [matmul_kernel_param_6];
	.loc	1 96 29                         // gated_mlp.py:96:29
	shl.b32 	%r1, %r205, 3;
	.loc	1 97 35                         // gated_mlp.py:97:35
	sub.s32 	%r207, 1, %r1;
	.loc	1 97 48                         // gated_mlp.py:97:48
	min.s32 	%r2, %r207, 8;
	.loc	1 98 34                         // gated_mlp.py:98:34
	mul.lo.s32 	%r208, %r205, %r204;
	sub.s32 	%r3, %r197, %r208;
	.loc	1 99 40                         // gated_mlp.py:99:40
	div.s32 	%r4, %r3, %r2;
	.loc	1 109 23                        // gated_mlp.py:109:23
	shl.b32 	%r209, %r4, 5;
	.loc	1 109 51                        // gated_mlp.py:109:51
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r5, 3;
	and.b32 	%r210, %r6, 24;
	.loc	1 109 38                        // gated_mlp.py:109:38
	or.b32 	%r7, %r209, %r210;
	.loc	1 109 68                        // gated_mlp.py:109:68
	rem.s32 	%r211, %r7, %r133;
	.loc	1 111 60                        // gated_mlp.py:111:60
	and.b32 	%r8, %r6, 56;
	.loc	1 111 22                        // gated_mlp.py:111:22
	mul.wide.u32 	%rd44, %r8, 2;
	add.s64 	%rd13, %rd11, %rd44;
	.loc	1 112 29                        // gated_mlp.py:112:29
	and.b32 	%r10, %r5, 32;
	bfe.s32 	%r212, %r5, 5, 1;
	and.b32 	%r11, %r5, 64;
	bfe.u32 	%r12, %r5, 2, 5;
	or.b32 	%r13, %r12, 32;
	.loc	1 112 40                        // gated_mlp.py:112:40
	shl.b32 	%r213, %r206, 5;
	.loc	1 112 52                        // gated_mlp.py:112:52
	mad.lo.s32 	%r214, %r206, %r12, %r211;
	add.s32 	%r215, %r214, %r213;
	.loc	1 112 22                        // gated_mlp.py:112:22
	mul.wide.s32 	%rd45, %r214, 2;
	add.s64 	%rd21, %rd43, %rd45;
	mul.wide.s32 	%rd46, %r215, 2;
	add.s64 	%rd22, %rd43, %rd46;
$L__tmp3:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:120:33 ]
	add.s32 	%r216, %r134, 63;
$L__tmp4:
	.loc	1 129 33                        // gated_mlp.py:129:33
	shl.b32 	%r220, %r206, 6;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.lt.s32 	%p1, %r216, 64;
	setp.gt.s32 	%p2, %r216, 63;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p3, %r8, %r134;
	.loc	1 123 20                        // gated_mlp.py:123:20
	and.b32 	%r221, %r5, 24;
	mul.lo.s32 	%r222, %r221, 9;
	xor.b32 	%r223, %r222, %r8;
	and.b32 	%r224, %r212, 288;
	xor.b32 	%r225, %r223, %r224;
	shl.b32 	%r15, %r11, 3;
	or.b32 	%r16, %r225, %r15;
	shl.b32 	%r226, %r16, 1;
	mov.b32 	%r227, global_smem;
	add.s32 	%r136, %r227, %r226;
	or.b32 	%r228, %r8, 1024;
	xor.b32 	%r229, %r222, %r228;
	xor.b32 	%r230, %r229, %r224;
	or.b32 	%r17, %r230, %r15;
	shl.b32 	%r231, %r17, 1;
	add.s32 	%r138, %r227, %r231;
	or.b32 	%r232, %r8, 2048;
	xor.b32 	%r233, %r222, %r232;
	xor.b32 	%r234, %r233, %r224;
	or.b32 	%r18, %r234, %r15;
	shl.b32 	%r235, %r18, 1;
	add.s32 	%r140, %r227, %r235;
	or.b32 	%r236, %r8, 3072;
	xor.b32 	%r237, %r222, %r236;
	xor.b32 	%r238, %r237, %r224;
	or.b32 	%r19, %r238, %r15;
	shl.b32 	%r239, %r19, 1;
	add.s32 	%r142, %r227, %r239;
	or.b32 	%r240, %r8, 4096;
	xor.b32 	%r241, %r222, %r240;
	xor.b32 	%r242, %r241, %r224;
	or.b32 	%r20, %r242, %r15;
	shl.b32 	%r243, %r20, 1;
	add.s32 	%r144, %r227, %r243;
	or.b32 	%r244, %r8, 5120;
	xor.b32 	%r245, %r222, %r244;
	xor.b32 	%r246, %r245, %r224;
	or.b32 	%r21, %r246, %r15;
	shl.b32 	%r247, %r21, 1;
	add.s32 	%r146, %r227, %r247;
	or.b32 	%r248, %r8, 6144;
	xor.b32 	%r249, %r222, %r248;
	xor.b32 	%r250, %r249, %r224;
	or.b32 	%r22, %r250, %r15;
	shl.b32 	%r251, %r22, 1;
	add.s32 	%r148, %r227, %r251;
	or.b32 	%r252, %r8, 7168;
	xor.b32 	%r253, %r222, %r252;
	xor.b32 	%r254, %r253, %r224;
	or.b32 	%r23, %r254, %r15;
	shl.b32 	%r255, %r23, 1;
	add.s32 	%r150, %r227, %r255;
	selp.b32 	%r256, 16, 0, %p2;
	selp.b32 	%r139, %r256, 0, %p3;
	// begin inline asm
	cp.async.cg.shared.global [ %r136 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r138 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r140 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r142 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r144 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r146 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r148 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r150 + 0 ], [ %rd13 + 0 ], 0x10, %r139;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p4, %r12, %r134;
	setp.lt.s32 	%p5, %r13, %r134;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r24, %r10, 3;
	or.b32 	%r257, %r15, %r24;
	or.b32 	%r25, %r257, %r223;
	shl.b32 	%r258, %r25, 1;
	add.s32 	%r259, %r227, 65536;
	add.s32 	%r152, %r259, %r258;
	or.b32 	%r26, %r257, %r229;
	shl.b32 	%r260, %r26, 1;
	add.s32 	%r154, %r259, %r260;
	selp.b32 	%r153, %r256, 0, %p4;
	// begin inline asm
	cp.async.cg.shared.global [ %r152 + 0 ], [ %rd21 + 0 ], 0x10, %r153;
	// end inline asm
	selp.b32 	%r155, %r256, 0, %p5;
	// begin inline asm
	cp.async.cg.shared.global [ %r154 + 0 ], [ %rd22 + 0 ], 0x10, %r155;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p6, %r216, 127;
	.loc	1 128 18                        // gated_mlp.py:128:18
	add.s64 	%rd23, %rd13, 128;
	.loc	1 129 18                        // gated_mlp.py:129:18
	mul.wide.s32 	%rd47, %r220, 2;
	add.s64 	%rd31, %rd21, %rd47;
	add.s64 	%rd32, %rd22, %rd47;
	.loc	1 123 55                        // gated_mlp.py:123:55
	add.s32 	%r261, %r134, -64;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p7, %r8, %r261;
	.loc	1 123 20                        // gated_mlp.py:123:20
	bar.sync 	0;
	add.s32 	%r262, %r227, 16384;
	add.s32 	%r156, %r262, %r226;
	add.s32 	%r158, %r262, %r231;
	add.s32 	%r160, %r262, %r235;
	add.s32 	%r162, %r262, %r239;
	add.s32 	%r164, %r262, %r243;
	add.s32 	%r166, %r262, %r247;
	add.s32 	%r168, %r262, %r251;
	add.s32 	%r170, %r262, %r255;
	selp.b32 	%r263, 16, 0, %p7;
	selp.b32 	%r159, %r263, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r156 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r158 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r160 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r162 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r164 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r166 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r168 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r170 + 0 ], [ %rd23 + 0 ], 0x10, %r159;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p8, %r12, %r261;
	setp.lt.s32 	%p9, %r13, %r261;
	.loc	1 124 20                        // gated_mlp.py:124:20
	add.s32 	%r264, %r227, 69632;
	add.s32 	%r172, %r264, %r258;
	add.s32 	%r174, %r264, %r260;
	selp.b32 	%r265, 16, 0, %p8;
	selp.b32 	%r173, %r265, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r172 + 0 ], [ %rd31 + 0 ], 0x10, %r173;
	// end inline asm
	selp.b32 	%r266, 16, 0, %p9;
	selp.b32 	%r175, %r266, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r174 + 0 ], [ %rd32 + 0 ], 0x10, %r175;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p10, %r216, 191;
	.loc	1 128 18                        // gated_mlp.py:128:18
	add.s64 	%rd33, %rd13, 256;
	.loc	1 129 18                        // gated_mlp.py:129:18
	add.s64 	%rd41, %rd31, %rd47;
	add.s64 	%rd42, %rd32, %rd47;
	.loc	1 123 55                        // gated_mlp.py:123:55
	add.s32 	%r267, %r134, -128;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p11, %r8, %r267;
	.loc	1 123 20                        // gated_mlp.py:123:20
	bar.sync 	0;
	add.s32 	%r268, %r227, 32768;
	add.s32 	%r176, %r268, %r226;
	add.s32 	%r178, %r268, %r231;
	add.s32 	%r180, %r268, %r235;
	add.s32 	%r182, %r268, %r239;
	add.s32 	%r184, %r268, %r243;
	add.s32 	%r186, %r268, %r247;
	add.s32 	%r188, %r268, %r251;
	add.s32 	%r190, %r268, %r255;
	selp.b32 	%r269, 16, 0, %p11;
	selp.b32 	%r179, %r269, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r176 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r178 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r180 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r182 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r184 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r186 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r188 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r190 + 0 ], [ %rd33 + 0 ], 0x10, %r179;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p12, %r12, %r267;
	setp.lt.s32 	%p13, %r13, %r267;
	.loc	1 124 20                        // gated_mlp.py:124:20
	add.s32 	%r270, %r227, 73728;
	add.s32 	%r192, %r270, %r258;
	add.s32 	%r194, %r270, %r260;
	selp.b32 	%r271, 16, 0, %p12;
	selp.b32 	%r193, %r271, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r192 + 0 ], [ %rd41 + 0 ], 0x10, %r193;
	// end inline asm
	selp.b32 	%r272, 16, 0, %p13;
	selp.b32 	%r195, %r272, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r194 + 0 ], [ %rd42 + 0 ], 0x10, %r195;
	// end inline asm
	cp.async.commit_group;
	mov.b32 	%r819, 0f00000000;
	mov.b32 	%r820, %r819;
	mov.b32 	%r821, %r819;
	mov.b32 	%r822, %r819;
	mov.b32 	%r823, %r819;
	mov.b32 	%r824, %r819;
	mov.b32 	%r825, %r819;
	mov.b32 	%r826, %r819;
	mov.b32 	%r827, %r819;
	mov.b32 	%r828, %r819;
	mov.b32 	%r829, %r819;
	mov.b32 	%r830, %r819;
	mov.b32 	%r831, %r819;
	mov.b32 	%r832, %r819;
	mov.b32 	%r833, %r819;
	mov.b32 	%r834, %r819;
	mov.b32 	%r835, %r819;
	mov.b32 	%r836, %r819;
	mov.b32 	%r837, %r819;
	mov.b32 	%r838, %r819;
	mov.b32 	%r839, %r819;
	mov.b32 	%r840, %r819;
	mov.b32 	%r841, %r819;
	mov.b32 	%r842, %r819;
	mov.b32 	%r843, %r819;
	mov.b32 	%r844, %r819;
	mov.b32 	%r845, %r819;
	mov.b32 	%r846, %r819;
	mov.b32 	%r847, %r819;
	mov.b32 	%r848, %r819;
	mov.b32 	%r849, %r819;
	mov.b32 	%r850, %r819;
	.loc	1 120 22                        // gated_mlp.py:120:22
	@%p1 bra 	$L__BB0_3;
// %bb.1:                               // %.lr.ph
	.loc	1 0 22                          // gated_mlp.py:0:22
	shr.u32 	%r9, %r5, 5;
	shr.s32 	%r217, %r216, 31;
	shr.u32 	%r218, %r217, 26;
	add.s32 	%r219, %r216, %r218;
	shr.s32 	%r14, %r219, 6;
	cvt.s64.s32 	%rd3, %r220;
	add.s32 	%r27, %r14, -3;
	add.s32 	%r816, %r134, -192;
	.loc	1 120 22                        // gated_mlp.py:120:22
	mul.lo.s64 	%rd102, %rd3, 6;
	shl.b64 	%rd5, %rd3, 1;
	and.b32 	%r277, %r5, 7;
	mul.wide.u32 	%rd48, %r277, 16;
	add.s64 	%rd49, %rd48, %rd11;
	add.s64 	%rd101, %rd49, 384;
	mov.b32 	%r605, 0;
	mov.b32 	%r819, 0f00000000;
	mov.b32 	%r818, 2;
	mov.b32 	%r817, -1;
	mov.b32 	%r820, %r819;
	mov.b32 	%r821, %r819;
	mov.b32 	%r822, %r819;
	mov.b32 	%r823, %r819;
	mov.b32 	%r824, %r819;
	mov.b32 	%r825, %r819;
	mov.b32 	%r826, %r819;
	mov.b32 	%r827, %r819;
	mov.b32 	%r828, %r819;
	mov.b32 	%r829, %r819;
	mov.b32 	%r830, %r819;
	mov.b32 	%r831, %r819;
	mov.b32 	%r832, %r819;
	mov.b32 	%r833, %r819;
	mov.b32 	%r834, %r819;
	mov.b32 	%r835, %r819;
	mov.b32 	%r836, %r819;
	mov.b32 	%r837, %r819;
	mov.b32 	%r838, %r819;
	mov.b32 	%r839, %r819;
	mov.b32 	%r840, %r819;
	mov.b32 	%r841, %r819;
	mov.b32 	%r842, %r819;
	mov.b32 	%r843, %r819;
	mov.b32 	%r844, %r819;
	mov.b32 	%r845, %r819;
	mov.b32 	%r846, %r819;
	mov.b32 	%r847, %r819;
	mov.b32 	%r848, %r819;
	mov.b32 	%r849, %r819;
	mov.b32 	%r850, %r819;
	mov.b32 	%r851, %r605;
$L__BB0_2:                              // =>This Inner Loop Header: Depth=1
	setp.lt.s32 	%p22, %r851, %r27;
	add.s32 	%r630, %r817, 1;
	setp.gt.s32 	%p23, %r630, 3;
	selp.b32 	%r817, 0, %r630, %p23;
	.loc	1 123 20                        // gated_mlp.py:123:20
	cp.async.wait_group 	4;
	bar.sync 	0;
	shl.b32 	%r631, %r817, 14;
	add.s32 	%r566, %r227, %r631;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r633, %r817, 12;
	add.s32 	%r569, %r259, %r633;
	.loc	1 126 35                        // gated_mlp.py:126:35
	shfl.sync.idx.b32 	%r635, %r9, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	bfe.u32 	%r636, %r566, 4, 14;
	cvt.u64.u32 	%rd76, %r636;
	or.b64 	%rd50, %rd76, 4611686293372403712;
	bfe.u32 	%r637, %r569, 4, 14;
	cvt.u64.u32 	%rd77, %r637;
	or.b64 	%rd51, %rd77, -9223371899399045120;
	mov.pred 	%p14, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834}, %rd50, %rd51, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r638, %r566, 32;
	bfe.u32 	%r639, %r638, 4, 14;
	cvt.u64.u32 	%rd78, %r639;
	or.b64 	%rd52, %rd78, 4611686293372403712;
	add.s32 	%r640, %r569, 1024;
	bfe.u32 	%r641, %r640, 4, 14;
	cvt.u64.u32 	%rd79, %r641;
	or.b64 	%rd53, %rd79, -9223371899399045120;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834}, %rd52, %rd53, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r642, %r566, 64;
	bfe.u32 	%r643, %r642, 4, 14;
	cvt.u64.u32 	%rd80, %r643;
	or.b64 	%rd54, %rd80, 4611686293372403712;
	add.s32 	%r644, %r569, 2048;
	bfe.u32 	%r645, %r644, 4, 14;
	cvt.u64.u32 	%rd81, %r645;
	or.b64 	%rd55, %rd81, -9223371899399045120;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834}, %rd54, %rd55, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r646, %r566, 96;
	bfe.u32 	%r647, %r646, 4, 14;
	cvt.u64.u32 	%rd82, %r647;
	or.b64 	%rd56, %rd82, 4611686293372403712;
	add.s32 	%r648, %r569, 3072;
	bfe.u32 	%r649, %r648, 4, 14;
	cvt.u64.u32 	%rd83, %r649;
	or.b64 	%rd57, %rd83, -9223371899399045120;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834}, %rd56, %rd57, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r650, %r566, 8192;
	bfe.u32 	%r651, %r650, 4, 14;
	cvt.u64.u32 	%rd84, %r651;
	or.b64 	%rd58, %rd84, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850}, %rd58, %rd51, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r652, %r566, 8224;
	bfe.u32 	%r653, %r652, 4, 14;
	cvt.u64.u32 	%rd85, %r653;
	or.b64 	%rd60, %rd85, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850}, %rd60, %rd53, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r654, %r566, 8256;
	bfe.u32 	%r655, %r654, 4, 14;
	cvt.u64.u32 	%rd86, %r655;
	or.b64 	%rd62, %rd86, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850}, %rd62, %rd55, %p14, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r656, %r566, 8288;
	bfe.u32 	%r657, %r656, 4, 14;
	cvt.u64.u32 	%rd87, %r657;
	or.b64 	%rd64, %rd87, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850}, %rd64, %rd57, %p14, 1, 1, 0, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	mov.b32 	%r571, %r605;
	mov.b32 	%r567, %r605;
	mov.b32 	%r568, %r605;
	mov.b32 	%r570, %r605;
	// begin inline asm
	// wait for regs: %r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834,%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850,%r566,%r567,%r568,%r569,%r570,%r571
	wgmma.wait_group.sync.aligned 1;
	// end inline asm
	.loc	1 129 18                        // gated_mlp.py:129:18
	add.s64 	%rd74, %rd21, %rd102;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s64 	%rd75, %rd22, %rd102;
	add.s32 	%r658, %r818, 1;
	setp.gt.s32 	%p24, %r658, 3;
	selp.b32 	%r818, 0, %r658, %p24;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p25, %r8, %r816;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shl.b32 	%r659, %r818, 14;
	add.s32 	%r660, %r227, %r659;
	bar.sync 	0;
	add.s32 	%r610, %r660, %r226;
	add.s32 	%r612, %r660, %r231;
	add.s32 	%r614, %r660, %r235;
	add.s32 	%r616, %r660, %r239;
	add.s32 	%r618, %r660, %r243;
	add.s32 	%r620, %r660, %r247;
	add.s32 	%r622, %r660, %r251;
	add.s32 	%r624, %r660, %r255;
	selp.b32 	%r669, 16, 0, %p25;
	selp.b32 	%r613, %r669, 0, %p22;
	// begin inline asm
	cp.async.cg.shared.global [ %r610 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r612 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r614 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r616 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r618 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r620 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r622 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r624 + 0 ], [ %rd101 + 0 ], 0x10, %r613;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p26, %r12, %r816;
	setp.lt.s32 	%p27, %r13, %r816;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r670, %r818, 12;
	add.s32 	%r671, %r259, %r670;
	add.s32 	%r626, %r671, %r258;
	add.s32 	%r628, %r671, %r260;
	selp.b32 	%r674, 16, 0, %p26;
	selp.b32 	%r627, %r674, 0, %p22;
	// begin inline asm
	cp.async.cg.shared.global [ %r626 + 0 ], [ %rd74 + 0 ], 0x10, %r627;
	// end inline asm
	selp.b32 	%r675, 16, 0, %p27;
	selp.b32 	%r629, %r675, 0, %p22;
	// begin inline asm
	cp.async.cg.shared.global [ %r628 + 0 ], [ %rd75 + 0 ], 0x10, %r629;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s32 	%r851, %r851, 1;
	add.s64 	%rd102, %rd102, %rd5;
	add.s64 	%rd101, %rd101, 128;
	add.s32 	%r816, %r816, -64;
	setp.ne.s32 	%p28, %r14, %r851;
	@%p28 bra 	$L__BB0_2;
$L__BB0_3:                              // %._crit_edge
	.loc	1 98 54                         // gated_mlp.py:98:54
	mul.lo.s32 	%r756, %r4, %r2;
	sub.s32 	%r757, %r3, %r756;
	.loc	1 98 27                         // gated_mlp.py:98:27
	add.s32 	%r758, %r757, %r1;
	.loc	1 120 22                        // gated_mlp.py:120:22
	// begin inline asm
	// wait for regs: %r819,%r820,%r821,%r822,%r823,%r824,%r825,%r826,%r827,%r828,%r829,%r830,%r831,%r832,%r833,%r834,%r835,%r836,%r837,%r838,%r839,%r840,%r841,%r842,%r843,%r844,%r845,%r846,%r847,%r848,%r849,%r850
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 134 23                        // gated_mlp.py:134:23
	cvt.rn.f16x2.f32 	%r759, %r820, %r819;
	cvt.rn.f16x2.f32 	%r760, %r822, %r821;
	cvt.rn.f16x2.f32 	%r761, %r824, %r823;
	cvt.rn.f16x2.f32 	%r762, %r826, %r825;
	cvt.rn.f16x2.f32 	%r763, %r828, %r827;
	cvt.rn.f16x2.f32 	%r764, %r830, %r829;
	cvt.rn.f16x2.f32 	%r765, %r832, %r831;
	cvt.rn.f16x2.f32 	%r766, %r834, %r833;
	cvt.rn.f16x2.f32 	%r767, %r836, %r835;
	cvt.rn.f16x2.f32 	%r768, %r838, %r837;
	cvt.rn.f16x2.f32 	%r769, %r840, %r839;
	cvt.rn.f16x2.f32 	%r770, %r842, %r841;
	cvt.rn.f16x2.f32 	%r771, %r844, %r843;
	cvt.rn.f16x2.f32 	%r772, %r846, %r845;
	cvt.rn.f16x2.f32 	%r773, %r848, %r847;
	cvt.rn.f16x2.f32 	%r774, %r850, %r849;
	.loc	1 138 22                        // gated_mlp.py:138:22
	shl.b32 	%r775, %r758, 7;
	.loc	1 138 37                        // gated_mlp.py:138:37
	or.b32 	%r776, %r775, %r12;
	or.b32 	%r777, %r775, %r13;
	.loc	1 140 33                        // gated_mlp.py:140:33
	mul.lo.s32 	%r778, %r776, %r135;
	mul.lo.s32 	%r779, %r777, %r135;
	shl.b32 	%r780, %r135, 6;
	add.s32 	%r781, %r778, %r780;
	shl.b32 	%r782, %r135, 5;
	add.s32 	%r783, %r781, %r782;
	.loc	1 140 21                        // gated_mlp.py:140:21
	mul.wide.s32 	%rd92, %r778, 2;
	add.s64 	%rd93, %rd12, %rd92;
	mul.wide.s32 	%rd94, %r779, 2;
	add.s64 	%rd95, %rd12, %rd94;
	mul.wide.s32 	%rd96, %r781, 2;
	add.s64 	%rd97, %rd12, %rd96;
	mul.wide.s32 	%rd98, %r783, 2;
	add.s64 	%rd99, %rd12, %rd98;
	.loc	1 140 52                        // gated_mlp.py:140:52
	mul.wide.s32 	%rd100, %r7, 2;
	add.s64 	%rd88, %rd93, %rd100;
	add.s64 	%rd89, %rd95, %rd100;
	add.s64 	%rd90, %rd97, %rd100;
	add.s64 	%rd91, %rd99, %rd100;
	.loc	1 141 33                        // gated_mlp.py:141:33
	setp.lt.s32 	%p33, %r776, 1;
	setp.lt.s32 	%p34, %r777, 1;
	setp.lt.s32 	%p35, %r775, 0;
	.loc	1 141 58                        // gated_mlp.py:141:58
	setp.lt.s32 	%p36, %r7, %r133;
	.loc	1 141 39                        // gated_mlp.py:141:39
	and.pred 	%p29, %p36, %p33;
	and.pred 	%p30, %p36, %p34;
	and.pred 	%p31, %p36, %p35;
	.loc	1 142 21                        // gated_mlp.py:142:21
	shl.b32 	%r784, %r5, 1;
	and.b32 	%r785, %r784, 6;
	shl.b32 	%r786, %r10, 4;
	or.b32 	%r787, %r785, %r786;
	and.b32 	%r788, %r6, 224;
	or.b32 	%r789, %r787, %r788;
	shl.b32 	%r790, %r11, 4;
	or.b32 	%r791, %r789, %r790;
	and.b32 	%r792, %r6, 248;
	or.b32 	%r793, %r792, %r24;
	or.b32 	%r794, %r793, %r15;
	shr.u32 	%r795, %r791, 1;
	and.b32 	%r796, %r795, 1008;
	add.s32 	%r798, %r227, %r796;
	shl.b32 	%r799, %r791, 1;
	add.s32 	%r800, %r798, %r799;
	st.shared.b32 	[%r800], %r759;
	or.b32 	%r801, %r791, 256;
	shr.u32 	%r802, %r801, 1;
	and.b32 	%r803, %r802, 1073741808;
	add.s32 	%r804, %r227, %r803;
	add.s32 	%r805, %r804, %r799;
	st.shared.b32 	[%r805+512], %r760;
	st.shared.b32 	[%r800+16], %r761;
	st.shared.b32 	[%r805+528], %r762;
	st.shared.b32 	[%r800+32], %r763;
	st.shared.b32 	[%r805+544], %r764;
	st.shared.b32 	[%r800+48], %r765;
	st.shared.b32 	[%r805+560], %r766;
	bar.sync 	0;
	shr.u32 	%r806, %r794, 1;
	and.b32 	%r807, %r806, 496;
	add.s32 	%r808, %r227, %r807;
	shl.b32 	%r809, %r794, 1;
	add.s32 	%r810, %r808, %r809;
	ld.shared.v4.b32 	{%r740, %r741, %r742, %r743}, [%r810];
	or.b32 	%r811, %r794, 1024;
	shr.u32 	%r812, %r811, 1;
	and.b32 	%r813, %r812, 1008;
	add.s32 	%r814, %r227, %r813;
	add.s32 	%r815, %r814, %r809;
	ld.shared.v4.b32 	{%r744, %r745, %r746, %r747}, [%r815+2048];
	bar.sync 	0;
	st.shared.b32 	[%r800], %r767;
	st.shared.b32 	[%r805+512], %r768;
	st.shared.b32 	[%r800+16], %r769;
	st.shared.b32 	[%r805+528], %r770;
	st.shared.b32 	[%r800+32], %r771;
	st.shared.b32 	[%r805+544], %r772;
	st.shared.b32 	[%r800+48], %r773;
	st.shared.b32 	[%r805+560], %r774;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r748, %r749, %r750, %r751}, [%r810];
	ld.shared.v4.b32 	{%r752, %r753, %r754, %r755}, [%r815+2048];
	// begin inline asm
	@%p29 st.global.v4.b32 [ %rd88 + 0 ], { %r740, %r741, %r742, %r743 };
	// end inline asm
	// begin inline asm
	@%p30 st.global.v4.b32 [ %rd89 + 0 ], { %r744, %r745, %r746, %r747 };
	// end inline asm
	// begin inline asm
	@%p31 st.global.v4.b32 [ %rd90 + 0 ], { %r748, %r749, %r750, %r751 };
	// end inline asm
	// begin inline asm
	@%p31 st.global.v4.b32 [ %rd91 + 0 ], { %r752, %r753, %r754, %r755 };
	// end inline asm
	.loc	1 142 4                         // gated_mlp.py:142:4
	ret;
$L__tmp5:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/PTX_dataset/triton_ptx/gated_mlp.py"
	.file	2 "/home/joy/miniconda3/envs/ptx/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 157                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x96 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 103                                 // DW_AT_name
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 109
.b8 108
.b8 112
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 80
.b8 84
.b8 88
.b8 95
.b8 100
.b8 97
.b8 116
.b8 97
.b8 115
.b8 101
.b8 116
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 112
.b8 116
.b8 120
.b8 0
.b8 2                                   // Abbrev [2] 0x4a:0x10 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x5a:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 74                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x6f:0x18 DW_TAG_inlined_subroutine
.b32 74                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 93                                  // DW_AT_call_line
.b8 27                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x87:0x18 DW_TAG_inlined_subroutine
.b32 74                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp4                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 120                                 // DW_AT_call_line
.b8 33                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
