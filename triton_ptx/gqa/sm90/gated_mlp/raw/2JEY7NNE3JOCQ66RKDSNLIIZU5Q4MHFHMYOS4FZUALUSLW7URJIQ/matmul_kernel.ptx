//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	matmul_kernel           // -- Begin function matmul_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel
.visible .entry matmul_kernel(
	.param .u64 .ptr .global .align 1 matmul_kernel_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u64 .ptr .global .align 1 matmul_kernel_param_8
)
.reqntid 256
{
	.reg .pred 	%p<100>;
	.reg .b32 	%r<3943>;
	.reg .b64 	%rd<218>;
	.loc	1 68 0                          // gated_mlp.py:68:0
$L__func_begin0:
	.loc	1 68 0                          // gated_mlp.py:68:0

// %bb.0:
	ld.param.b32 	%r453, [matmul_kernel_param_7];
	ld.param.b32 	%r452, [matmul_kernel_param_6];
	ld.param.b32 	%r451, [matmul_kernel_param_4];
	ld.param.b32 	%r450, [matmul_kernel_param_3];
	ld.param.b64 	%rd41, [matmul_kernel_param_2];
	ld.param.b64 	%rd40, [matmul_kernel_param_1];
	ld.param.b64 	%rd39, [matmul_kernel_param_0];
$L__tmp0:
	.loc	1 91 24                         // gated_mlp.py:91:24
	mov.u32 	%r551, %ctaid.x;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:93:27 ]
	add.s32 	%r552, %r450, 255;
	.loc	2 40 28                         // standard.py:40:28 @[ gated_mlp.py:93:27 ]
	shr.s32 	%r553, %r552, 31;
	shr.u32 	%r554, %r553, 24;
	add.s32 	%r555, %r552, %r554;
	shr.s32 	%r556, %r555, 8;
$L__tmp2:
	.loc	1 94 38                         // gated_mlp.py:94:38
	shl.b32 	%r558, %r556, 3;
	.loc	1 95 22                         // gated_mlp.py:95:22
	div.s32 	%r559, %r551, %r558;
	.loc	1 96 29                         // gated_mlp.py:96:29
	shl.b32 	%r1, %r559, 3;
	.loc	1 97 35                         // gated_mlp.py:97:35
	sub.s32 	%r560, 1, %r1;
	.loc	1 97 48                         // gated_mlp.py:97:48
	min.s32 	%r2, %r560, 8;
	.loc	1 98 34                         // gated_mlp.py:98:34
	mul.lo.s32 	%r561, %r559, %r558;
	sub.s32 	%r3, %r551, %r561;
	.loc	1 99 40                         // gated_mlp.py:99:40
	div.s32 	%r4, %r3, %r2;
	.loc	1 109 23                        // gated_mlp.py:109:23
	shl.b32 	%r562, %r4, 8;
	.loc	1 109 51                        // gated_mlp.py:109:51
	mov.u32 	%r5, %tid.x;
	shl.b32 	%r6, %r5, 3;
	and.b32 	%r7, %r6, 56;
	and.b32 	%r563, %r5, 8;
	shl.b32 	%r8, %r563, 3;
	or.b32 	%r9, %r7, %r8;
	and.b32 	%r10, %r5, 16;
	bfe.s32 	%r564, %r5, 4, 1;
	and.b32 	%r565, %r6, 248;
	.loc	1 109 38                        // gated_mlp.py:109:38
	or.b32 	%r11, %r562, %r565;
	.loc	1 109 68                        // gated_mlp.py:109:68
	rem.s32 	%r12, %r11, %r450;
	.loc	1 110 26                        // gated_mlp.py:110:26
	shr.u32 	%r13, %r5, 5;
	bfe.s32 	%r566, %r5, 5, 1;
	bfe.s32 	%r567, %r5, 6, 1;
	bfe.s32 	%r568, %r5, 7, 1;
	and.b32 	%r14, %r5, 128;
	bfe.u32 	%r15, %r5, 5, 3;
	or.b32 	%r16, %r15, 8;
	or.b32 	%r17, %r15, 16;
	or.b32 	%r18, %r13, 24;
	or.b32 	%r19, %r15, 32;
	or.b32 	%r20, %r15, 40;
	or.b32 	%r21, %r15, 48;
	or.b32 	%r22, %r13, 56;
	or.b32 	%r23, %r15, 64;
	or.b32 	%r24, %r15, 72;
	or.b32 	%r25, %r15, 80;
	or.b32 	%r26, %r13, 88;
	or.b32 	%r27, %r15, 96;
	or.b32 	%r28, %r15, 104;
	or.b32 	%r29, %r15, 112;
	or.b32 	%r30, %r13, 120;
	.loc	1 111 22                        // gated_mlp.py:111:22
	mul.wide.u32 	%rd90, %r9, 2;
	add.s64 	%rd42, %rd39, %rd90;
	.loc	1 112 40                        // gated_mlp.py:112:40
	mul.lo.s32 	%r569, %r452, %r15;
	shl.b32 	%r570, %r452, 3;
	add.s32 	%r571, %r569, %r570;
	add.s32 	%r572, %r571, %r570;
	shl.b32 	%r573, %r452, 4;
	add.s32 	%r574, %r572, %r573;
	add.s32 	%r575, %r574, %r570;
	add.s32 	%r576, %r575, %r570;
	add.s32 	%r577, %r576, %r573;
	add.s32 	%r578, %r577, %r570;
	add.s32 	%r579, %r578, %r570;
	add.s32 	%r580, %r579, %r573;
	add.s32 	%r581, %r580, %r570;
	add.s32 	%r582, %r581, %r570;
	.loc	1 112 52                        // gated_mlp.py:112:52
	add.s32 	%r583, %r12, %r569;
	add.s32 	%r584, %r12, %r571;
	add.s32 	%r585, %r12, %r572;
	mad.lo.s32 	%r586, %r452, %r18, %r12;
	add.s32 	%r587, %r12, %r574;
	add.s32 	%r588, %r12, %r575;
	add.s32 	%r589, %r12, %r576;
	mad.lo.s32 	%r590, %r452, %r22, %r12;
	add.s32 	%r591, %r12, %r577;
	add.s32 	%r592, %r12, %r578;
	add.s32 	%r593, %r12, %r579;
	mad.lo.s32 	%r594, %r452, %r26, %r12;
	add.s32 	%r595, %r12, %r580;
	add.s32 	%r596, %r12, %r581;
	add.s32 	%r597, %r12, %r582;
	mad.lo.s32 	%r598, %r452, %r30, %r12;
	.loc	1 112 22                        // gated_mlp.py:112:22
	mul.wide.s32 	%rd91, %r583, 2;
	add.s64 	%rd50, %rd40, %rd91;
	mul.wide.s32 	%rd92, %r584, 2;
	add.s64 	%rd51, %rd40, %rd92;
	mul.wide.s32 	%rd93, %r585, 2;
	add.s64 	%rd52, %rd40, %rd93;
	mul.wide.s32 	%rd94, %r586, 2;
	add.s64 	%rd53, %rd40, %rd94;
	mul.wide.s32 	%rd95, %r587, 2;
	add.s64 	%rd54, %rd40, %rd95;
	mul.wide.s32 	%rd96, %r588, 2;
	add.s64 	%rd55, %rd40, %rd96;
	mul.wide.s32 	%rd97, %r589, 2;
	add.s64 	%rd56, %rd40, %rd97;
	mul.wide.s32 	%rd98, %r590, 2;
	add.s64 	%rd57, %rd40, %rd98;
	mul.wide.s32 	%rd99, %r591, 2;
	add.s64 	%rd58, %rd40, %rd99;
	mul.wide.s32 	%rd100, %r592, 2;
	add.s64 	%rd59, %rd40, %rd100;
	mul.wide.s32 	%rd101, %r593, 2;
	add.s64 	%rd60, %rd40, %rd101;
	mul.wide.s32 	%rd102, %r594, 2;
	add.s64 	%rd61, %rd40, %rd102;
	mul.wide.s32 	%rd103, %r595, 2;
	add.s64 	%rd62, %rd40, %rd103;
	mul.wide.s32 	%rd104, %r596, 2;
	add.s64 	%rd63, %rd40, %rd104;
	mul.wide.s32 	%rd105, %r597, 2;
	add.s64 	%rd64, %rd40, %rd105;
	mul.wide.s32 	%rd106, %r598, 2;
	add.s64 	%rd65, %rd40, %rd106;
$L__tmp3:
	.loc	2 40 22                         // standard.py:40:22 @[ gated_mlp.py:120:33 ]
	add.s32 	%r599, %r451, 127;
$L__tmp4:
	.loc	1 129 33                        // gated_mlp.py:129:33
	shl.b32 	%r603, %r452, 7;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.lt.s32 	%p1, %r599, 128;
	setp.gt.s32 	%p2, %r599, 127;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p3, %r9, %r451;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shl.b32 	%r604, %r563, 10;
	or.b32 	%r605, %r7, %r604;
	and.b32 	%r606, %r564, 72;
	and.b32 	%r607, %r566, 144;
	and.b32 	%r608, %r567, 288;
	or.b32 	%r609, %r607, %r606;
	xor.b32 	%r610, %r609, %r605;
	xor.b32 	%r611, %r610, %r608;
	shl.b32 	%r612, %r14, 2;
	or.b32 	%r32, %r611, %r612;
	shl.b32 	%r613, %r32, 1;
	mov.b32 	%r614, global_smem;
	add.s32 	%r615, %r614, 196608;
	add.s32 	%r454, %r615, %r613;
	or.b32 	%r616, %r605, 1024;
	or.b32 	%r617, %r609, %r612;
	or.b32 	%r618, %r617, %r608;
	xor.b32 	%r33, %r618, %r616;
	shl.b32 	%r619, %r33, 1;
	add.s32 	%r456, %r615, %r619;
	or.b32 	%r620, %r605, 2048;
	xor.b32 	%r34, %r618, %r620;
	shl.b32 	%r621, %r34, 1;
	add.s32 	%r458, %r615, %r621;
	or.b32 	%r622, %r605, 3072;
	xor.b32 	%r35, %r618, %r622;
	shl.b32 	%r623, %r35, 1;
	add.s32 	%r460, %r615, %r623;
	or.b32 	%r624, %r605, 4096;
	xor.b32 	%r36, %r618, %r624;
	shl.b32 	%r625, %r36, 1;
	add.s32 	%r462, %r615, %r625;
	or.b32 	%r626, %r605, 5120;
	xor.b32 	%r37, %r618, %r626;
	shl.b32 	%r627, %r37, 1;
	add.s32 	%r464, %r615, %r627;
	or.b32 	%r628, %r605, 6144;
	xor.b32 	%r38, %r618, %r628;
	shl.b32 	%r629, %r38, 1;
	add.s32 	%r466, %r615, %r629;
	or.b32 	%r630, %r605, 7168;
	xor.b32 	%r39, %r618, %r630;
	shl.b32 	%r631, %r39, 1;
	add.s32 	%r468, %r615, %r631;
	selp.b32 	%r632, 16, 0, %p2;
	selp.b32 	%r457, %r632, 0, %p3;
	// begin inline asm
	cp.async.cg.shared.global [ %r454 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r456 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r458 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r460 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r462 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r464 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r466 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r468 + 0 ], [ %rd42 + 0 ], 0x10, %r457;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p4, %r15, %r451;
	setp.lt.s32 	%p5, %r16, %r451;
	setp.lt.s32 	%p6, %r17, %r451;
	setp.lt.s32 	%p7, %r18, %r451;
	setp.lt.s32 	%p8, %r19, %r451;
	setp.lt.s32 	%p9, %r20, %r451;
	setp.lt.s32 	%p10, %r21, %r451;
	setp.lt.s32 	%p11, %r22, %r451;
	setp.lt.s32 	%p12, %r23, %r451;
	setp.lt.s32 	%p13, %r24, %r451;
	setp.lt.s32 	%p14, %r25, %r451;
	setp.lt.s32 	%p15, %r26, %r451;
	setp.lt.s32 	%p16, %r27, %r451;
	setp.lt.s32 	%p17, %r28, %r451;
	setp.lt.s32 	%p18, %r29, %r451;
	setp.lt.s32 	%p19, %r30, %r451;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r633, %r10, 10;
	or.b32 	%r634, %r605, %r633;
	and.b32 	%r635, %r566, 72;
	and.b32 	%r636, %r567, 144;
	and.b32 	%r637, %r568, 288;
	or.b32 	%r638, %r636, %r635;
	or.b32 	%r639, %r638, %r637;
	xor.b32 	%r40, %r639, %r634;
	shl.b32 	%r640, %r40, 1;
	add.s32 	%r470, %r614, %r640;
	or.b32 	%r641, %r634, 512;
	xor.b32 	%r41, %r639, %r641;
	shl.b32 	%r642, %r41, 1;
	add.s32 	%r472, %r614, %r642;
	or.b32 	%r643, %r616, %r633;
	xor.b32 	%r42, %r639, %r643;
	shl.b32 	%r644, %r42, 1;
	add.s32 	%r474, %r614, %r644;
	or.b32 	%r645, %r634, 1536;
	xor.b32 	%r43, %r639, %r645;
	shl.b32 	%r646, %r43, 1;
	add.s32 	%r476, %r614, %r646;
	or.b32 	%r647, %r620, %r633;
	xor.b32 	%r44, %r639, %r647;
	shl.b32 	%r648, %r44, 1;
	add.s32 	%r478, %r614, %r648;
	or.b32 	%r649, %r634, 2560;
	xor.b32 	%r45, %r639, %r649;
	shl.b32 	%r650, %r45, 1;
	add.s32 	%r480, %r614, %r650;
	or.b32 	%r651, %r622, %r633;
	xor.b32 	%r46, %r639, %r651;
	shl.b32 	%r652, %r46, 1;
	add.s32 	%r482, %r614, %r652;
	or.b32 	%r653, %r634, 3584;
	xor.b32 	%r47, %r639, %r653;
	shl.b32 	%r654, %r47, 1;
	add.s32 	%r484, %r614, %r654;
	or.b32 	%r655, %r624, %r633;
	xor.b32 	%r48, %r639, %r655;
	shl.b32 	%r656, %r48, 1;
	add.s32 	%r486, %r614, %r656;
	or.b32 	%r657, %r634, 4608;
	xor.b32 	%r49, %r639, %r657;
	shl.b32 	%r658, %r49, 1;
	add.s32 	%r488, %r614, %r658;
	or.b32 	%r659, %r626, %r633;
	xor.b32 	%r50, %r639, %r659;
	shl.b32 	%r660, %r50, 1;
	add.s32 	%r490, %r614, %r660;
	or.b32 	%r661, %r634, 5632;
	xor.b32 	%r51, %r639, %r661;
	shl.b32 	%r662, %r51, 1;
	add.s32 	%r492, %r614, %r662;
	or.b32 	%r663, %r628, %r633;
	xor.b32 	%r52, %r639, %r663;
	shl.b32 	%r664, %r52, 1;
	add.s32 	%r494, %r614, %r664;
	or.b32 	%r665, %r634, 6656;
	xor.b32 	%r53, %r639, %r665;
	shl.b32 	%r666, %r53, 1;
	add.s32 	%r496, %r614, %r666;
	or.b32 	%r667, %r630, %r633;
	xor.b32 	%r54, %r639, %r667;
	shl.b32 	%r668, %r54, 1;
	add.s32 	%r498, %r614, %r668;
	or.b32 	%r669, %r634, 7680;
	xor.b32 	%r55, %r639, %r669;
	shl.b32 	%r670, %r55, 1;
	add.s32 	%r500, %r614, %r670;
	selp.b32 	%r471, %r632, 0, %p4;
	// begin inline asm
	cp.async.cg.shared.global [ %r470 + 0 ], [ %rd50 + 0 ], 0x10, %r471;
	// end inline asm
	selp.b32 	%r473, %r632, 0, %p5;
	// begin inline asm
	cp.async.cg.shared.global [ %r472 + 0 ], [ %rd51 + 0 ], 0x10, %r473;
	// end inline asm
	selp.b32 	%r475, %r632, 0, %p6;
	// begin inline asm
	cp.async.cg.shared.global [ %r474 + 0 ], [ %rd52 + 0 ], 0x10, %r475;
	// end inline asm
	selp.b32 	%r477, %r632, 0, %p7;
	// begin inline asm
	cp.async.cg.shared.global [ %r476 + 0 ], [ %rd53 + 0 ], 0x10, %r477;
	// end inline asm
	selp.b32 	%r479, %r632, 0, %p8;
	// begin inline asm
	cp.async.cg.shared.global [ %r478 + 0 ], [ %rd54 + 0 ], 0x10, %r479;
	// end inline asm
	selp.b32 	%r481, %r632, 0, %p9;
	// begin inline asm
	cp.async.cg.shared.global [ %r480 + 0 ], [ %rd55 + 0 ], 0x10, %r481;
	// end inline asm
	selp.b32 	%r483, %r632, 0, %p10;
	// begin inline asm
	cp.async.cg.shared.global [ %r482 + 0 ], [ %rd56 + 0 ], 0x10, %r483;
	// end inline asm
	selp.b32 	%r485, %r632, 0, %p11;
	// begin inline asm
	cp.async.cg.shared.global [ %r484 + 0 ], [ %rd57 + 0 ], 0x10, %r485;
	// end inline asm
	selp.b32 	%r487, %r632, 0, %p12;
	// begin inline asm
	cp.async.cg.shared.global [ %r486 + 0 ], [ %rd58 + 0 ], 0x10, %r487;
	// end inline asm
	selp.b32 	%r489, %r632, 0, %p13;
	// begin inline asm
	cp.async.cg.shared.global [ %r488 + 0 ], [ %rd59 + 0 ], 0x10, %r489;
	// end inline asm
	selp.b32 	%r491, %r632, 0, %p14;
	// begin inline asm
	cp.async.cg.shared.global [ %r490 + 0 ], [ %rd60 + 0 ], 0x10, %r491;
	// end inline asm
	selp.b32 	%r493, %r632, 0, %p15;
	// begin inline asm
	cp.async.cg.shared.global [ %r492 + 0 ], [ %rd61 + 0 ], 0x10, %r493;
	// end inline asm
	selp.b32 	%r495, %r632, 0, %p16;
	// begin inline asm
	cp.async.cg.shared.global [ %r494 + 0 ], [ %rd62 + 0 ], 0x10, %r495;
	// end inline asm
	selp.b32 	%r497, %r632, 0, %p17;
	// begin inline asm
	cp.async.cg.shared.global [ %r496 + 0 ], [ %rd63 + 0 ], 0x10, %r497;
	// end inline asm
	selp.b32 	%r499, %r632, 0, %p18;
	// begin inline asm
	cp.async.cg.shared.global [ %r498 + 0 ], [ %rd64 + 0 ], 0x10, %r499;
	// end inline asm
	selp.b32 	%r501, %r632, 0, %p19;
	// begin inline asm
	cp.async.cg.shared.global [ %r500 + 0 ], [ %rd65 + 0 ], 0x10, %r501;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	setp.gt.s32 	%p20, %r599, 255;
	.loc	1 128 18                        // gated_mlp.py:128:18
	add.s64 	%rd66, %rd42, 256;
	.loc	1 129 18                        // gated_mlp.py:129:18
	mul.wide.s32 	%rd107, %r603, 2;
	add.s64 	%rd74, %rd50, %rd107;
	add.s64 	%rd75, %rd51, %rd107;
	add.s64 	%rd76, %rd52, %rd107;
	add.s64 	%rd77, %rd53, %rd107;
	add.s64 	%rd78, %rd54, %rd107;
	add.s64 	%rd79, %rd55, %rd107;
	add.s64 	%rd80, %rd56, %rd107;
	add.s64 	%rd81, %rd57, %rd107;
	add.s64 	%rd82, %rd58, %rd107;
	add.s64 	%rd83, %rd59, %rd107;
	add.s64 	%rd84, %rd60, %rd107;
	add.s64 	%rd85, %rd61, %rd107;
	add.s64 	%rd86, %rd62, %rd107;
	add.s64 	%rd87, %rd63, %rd107;
	add.s64 	%rd88, %rd64, %rd107;
	add.s64 	%rd89, %rd65, %rd107;
	.loc	1 123 55                        // gated_mlp.py:123:55
	add.s32 	%r671, %r451, -128;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p21, %r9, %r671;
	.loc	1 123 20                        // gated_mlp.py:123:20
	bar.sync 	0;
	add.s32 	%r672, %r614, 229376;
	add.s32 	%r502, %r672, %r613;
	add.s32 	%r504, %r672, %r619;
	add.s32 	%r506, %r672, %r621;
	add.s32 	%r508, %r672, %r623;
	add.s32 	%r510, %r672, %r625;
	add.s32 	%r512, %r672, %r627;
	add.s32 	%r514, %r672, %r629;
	add.s32 	%r516, %r672, %r631;
	selp.b32 	%r673, 16, 0, %p21;
	selp.b32 	%r505, %r673, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r502 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r504 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r506 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r508 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r510 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r512 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r514 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r516 + 0 ], [ %rd66 + 0 ], 0x10, %r505;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p22, %r15, %r671;
	setp.lt.s32 	%p23, %r16, %r671;
	setp.lt.s32 	%p24, %r17, %r671;
	setp.lt.s32 	%p25, %r18, %r671;
	setp.lt.s32 	%p26, %r19, %r671;
	setp.lt.s32 	%p27, %r20, %r671;
	setp.lt.s32 	%p28, %r21, %r671;
	setp.lt.s32 	%p29, %r22, %r671;
	setp.lt.s32 	%p30, %r23, %r671;
	setp.lt.s32 	%p31, %r24, %r671;
	setp.lt.s32 	%p32, %r25, %r671;
	setp.lt.s32 	%p33, %r26, %r671;
	setp.lt.s32 	%p34, %r27, %r671;
	setp.lt.s32 	%p35, %r28, %r671;
	setp.lt.s32 	%p36, %r29, %r671;
	setp.lt.s32 	%p37, %r30, %r671;
	.loc	1 124 20                        // gated_mlp.py:124:20
	add.s32 	%r674, %r614, 65536;
	add.s32 	%r518, %r674, %r640;
	add.s32 	%r520, %r674, %r642;
	add.s32 	%r522, %r674, %r644;
	add.s32 	%r524, %r674, %r646;
	add.s32 	%r526, %r674, %r648;
	add.s32 	%r528, %r674, %r650;
	add.s32 	%r530, %r674, %r652;
	add.s32 	%r532, %r674, %r654;
	add.s32 	%r534, %r674, %r656;
	add.s32 	%r536, %r674, %r658;
	add.s32 	%r538, %r674, %r660;
	add.s32 	%r540, %r674, %r662;
	add.s32 	%r542, %r674, %r664;
	add.s32 	%r544, %r674, %r666;
	add.s32 	%r546, %r674, %r668;
	add.s32 	%r548, %r674, %r670;
	selp.b32 	%r675, 16, 0, %p22;
	selp.b32 	%r519, %r675, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r518 + 0 ], [ %rd74 + 0 ], 0x10, %r519;
	// end inline asm
	selp.b32 	%r676, 16, 0, %p23;
	selp.b32 	%r521, %r676, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r520 + 0 ], [ %rd75 + 0 ], 0x10, %r521;
	// end inline asm
	selp.b32 	%r677, 16, 0, %p24;
	selp.b32 	%r523, %r677, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r522 + 0 ], [ %rd76 + 0 ], 0x10, %r523;
	// end inline asm
	selp.b32 	%r678, 16, 0, %p25;
	selp.b32 	%r525, %r678, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r524 + 0 ], [ %rd77 + 0 ], 0x10, %r525;
	// end inline asm
	selp.b32 	%r679, 16, 0, %p26;
	selp.b32 	%r527, %r679, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r526 + 0 ], [ %rd78 + 0 ], 0x10, %r527;
	// end inline asm
	selp.b32 	%r680, 16, 0, %p27;
	selp.b32 	%r529, %r680, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r528 + 0 ], [ %rd79 + 0 ], 0x10, %r529;
	// end inline asm
	selp.b32 	%r681, 16, 0, %p28;
	selp.b32 	%r531, %r681, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r530 + 0 ], [ %rd80 + 0 ], 0x10, %r531;
	// end inline asm
	selp.b32 	%r682, 16, 0, %p29;
	selp.b32 	%r533, %r682, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r532 + 0 ], [ %rd81 + 0 ], 0x10, %r533;
	// end inline asm
	selp.b32 	%r683, 16, 0, %p30;
	selp.b32 	%r535, %r683, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r534 + 0 ], [ %rd82 + 0 ], 0x10, %r535;
	// end inline asm
	selp.b32 	%r684, 16, 0, %p31;
	selp.b32 	%r537, %r684, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r536 + 0 ], [ %rd83 + 0 ], 0x10, %r537;
	// end inline asm
	selp.b32 	%r685, 16, 0, %p32;
	selp.b32 	%r539, %r685, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r538 + 0 ], [ %rd84 + 0 ], 0x10, %r539;
	// end inline asm
	selp.b32 	%r686, 16, 0, %p33;
	selp.b32 	%r541, %r686, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r540 + 0 ], [ %rd85 + 0 ], 0x10, %r541;
	// end inline asm
	selp.b32 	%r687, 16, 0, %p34;
	selp.b32 	%r543, %r687, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r542 + 0 ], [ %rd86 + 0 ], 0x10, %r543;
	// end inline asm
	selp.b32 	%r688, 16, 0, %p35;
	selp.b32 	%r545, %r688, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r544 + 0 ], [ %rd87 + 0 ], 0x10, %r545;
	// end inline asm
	selp.b32 	%r689, 16, 0, %p36;
	selp.b32 	%r547, %r689, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r546 + 0 ], [ %rd88 + 0 ], 0x10, %r547;
	// end inline asm
	selp.b32 	%r690, 16, 0, %p37;
	selp.b32 	%r549, %r690, 0, %p20;
	// begin inline asm
	cp.async.cg.shared.global [ %r548 + 0 ], [ %rd89 + 0 ], 0x10, %r549;
	// end inline asm
	cp.async.commit_group;
	mov.b32 	%r3686, 0f00000000;
	mov.b32 	%r3687, %r3686;
	mov.b32 	%r3688, %r3686;
	mov.b32 	%r3689, %r3686;
	mov.b32 	%r3690, %r3686;
	mov.b32 	%r3691, %r3686;
	mov.b32 	%r3692, %r3686;
	mov.b32 	%r3693, %r3686;
	mov.b32 	%r3694, %r3686;
	mov.b32 	%r3695, %r3686;
	mov.b32 	%r3696, %r3686;
	mov.b32 	%r3697, %r3686;
	mov.b32 	%r3698, %r3686;
	mov.b32 	%r3699, %r3686;
	mov.b32 	%r3700, %r3686;
	mov.b32 	%r3701, %r3686;
	mov.b32 	%r3702, %r3686;
	mov.b32 	%r3703, %r3686;
	mov.b32 	%r3704, %r3686;
	mov.b32 	%r3705, %r3686;
	mov.b32 	%r3706, %r3686;
	mov.b32 	%r3707, %r3686;
	mov.b32 	%r3708, %r3686;
	mov.b32 	%r3709, %r3686;
	mov.b32 	%r3710, %r3686;
	mov.b32 	%r3711, %r3686;
	mov.b32 	%r3712, %r3686;
	mov.b32 	%r3713, %r3686;
	mov.b32 	%r3714, %r3686;
	mov.b32 	%r3715, %r3686;
	mov.b32 	%r3716, %r3686;
	mov.b32 	%r3717, %r3686;
	mov.b32 	%r3718, %r3686;
	mov.b32 	%r3719, %r3686;
	mov.b32 	%r3720, %r3686;
	mov.b32 	%r3721, %r3686;
	mov.b32 	%r3722, %r3686;
	mov.b32 	%r3723, %r3686;
	mov.b32 	%r3724, %r3686;
	mov.b32 	%r3725, %r3686;
	mov.b32 	%r3726, %r3686;
	mov.b32 	%r3727, %r3686;
	mov.b32 	%r3728, %r3686;
	mov.b32 	%r3729, %r3686;
	mov.b32 	%r3730, %r3686;
	mov.b32 	%r3731, %r3686;
	mov.b32 	%r3732, %r3686;
	mov.b32 	%r3733, %r3686;
	mov.b32 	%r3734, %r3686;
	mov.b32 	%r3735, %r3686;
	mov.b32 	%r3736, %r3686;
	mov.b32 	%r3737, %r3686;
	mov.b32 	%r3738, %r3686;
	mov.b32 	%r3739, %r3686;
	mov.b32 	%r3740, %r3686;
	mov.b32 	%r3741, %r3686;
	mov.b32 	%r3742, %r3686;
	mov.b32 	%r3743, %r3686;
	mov.b32 	%r3744, %r3686;
	mov.b32 	%r3745, %r3686;
	mov.b32 	%r3746, %r3686;
	mov.b32 	%r3747, %r3686;
	mov.b32 	%r3748, %r3686;
	mov.b32 	%r3749, %r3686;
	mov.b32 	%r3750, %r3686;
	mov.b32 	%r3751, %r3686;
	mov.b32 	%r3752, %r3686;
	mov.b32 	%r3753, %r3686;
	mov.b32 	%r3754, %r3686;
	mov.b32 	%r3755, %r3686;
	mov.b32 	%r3756, %r3686;
	mov.b32 	%r3757, %r3686;
	mov.b32 	%r3758, %r3686;
	mov.b32 	%r3759, %r3686;
	mov.b32 	%r3760, %r3686;
	mov.b32 	%r3761, %r3686;
	mov.b32 	%r3762, %r3686;
	mov.b32 	%r3763, %r3686;
	mov.b32 	%r3764, %r3686;
	mov.b32 	%r3765, %r3686;
	mov.b32 	%r3766, %r3686;
	mov.b32 	%r3767, %r3686;
	mov.b32 	%r3768, %r3686;
	mov.b32 	%r3769, %r3686;
	mov.b32 	%r3770, %r3686;
	mov.b32 	%r3771, %r3686;
	mov.b32 	%r3772, %r3686;
	mov.b32 	%r3773, %r3686;
	mov.b32 	%r3774, %r3686;
	mov.b32 	%r3775, %r3686;
	mov.b32 	%r3776, %r3686;
	mov.b32 	%r3777, %r3686;
	mov.b32 	%r3778, %r3686;
	mov.b32 	%r3779, %r3686;
	mov.b32 	%r3780, %r3686;
	mov.b32 	%r3781, %r3686;
	mov.b32 	%r3782, %r3686;
	mov.b32 	%r3783, %r3686;
	mov.b32 	%r3784, %r3686;
	mov.b32 	%r3785, %r3686;
	mov.b32 	%r3786, %r3686;
	mov.b32 	%r3787, %r3686;
	mov.b32 	%r3788, %r3686;
	mov.b32 	%r3789, %r3686;
	mov.b32 	%r3790, %r3686;
	mov.b32 	%r3791, %r3686;
	mov.b32 	%r3792, %r3686;
	mov.b32 	%r3793, %r3686;
	mov.b32 	%r3794, %r3686;
	mov.b32 	%r3795, %r3686;
	mov.b32 	%r3796, %r3686;
	mov.b32 	%r3797, %r3686;
	mov.b32 	%r3798, %r3686;
	mov.b32 	%r3799, %r3686;
	mov.b32 	%r3800, %r3686;
	mov.b32 	%r3801, %r3686;
	mov.b32 	%r3802, %r3686;
	mov.b32 	%r3803, %r3686;
	mov.b32 	%r3804, %r3686;
	mov.b32 	%r3805, %r3686;
	mov.b32 	%r3806, %r3686;
	mov.b32 	%r3807, %r3686;
	mov.b32 	%r3808, %r3686;
	mov.b32 	%r3809, %r3686;
	mov.b32 	%r3810, %r3686;
	mov.b32 	%r3811, %r3686;
	mov.b32 	%r3812, %r3686;
	mov.b32 	%r3813, %r3686;
	.loc	1 120 22                        // gated_mlp.py:120:22
	@%p1 bra 	$L__BB0_3;
// %bb.1:                               // %.lr.ph
	.loc	1 0 22                          // gated_mlp.py:0:22
	cvt.s64.s32 	%rd1, %r583;
	cvt.s64.s32 	%rd2, %r584;
	cvt.s64.s32 	%rd3, %r585;
	cvt.s64.s32 	%rd4, %r586;
	cvt.s64.s32 	%rd5, %r587;
	cvt.s64.s32 	%rd6, %r588;
	cvt.s64.s32 	%rd7, %r589;
	cvt.s64.s32 	%rd8, %r590;
	cvt.s64.s32 	%rd9, %r591;
	cvt.s64.s32 	%rd10, %r592;
	cvt.s64.s32 	%rd11, %r593;
	cvt.s64.s32 	%rd12, %r594;
	cvt.s64.s32 	%rd13, %r595;
	cvt.s64.s32 	%rd14, %r598;
	shr.s32 	%r600, %r599, 31;
	shr.u32 	%r601, %r600, 25;
	add.s32 	%r602, %r599, %r601;
	shr.s32 	%r31, %r602, 7;
	cvt.s64.s32 	%rd15, %r603;
	add.s32 	%r56, %r31, -2;
	add.s32 	%r3683, %r451, -256;
	.loc	1 120 22                        // gated_mlp.py:120:22
	shl.b64 	%rd16, %rd14, 1;
	shl.b64 	%rd108, %rd15, 2;
	add.s64 	%rd217, %rd40, %rd108;
	shl.b64 	%rd18, %rd15, 1;
	mad.lo.s32 	%r696, %r452, %r29, %r12;
	mul.wide.s32 	%rd19, %r696, 2;
	mad.lo.s32 	%r698, %r452, %r28, %r12;
	mul.wide.s32 	%rd20, %r698, 2;
	shl.b64 	%rd21, %rd13, 1;
	shl.b64 	%rd22, %rd12, 1;
	shl.b64 	%rd23, %rd11, 1;
	shl.b64 	%rd24, %rd10, 1;
	shl.b64 	%rd25, %rd9, 1;
	shl.b64 	%rd26, %rd8, 1;
	shl.b64 	%rd27, %rd7, 1;
	shl.b64 	%rd28, %rd6, 1;
	shl.b64 	%rd29, %rd5, 1;
	shl.b64 	%rd30, %rd4, 1;
	shl.b64 	%rd31, %rd3, 1;
	shl.b64 	%rd32, %rd2, 1;
	shl.b64 	%rd33, %rd1, 1;
	add.s32 	%r699, %r8, %r7;
	mul.wide.u32 	%rd109, %r699, 2;
	add.s64 	%rd110, %rd109, %rd39;
	add.s64 	%rd216, %rd110, 512;
	mov.b32 	%r3011, 0;
	mov.b32 	%r3686, 0f00000000;
	mov.b32 	%r3685, 1;
	mov.b32 	%r3684, -1;
	mov.b32 	%r3687, %r3686;
	mov.b32 	%r3688, %r3686;
	mov.b32 	%r3689, %r3686;
	mov.b32 	%r3690, %r3686;
	mov.b32 	%r3691, %r3686;
	mov.b32 	%r3692, %r3686;
	mov.b32 	%r3693, %r3686;
	mov.b32 	%r3694, %r3686;
	mov.b32 	%r3695, %r3686;
	mov.b32 	%r3696, %r3686;
	mov.b32 	%r3697, %r3686;
	mov.b32 	%r3698, %r3686;
	mov.b32 	%r3699, %r3686;
	mov.b32 	%r3700, %r3686;
	mov.b32 	%r3701, %r3686;
	mov.b32 	%r3702, %r3686;
	mov.b32 	%r3703, %r3686;
	mov.b32 	%r3704, %r3686;
	mov.b32 	%r3705, %r3686;
	mov.b32 	%r3706, %r3686;
	mov.b32 	%r3707, %r3686;
	mov.b32 	%r3708, %r3686;
	mov.b32 	%r3709, %r3686;
	mov.b32 	%r3710, %r3686;
	mov.b32 	%r3711, %r3686;
	mov.b32 	%r3712, %r3686;
	mov.b32 	%r3713, %r3686;
	mov.b32 	%r3714, %r3686;
	mov.b32 	%r3715, %r3686;
	mov.b32 	%r3716, %r3686;
	mov.b32 	%r3717, %r3686;
	mov.b32 	%r3718, %r3686;
	mov.b32 	%r3719, %r3686;
	mov.b32 	%r3720, %r3686;
	mov.b32 	%r3721, %r3686;
	mov.b32 	%r3722, %r3686;
	mov.b32 	%r3723, %r3686;
	mov.b32 	%r3724, %r3686;
	mov.b32 	%r3725, %r3686;
	mov.b32 	%r3726, %r3686;
	mov.b32 	%r3727, %r3686;
	mov.b32 	%r3728, %r3686;
	mov.b32 	%r3729, %r3686;
	mov.b32 	%r3730, %r3686;
	mov.b32 	%r3731, %r3686;
	mov.b32 	%r3732, %r3686;
	mov.b32 	%r3733, %r3686;
	mov.b32 	%r3734, %r3686;
	mov.b32 	%r3735, %r3686;
	mov.b32 	%r3736, %r3686;
	mov.b32 	%r3737, %r3686;
	mov.b32 	%r3738, %r3686;
	mov.b32 	%r3739, %r3686;
	mov.b32 	%r3740, %r3686;
	mov.b32 	%r3741, %r3686;
	mov.b32 	%r3742, %r3686;
	mov.b32 	%r3743, %r3686;
	mov.b32 	%r3744, %r3686;
	mov.b32 	%r3745, %r3686;
	mov.b32 	%r3746, %r3686;
	mov.b32 	%r3747, %r3686;
	mov.b32 	%r3748, %r3686;
	mov.b32 	%r3749, %r3686;
	mov.b32 	%r3750, %r3686;
	mov.b32 	%r3751, %r3686;
	mov.b32 	%r3752, %r3686;
	mov.b32 	%r3753, %r3686;
	mov.b32 	%r3754, %r3686;
	mov.b32 	%r3755, %r3686;
	mov.b32 	%r3756, %r3686;
	mov.b32 	%r3757, %r3686;
	mov.b32 	%r3758, %r3686;
	mov.b32 	%r3759, %r3686;
	mov.b32 	%r3760, %r3686;
	mov.b32 	%r3761, %r3686;
	mov.b32 	%r3762, %r3686;
	mov.b32 	%r3763, %r3686;
	mov.b32 	%r3764, %r3686;
	mov.b32 	%r3765, %r3686;
	mov.b32 	%r3766, %r3686;
	mov.b32 	%r3767, %r3686;
	mov.b32 	%r3768, %r3686;
	mov.b32 	%r3769, %r3686;
	mov.b32 	%r3770, %r3686;
	mov.b32 	%r3771, %r3686;
	mov.b32 	%r3772, %r3686;
	mov.b32 	%r3773, %r3686;
	mov.b32 	%r3774, %r3686;
	mov.b32 	%r3775, %r3686;
	mov.b32 	%r3776, %r3686;
	mov.b32 	%r3777, %r3686;
	mov.b32 	%r3778, %r3686;
	mov.b32 	%r3779, %r3686;
	mov.b32 	%r3780, %r3686;
	mov.b32 	%r3781, %r3686;
	mov.b32 	%r3782, %r3686;
	mov.b32 	%r3783, %r3686;
	mov.b32 	%r3784, %r3686;
	mov.b32 	%r3785, %r3686;
	mov.b32 	%r3786, %r3686;
	mov.b32 	%r3787, %r3686;
	mov.b32 	%r3788, %r3686;
	mov.b32 	%r3789, %r3686;
	mov.b32 	%r3790, %r3686;
	mov.b32 	%r3791, %r3686;
	mov.b32 	%r3792, %r3686;
	mov.b32 	%r3793, %r3686;
	mov.b32 	%r3794, %r3686;
	mov.b32 	%r3795, %r3686;
	mov.b32 	%r3796, %r3686;
	mov.b32 	%r3797, %r3686;
	mov.b32 	%r3798, %r3686;
	mov.b32 	%r3799, %r3686;
	mov.b32 	%r3800, %r3686;
	mov.b32 	%r3801, %r3686;
	mov.b32 	%r3802, %r3686;
	mov.b32 	%r3803, %r3686;
	mov.b32 	%r3804, %r3686;
	mov.b32 	%r3805, %r3686;
	mov.b32 	%r3806, %r3686;
	mov.b32 	%r3807, %r3686;
	mov.b32 	%r3808, %r3686;
	mov.b32 	%r3809, %r3686;
	mov.b32 	%r3810, %r3686;
	mov.b32 	%r3811, %r3686;
	mov.b32 	%r3812, %r3686;
	mov.b32 	%r3813, %r3686;
	mov.b32 	%r3814, %r3011;
$L__BB0_2:                              // =>This Inner Loop Header: Depth=1
	setp.lt.s32 	%p46, %r3814, %r56;
	add.s32 	%r3064, %r3684, 1;
	setp.gt.s32 	%p47, %r3064, 2;
	selp.b32 	%r3684, 0, %r3064, %p47;
	.loc	1 123 20                        // gated_mlp.py:123:20
	cp.async.wait_group 	2;
	bar.sync 	0;
	shl.b32 	%r3065, %r3684, 15;
	add.s32 	%r2876, %r615, %r3065;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r3068, %r3684, 16;
	add.s32 	%r2879, %r614, %r3068;
	.loc	1 126 35                        // gated_mlp.py:126:35
	shfl.sync.idx.b32 	%r3069, %r13, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r3070, %r3069, 11;
	and.b32 	%r3071, %r3070, 8192;
	add.s32 	%r3072, %r3071, %r2876;
	bfe.u32 	%r3073, %r3072, 4, 14;
	cvt.u64.u32 	%rd151, %r3073;
	or.b64 	%rd111, %rd151, 4611686293372403712;
	bfe.u32 	%r3074, %r2879, 4, 14;
	cvt.u64.u32 	%rd152, %r3074;
	or.b64 	%rd112, %rd152, 4611686293372403712;
	mov.pred 	%p38, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd111, %rd112, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3075, %r3072, 32;
	bfe.u32 	%r3076, %r3075, 4, 14;
	cvt.u64.u32 	%rd153, %r3076;
	or.b64 	%rd113, %rd153, 4611686293372403712;
	add.s32 	%r3077, %r2879, 2048;
	bfe.u32 	%r3078, %r3077, 4, 14;
	cvt.u64.u32 	%rd154, %r3078;
	or.b64 	%rd114, %rd154, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd113, %rd114, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3079, %r3072, 64;
	bfe.u32 	%r3080, %r3079, 4, 14;
	cvt.u64.u32 	%rd155, %r3080;
	or.b64 	%rd115, %rd155, 4611686293372403712;
	add.s32 	%r3081, %r2879, 4096;
	bfe.u32 	%r3082, %r3081, 4, 14;
	cvt.u64.u32 	%rd156, %r3082;
	or.b64 	%rd116, %rd156, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd115, %rd116, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3083, %r3072, 96;
	bfe.u32 	%r3084, %r3083, 4, 14;
	cvt.u64.u32 	%rd157, %r3084;
	or.b64 	%rd117, %rd157, 4611686293372403712;
	add.s32 	%r3085, %r2879, 6144;
	bfe.u32 	%r3086, %r3085, 4, 14;
	cvt.u64.u32 	%rd158, %r3086;
	or.b64 	%rd118, %rd158, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd117, %rd118, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3087, %r3072, 16384;
	bfe.u32 	%r3088, %r3087, 4, 14;
	cvt.u64.u32 	%rd159, %r3088;
	or.b64 	%rd119, %rd159, 4611686293372403712;
	add.s32 	%r3089, %r2879, 8192;
	bfe.u32 	%r3090, %r3089, 4, 14;
	cvt.u64.u32 	%rd160, %r3090;
	or.b64 	%rd120, %rd160, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd119, %rd120, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3091, %r3072, 16416;
	bfe.u32 	%r3092, %r3091, 4, 14;
	cvt.u64.u32 	%rd161, %r3092;
	or.b64 	%rd121, %rd161, 4611686293372403712;
	add.s32 	%r3093, %r2879, 10240;
	bfe.u32 	%r3094, %r3093, 4, 14;
	cvt.u64.u32 	%rd162, %r3094;
	or.b64 	%rd122, %rd162, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd121, %rd122, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3095, %r3072, 16448;
	bfe.u32 	%r3096, %r3095, 4, 14;
	cvt.u64.u32 	%rd163, %r3096;
	or.b64 	%rd123, %rd163, 4611686293372403712;
	add.s32 	%r3097, %r2879, 12288;
	bfe.u32 	%r3098, %r3097, 4, 14;
	cvt.u64.u32 	%rd164, %r3098;
	or.b64 	%rd124, %rd164, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd123, %rd124, %p38, 1, 1, 0, 1;
	// end inline asm
	add.s32 	%r3099, %r3072, 16480;
	bfe.u32 	%r3100, %r3099, 4, 14;
	cvt.u64.u32 	%rd165, %r3100;
	or.b64 	%rd125, %rd165, 4611686293372403712;
	add.s32 	%r3101, %r2879, 14336;
	bfe.u32 	%r3102, %r3101, 4, 14;
	cvt.u64.u32 	%rd166, %r3102;
	or.b64 	%rd126, %rd166, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813}, %rd125, %rd126, %p38, 1, 1, 0, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	mov.b32 	%r2877, %r3011;
	mov.b32 	%r2878, %r3011;
	mov.b32 	%r2880, %r3011;
	mov.b32 	%r2881, %r3011;
	// begin inline asm
	// wait for regs: %r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813,%r2876,%r2877,%r2878,%r2879,%r2880,%r2881
	wgmma.wait_group.sync.aligned 1;
	// end inline asm
	.loc	1 129 18                        // gated_mlp.py:129:18
	add.s64 	%rd135, %rd217, %rd33;
	add.s64 	%rd136, %rd217, %rd32;
	add.s64 	%rd137, %rd217, %rd31;
	add.s64 	%rd138, %rd217, %rd30;
	add.s64 	%rd139, %rd217, %rd29;
	add.s64 	%rd140, %rd217, %rd28;
	add.s64 	%rd141, %rd217, %rd27;
	add.s64 	%rd142, %rd217, %rd26;
	add.s64 	%rd143, %rd217, %rd25;
	add.s64 	%rd144, %rd217, %rd24;
	add.s64 	%rd145, %rd217, %rd23;
	add.s64 	%rd146, %rd217, %rd22;
	add.s64 	%rd147, %rd217, %rd21;
	add.s64 	%rd148, %rd217, %rd20;
	add.s64 	%rd149, %rd217, %rd19;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s64 	%rd150, %rd217, %rd16;
	add.s32 	%r3103, %r3685, 1;
	setp.gt.s32 	%p48, %r3103, 2;
	selp.b32 	%r3685, 0, %r3103, %p48;
	.loc	1 123 51                        // gated_mlp.py:123:51
	setp.lt.s32 	%p49, %r9, %r3683;
	.loc	1 123 20                        // gated_mlp.py:123:20
	shl.b32 	%r3104, %r3685, 15;
	add.s32 	%r3105, %r615, %r3104;
	bar.sync 	0;
	add.s32 	%r3016, %r3105, %r613;
	add.s32 	%r3018, %r3105, %r619;
	add.s32 	%r3020, %r3105, %r621;
	add.s32 	%r3022, %r3105, %r623;
	add.s32 	%r3024, %r3105, %r625;
	add.s32 	%r3026, %r3105, %r627;
	add.s32 	%r3028, %r3105, %r629;
	add.s32 	%r3030, %r3105, %r631;
	selp.b32 	%r3114, 16, 0, %p49;
	selp.b32 	%r3019, %r3114, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3016 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3018 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3020 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3022 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3024 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3026 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3028 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3030 + 0 ], [ %rd216 + 0 ], 0x10, %r3019;
	// end inline asm
	cp.async.commit_group;
	.loc	1 124 51                        // gated_mlp.py:124:51
	setp.lt.s32 	%p50, %r15, %r3683;
	setp.lt.s32 	%p51, %r16, %r3683;
	setp.lt.s32 	%p52, %r17, %r3683;
	setp.lt.s32 	%p53, %r18, %r3683;
	setp.lt.s32 	%p54, %r19, %r3683;
	setp.lt.s32 	%p55, %r20, %r3683;
	setp.lt.s32 	%p56, %r21, %r3683;
	setp.lt.s32 	%p57, %r22, %r3683;
	setp.lt.s32 	%p58, %r23, %r3683;
	setp.lt.s32 	%p59, %r24, %r3683;
	setp.lt.s32 	%p60, %r25, %r3683;
	setp.lt.s32 	%p61, %r26, %r3683;
	setp.lt.s32 	%p62, %r27, %r3683;
	setp.lt.s32 	%p63, %r28, %r3683;
	setp.lt.s32 	%p64, %r29, %r3683;
	setp.lt.s32 	%p65, %r30, %r3683;
	.loc	1 124 20                        // gated_mlp.py:124:20
	shl.b32 	%r3115, %r3685, 16;
	add.s32 	%r3116, %r614, %r3115;
	add.s32 	%r3032, %r3116, %r640;
	add.s32 	%r3034, %r3116, %r642;
	add.s32 	%r3036, %r3116, %r644;
	add.s32 	%r3038, %r3116, %r646;
	add.s32 	%r3040, %r3116, %r648;
	add.s32 	%r3042, %r3116, %r650;
	add.s32 	%r3044, %r3116, %r652;
	add.s32 	%r3046, %r3116, %r654;
	add.s32 	%r3048, %r3116, %r656;
	add.s32 	%r3050, %r3116, %r658;
	add.s32 	%r3052, %r3116, %r660;
	add.s32 	%r3054, %r3116, %r662;
	add.s32 	%r3056, %r3116, %r664;
	add.s32 	%r3058, %r3116, %r666;
	add.s32 	%r3060, %r3116, %r668;
	add.s32 	%r3062, %r3116, %r670;
	selp.b32 	%r3133, 16, 0, %p50;
	selp.b32 	%r3033, %r3133, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3032 + 0 ], [ %rd135 + 0 ], 0x10, %r3033;
	// end inline asm
	selp.b32 	%r3134, 16, 0, %p51;
	selp.b32 	%r3035, %r3134, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3034 + 0 ], [ %rd136 + 0 ], 0x10, %r3035;
	// end inline asm
	selp.b32 	%r3135, 16, 0, %p52;
	selp.b32 	%r3037, %r3135, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3036 + 0 ], [ %rd137 + 0 ], 0x10, %r3037;
	// end inline asm
	selp.b32 	%r3136, 16, 0, %p53;
	selp.b32 	%r3039, %r3136, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3038 + 0 ], [ %rd138 + 0 ], 0x10, %r3039;
	// end inline asm
	selp.b32 	%r3137, 16, 0, %p54;
	selp.b32 	%r3041, %r3137, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3040 + 0 ], [ %rd139 + 0 ], 0x10, %r3041;
	// end inline asm
	selp.b32 	%r3138, 16, 0, %p55;
	selp.b32 	%r3043, %r3138, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3042 + 0 ], [ %rd140 + 0 ], 0x10, %r3043;
	// end inline asm
	selp.b32 	%r3139, 16, 0, %p56;
	selp.b32 	%r3045, %r3139, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3044 + 0 ], [ %rd141 + 0 ], 0x10, %r3045;
	// end inline asm
	selp.b32 	%r3140, 16, 0, %p57;
	selp.b32 	%r3047, %r3140, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3046 + 0 ], [ %rd142 + 0 ], 0x10, %r3047;
	// end inline asm
	selp.b32 	%r3141, 16, 0, %p58;
	selp.b32 	%r3049, %r3141, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3048 + 0 ], [ %rd143 + 0 ], 0x10, %r3049;
	// end inline asm
	selp.b32 	%r3142, 16, 0, %p59;
	selp.b32 	%r3051, %r3142, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3050 + 0 ], [ %rd144 + 0 ], 0x10, %r3051;
	// end inline asm
	selp.b32 	%r3143, 16, 0, %p60;
	selp.b32 	%r3053, %r3143, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3052 + 0 ], [ %rd145 + 0 ], 0x10, %r3053;
	// end inline asm
	selp.b32 	%r3144, 16, 0, %p61;
	selp.b32 	%r3055, %r3144, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3054 + 0 ], [ %rd146 + 0 ], 0x10, %r3055;
	// end inline asm
	selp.b32 	%r3145, 16, 0, %p62;
	selp.b32 	%r3057, %r3145, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3056 + 0 ], [ %rd147 + 0 ], 0x10, %r3057;
	// end inline asm
	selp.b32 	%r3146, 16, 0, %p63;
	selp.b32 	%r3059, %r3146, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3058 + 0 ], [ %rd148 + 0 ], 0x10, %r3059;
	// end inline asm
	selp.b32 	%r3147, 16, 0, %p64;
	selp.b32 	%r3061, %r3147, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3060 + 0 ], [ %rd149 + 0 ], 0x10, %r3061;
	// end inline asm
	selp.b32 	%r3148, 16, 0, %p65;
	selp.b32 	%r3063, %r3148, 0, %p46;
	// begin inline asm
	cp.async.cg.shared.global [ %r3062 + 0 ], [ %rd150 + 0 ], 0x10, %r3063;
	// end inline asm
	cp.async.commit_group;
	.loc	1 120 22                        // gated_mlp.py:120:22
	add.s32 	%r3814, %r3814, 1;
	add.s64 	%rd217, %rd217, %rd18;
	add.s64 	%rd216, %rd216, 256;
	add.s32 	%r3683, %r3683, -128;
	setp.ne.s32 	%p66, %r31, %r3814;
	@%p66 bra 	$L__BB0_2;
$L__BB0_3:                              // %._crit_edge
	.loc	1 98 54                         // gated_mlp.py:98:54
	mul.lo.s32 	%r3549, %r4, %r2;
	sub.s32 	%r3550, %r3, %r3549;
	.loc	1 98 27                         // gated_mlp.py:98:27
	add.s32 	%r3551, %r3550, %r1;
	.loc	1 120 22                        // gated_mlp.py:120:22
	// begin inline asm
	// wait for regs: %r3686,%r3687,%r3688,%r3689,%r3690,%r3691,%r3692,%r3693,%r3694,%r3695,%r3696,%r3697,%r3698,%r3699,%r3700,%r3701,%r3702,%r3703,%r3704,%r3705,%r3706,%r3707,%r3708,%r3709,%r3710,%r3711,%r3712,%r3713,%r3714,%r3715,%r3716,%r3717,%r3718,%r3719,%r3720,%r3721,%r3722,%r3723,%r3724,%r3725,%r3726,%r3727,%r3728,%r3729,%r3730,%r3731,%r3732,%r3733,%r3734,%r3735,%r3736,%r3737,%r3738,%r3739,%r3740,%r3741,%r3742,%r3743,%r3744,%r3745,%r3746,%r3747,%r3748,%r3749,%r3750,%r3751,%r3752,%r3753,%r3754,%r3755,%r3756,%r3757,%r3758,%r3759,%r3760,%r3761,%r3762,%r3763,%r3764,%r3765,%r3766,%r3767,%r3768,%r3769,%r3770,%r3771,%r3772,%r3773,%r3774,%r3775,%r3776,%r3777,%r3778,%r3779,%r3780,%r3781,%r3782,%r3783,%r3784,%r3785,%r3786,%r3787,%r3788,%r3789,%r3790,%r3791,%r3792,%r3793,%r3794,%r3795,%r3796,%r3797,%r3798,%r3799,%r3800,%r3801,%r3802,%r3803,%r3804,%r3805,%r3806,%r3807,%r3808,%r3809,%r3810,%r3811,%r3812,%r3813
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	cp.async.wait_group 	0;
	bar.sync 	0;
	.loc	1 134 23                        // gated_mlp.py:134:23
	cvt.rn.f16x2.f32 	%r3406, %r3687, %r3686;
	cvt.rn.f16x2.f32 	%r3407, %r3689, %r3688;
	cvt.rn.f16x2.f32 	%r3408, %r3691, %r3690;
	cvt.rn.f16x2.f32 	%r3409, %r3693, %r3692;
	cvt.rn.f16x2.f32 	%r3411, %r3695, %r3694;
	cvt.rn.f16x2.f32 	%r3412, %r3697, %r3696;
	cvt.rn.f16x2.f32 	%r3413, %r3699, %r3698;
	cvt.rn.f16x2.f32 	%r3414, %r3701, %r3700;
	cvt.rn.f16x2.f32 	%r3416, %r3703, %r3702;
	cvt.rn.f16x2.f32 	%r3417, %r3705, %r3704;
	cvt.rn.f16x2.f32 	%r3418, %r3707, %r3706;
	cvt.rn.f16x2.f32 	%r3419, %r3709, %r3708;
	cvt.rn.f16x2.f32 	%r3421, %r3711, %r3710;
	cvt.rn.f16x2.f32 	%r3422, %r3713, %r3712;
	cvt.rn.f16x2.f32 	%r3423, %r3715, %r3714;
	cvt.rn.f16x2.f32 	%r3424, %r3717, %r3716;
	cvt.rn.f16x2.f32 	%r3426, %r3719, %r3718;
	cvt.rn.f16x2.f32 	%r3427, %r3721, %r3720;
	cvt.rn.f16x2.f32 	%r3428, %r3723, %r3722;
	cvt.rn.f16x2.f32 	%r3429, %r3725, %r3724;
	cvt.rn.f16x2.f32 	%r3431, %r3727, %r3726;
	cvt.rn.f16x2.f32 	%r3432, %r3729, %r3728;
	cvt.rn.f16x2.f32 	%r3433, %r3731, %r3730;
	cvt.rn.f16x2.f32 	%r3434, %r3733, %r3732;
	cvt.rn.f16x2.f32 	%r3436, %r3735, %r3734;
	cvt.rn.f16x2.f32 	%r3437, %r3737, %r3736;
	cvt.rn.f16x2.f32 	%r3438, %r3739, %r3738;
	cvt.rn.f16x2.f32 	%r3439, %r3741, %r3740;
	cvt.rn.f16x2.f32 	%r3441, %r3743, %r3742;
	cvt.rn.f16x2.f32 	%r3442, %r3745, %r3744;
	cvt.rn.f16x2.f32 	%r3443, %r3747, %r3746;
	cvt.rn.f16x2.f32 	%r3444, %r3749, %r3748;
	cvt.rn.f16x2.f32 	%r3446, %r3751, %r3750;
	cvt.rn.f16x2.f32 	%r3447, %r3753, %r3752;
	cvt.rn.f16x2.f32 	%r3448, %r3755, %r3754;
	cvt.rn.f16x2.f32 	%r3449, %r3757, %r3756;
	cvt.rn.f16x2.f32 	%r3451, %r3759, %r3758;
	cvt.rn.f16x2.f32 	%r3452, %r3761, %r3760;
	cvt.rn.f16x2.f32 	%r3453, %r3763, %r3762;
	cvt.rn.f16x2.f32 	%r3454, %r3765, %r3764;
	cvt.rn.f16x2.f32 	%r3456, %r3767, %r3766;
	cvt.rn.f16x2.f32 	%r3457, %r3769, %r3768;
	cvt.rn.f16x2.f32 	%r3458, %r3771, %r3770;
	cvt.rn.f16x2.f32 	%r3459, %r3773, %r3772;
	cvt.rn.f16x2.f32 	%r3461, %r3775, %r3774;
	cvt.rn.f16x2.f32 	%r3462, %r3777, %r3776;
	cvt.rn.f16x2.f32 	%r3463, %r3779, %r3778;
	cvt.rn.f16x2.f32 	%r3464, %r3781, %r3780;
	cvt.rn.f16x2.f32 	%r3466, %r3783, %r3782;
	cvt.rn.f16x2.f32 	%r3467, %r3785, %r3784;
	cvt.rn.f16x2.f32 	%r3468, %r3787, %r3786;
	cvt.rn.f16x2.f32 	%r3469, %r3789, %r3788;
	cvt.rn.f16x2.f32 	%r3471, %r3791, %r3790;
	cvt.rn.f16x2.f32 	%r3472, %r3793, %r3792;
	cvt.rn.f16x2.f32 	%r3473, %r3795, %r3794;
	cvt.rn.f16x2.f32 	%r3474, %r3797, %r3796;
	cvt.rn.f16x2.f32 	%r3476, %r3799, %r3798;
	cvt.rn.f16x2.f32 	%r3477, %r3801, %r3800;
	cvt.rn.f16x2.f32 	%r3478, %r3803, %r3802;
	cvt.rn.f16x2.f32 	%r3479, %r3805, %r3804;
	cvt.rn.f16x2.f32 	%r3481, %r3807, %r3806;
	cvt.rn.f16x2.f32 	%r3482, %r3809, %r3808;
	cvt.rn.f16x2.f32 	%r3483, %r3811, %r3810;
	cvt.rn.f16x2.f32 	%r3484, %r3813, %r3812;
	.loc	1 138 22                        // gated_mlp.py:138:22
	shl.b32 	%r3552, %r3551, 7;
	.loc	1 138 37                        // gated_mlp.py:138:37
	or.b32 	%r3553, %r3552, %r15;
	or.b32 	%r3554, %r3552, %r16;
	or.b32 	%r3555, %r3552, %r17;
	or.b32 	%r3556, %r3552, %r18;
	or.b32 	%r3557, %r3552, %r19;
	or.b32 	%r3558, %r3552, %r20;
	or.b32 	%r3559, %r3552, %r21;
	or.b32 	%r3560, %r3552, %r22;
	or.b32 	%r3561, %r3552, %r23;
	or.b32 	%r3562, %r3552, %r24;
	or.b32 	%r3563, %r3552, %r25;
	or.b32 	%r3564, %r3552, %r26;
	or.b32 	%r3565, %r3552, %r27;
	or.b32 	%r3566, %r3552, %r28;
	or.b32 	%r3567, %r3552, %r29;
	or.b32 	%r3568, %r3552, %r30;
	.loc	1 140 33                        // gated_mlp.py:140:33
	mul.lo.s32 	%r3569, %r3553, %r453;
	mul.lo.s32 	%r3570, %r3554, %r453;
	mul.lo.s32 	%r3571, %r3555, %r453;
	mul.lo.s32 	%r3572, %r3556, %r453;
	mul.lo.s32 	%r3573, %r3557, %r453;
	mul.lo.s32 	%r3574, %r3558, %r453;
	mul.lo.s32 	%r3575, %r3559, %r453;
	mul.lo.s32 	%r3576, %r3560, %r453;
	mul.lo.s32 	%r3577, %r3561, %r453;
	mul.lo.s32 	%r3578, %r3562, %r453;
	mul.lo.s32 	%r3579, %r3563, %r453;
	mul.lo.s32 	%r3580, %r3564, %r453;
	mul.lo.s32 	%r3581, %r3565, %r453;
	mul.lo.s32 	%r3582, %r3566, %r453;
	mul.lo.s32 	%r3583, %r3567, %r453;
	mul.lo.s32 	%r3584, %r3568, %r453;
	.loc	1 140 21                        // gated_mlp.py:140:21
	mul.wide.s32 	%rd183, %r3569, 2;
	add.s64 	%rd184, %rd41, %rd183;
	mul.wide.s32 	%rd185, %r3570, 2;
	add.s64 	%rd186, %rd41, %rd185;
	mul.wide.s32 	%rd187, %r3571, 2;
	add.s64 	%rd188, %rd41, %rd187;
	mul.wide.s32 	%rd189, %r3572, 2;
	add.s64 	%rd190, %rd41, %rd189;
	mul.wide.s32 	%rd191, %r3573, 2;
	add.s64 	%rd192, %rd41, %rd191;
	mul.wide.s32 	%rd193, %r3574, 2;
	add.s64 	%rd194, %rd41, %rd193;
	mul.wide.s32 	%rd195, %r3575, 2;
	add.s64 	%rd196, %rd41, %rd195;
	mul.wide.s32 	%rd197, %r3576, 2;
	add.s64 	%rd198, %rd41, %rd197;
	mul.wide.s32 	%rd199, %r3577, 2;
	add.s64 	%rd200, %rd41, %rd199;
	mul.wide.s32 	%rd201, %r3578, 2;
	add.s64 	%rd202, %rd41, %rd201;
	mul.wide.s32 	%rd203, %r3579, 2;
	add.s64 	%rd204, %rd41, %rd203;
	mul.wide.s32 	%rd205, %r3580, 2;
	add.s64 	%rd206, %rd41, %rd205;
	mul.wide.s32 	%rd207, %r3581, 2;
	add.s64 	%rd208, %rd41, %rd207;
	mul.wide.s32 	%rd209, %r3582, 2;
	add.s64 	%rd210, %rd41, %rd209;
	mul.wide.s32 	%rd211, %r3583, 2;
	add.s64 	%rd212, %rd41, %rd211;
	mul.wide.s32 	%rd213, %r3584, 2;
	add.s64 	%rd214, %rd41, %rd213;
	.loc	1 140 52                        // gated_mlp.py:140:52
	mul.wide.s32 	%rd215, %r11, 2;
	add.s64 	%rd167, %rd184, %rd215;
	add.s64 	%rd168, %rd186, %rd215;
	add.s64 	%rd169, %rd188, %rd215;
	add.s64 	%rd170, %rd190, %rd215;
	add.s64 	%rd171, %rd192, %rd215;
	add.s64 	%rd172, %rd194, %rd215;
	add.s64 	%rd173, %rd196, %rd215;
	add.s64 	%rd174, %rd198, %rd215;
	add.s64 	%rd175, %rd200, %rd215;
	add.s64 	%rd176, %rd202, %rd215;
	add.s64 	%rd177, %rd204, %rd215;
	add.s64 	%rd178, %rd206, %rd215;
	add.s64 	%rd179, %rd208, %rd215;
	add.s64 	%rd180, %rd210, %rd215;
	add.s64 	%rd181, %rd212, %rd215;
	add.s64 	%rd182, %rd214, %rd215;
	.loc	1 141 33                        // gated_mlp.py:141:33
	setp.lt.s32 	%p83, %r3553, 1;
	setp.lt.s32 	%p84, %r3554, 1;
	setp.lt.s32 	%p85, %r3555, 1;
	setp.lt.s32 	%p86, %r3556, 1;
	setp.lt.s32 	%p87, %r3557, 1;
	setp.lt.s32 	%p88, %r3558, 1;
	setp.lt.s32 	%p89, %r3559, 1;
	setp.lt.s32 	%p90, %r3560, 1;
	setp.lt.s32 	%p91, %r3561, 1;
	setp.lt.s32 	%p92, %r3562, 1;
	setp.lt.s32 	%p93, %r3563, 1;
	setp.lt.s32 	%p94, %r3564, 1;
	setp.lt.s32 	%p95, %r3565, 1;
	setp.lt.s32 	%p96, %r3566, 1;
	setp.lt.s32 	%p97, %r3567, 1;
	setp.lt.s32 	%p98, %r3568, 1;
	.loc	1 141 58                        // gated_mlp.py:141:58
	setp.lt.s32 	%p99, %r11, %r450;
	.loc	1 141 39                        // gated_mlp.py:141:39
	and.pred 	%p67, %p99, %p83;
	and.pred 	%p68, %p99, %p84;
	and.pred 	%p69, %p99, %p85;
	and.pred 	%p70, %p99, %p86;
	and.pred 	%p71, %p99, %p87;
	and.pred 	%p72, %p99, %p88;
	and.pred 	%p73, %p99, %p89;
	and.pred 	%p74, %p99, %p90;
	and.pred 	%p75, %p99, %p91;
	and.pred 	%p76, %p99, %p92;
	and.pred 	%p77, %p99, %p93;
	and.pred 	%p78, %p99, %p94;
	and.pred 	%p79, %p99, %p95;
	and.pred 	%p80, %p99, %p96;
	and.pred 	%p81, %p99, %p97;
	and.pred 	%p82, %p99, %p98;
	.loc	1 142 21                        // gated_mlp.py:142:21
	shl.b32 	%r3585, %r5, 8;
	and.b32 	%r3586, %r3585, 3840;
	shr.u32 	%r3587, %r10, 1;
	or.b32 	%r3588, %r3586, %r3587;
	shl.b32 	%r3589, %r5, 7;
	and.b32 	%r3590, %r3589, 12288;
	or.b32 	%r3591, %r3588, %r3590;
	shl.b32 	%r3592, %r14, 7;
	or.b32 	%r3593, %r3591, %r3592;
	and.b32 	%r3594, %r6, 2040;
	shr.u32 	%r3595, %r3593, 4;
	add.s32 	%r3597, %r614, %r3595;
	shl.b32 	%r3598, %r3593, 1;
	add.s32 	%r3405, %r3597, %r3598;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3405], {%r3406, %r3407, %r3408, %r3409};
	// end inline asm
	add.s32 	%r3410, %r3405, 32;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3410], {%r3411, %r3412, %r3413, %r3414};
	// end inline asm
	add.s32 	%r3415, %r3405, 64;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3415], {%r3416, %r3417, %r3418, %r3419};
	// end inline asm
	add.s32 	%r3420, %r3405, 96;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3420], {%r3421, %r3422, %r3423, %r3424};
	// end inline asm
	add.s32 	%r3425, %r3405, 128;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3425], {%r3426, %r3427, %r3428, %r3429};
	// end inline asm
	add.s32 	%r3430, %r3405, 160;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3430], {%r3431, %r3432, %r3433, %r3434};
	// end inline asm
	add.s32 	%r3435, %r3405, 192;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3435], {%r3436, %r3437, %r3438, %r3439};
	// end inline asm
	add.s32 	%r3440, %r3405, 224;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3440], {%r3441, %r3442, %r3443, %r3444};
	// end inline asm
	add.s32 	%r3445, %r3405, 256;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3445], {%r3446, %r3447, %r3448, %r3449};
	// end inline asm
	add.s32 	%r3450, %r3405, 288;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3450], {%r3451, %r3452, %r3453, %r3454};
	// end inline asm
	add.s32 	%r3455, %r3405, 320;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3455], {%r3456, %r3457, %r3458, %r3459};
	// end inline asm
	add.s32 	%r3460, %r3405, 352;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3460], {%r3461, %r3462, %r3463, %r3464};
	// end inline asm
	add.s32 	%r3465, %r3405, 384;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3465], {%r3466, %r3467, %r3468, %r3469};
	// end inline asm
	add.s32 	%r3470, %r3405, 416;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3470], {%r3471, %r3472, %r3473, %r3474};
	// end inline asm
	add.s32 	%r3475, %r3405, 448;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3475], {%r3476, %r3477, %r3478, %r3479};
	// end inline asm
	add.s32 	%r3480, %r3405, 480;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r3480], {%r3481, %r3482, %r3483, %r3484};
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r3599, %r5, 1;
	and.b32 	%r3600, %r3599, 112;
	add.s32 	%r3601, %r614, %r3600;
	shl.b32 	%r3602, %r3594, 1;
	add.s32 	%r3603, %r3601, %r3602;
	ld.shared.v4.b32 	{%r3485, %r3486, %r3487, %r3488}, [%r3603];
	or.b32 	%r3604, %r3594, 2048;
	shr.u32 	%r3605, %r3604, 4;
	and.b32 	%r3606, %r3605, 240;
	add.s32 	%r3607, %r614, %r3606;
	add.s32 	%r3608, %r3607, %r3602;
	ld.shared.v4.b32 	{%r3489, %r3490, %r3491, %r3492}, [%r3608+4096];
	or.b32 	%r3609, %r3594, 4096;
	shr.u32 	%r3610, %r3609, 4;
	and.b32 	%r3611, %r3610, 368;
	add.s32 	%r3612, %r614, %r3611;
	add.s32 	%r3613, %r3612, %r3602;
	ld.shared.v4.b32 	{%r3493, %r3494, %r3495, %r3496}, [%r3613+8192];
	or.b32 	%r3614, %r6, 6144;
	shr.u32 	%r3615, %r3614, 4;
	and.b32 	%r3616, %r3615, 496;
	add.s32 	%r3617, %r614, %r3616;
	shl.b32 	%r3618, %r3614, 1;
	add.s32 	%r3619, %r3617, %r3618;
	ld.shared.v4.b32 	{%r3497, %r3498, %r3499, %r3500}, [%r3619];
	or.b32 	%r3620, %r6, 8192;
	shr.u32 	%r3621, %r3620, 4;
	and.b32 	%r3622, %r3621, 624;
	add.s32 	%r3623, %r614, %r3622;
	add.s32 	%r3624, %r3623, %r3602;
	ld.shared.v4.b32 	{%r3501, %r3502, %r3503, %r3504}, [%r3624+16384];
	or.b32 	%r3625, %r3594, 10240;
	shr.u32 	%r3626, %r3625, 4;
	and.b32 	%r3627, %r3626, 752;
	add.s32 	%r3628, %r614, %r3627;
	add.s32 	%r3629, %r3628, %r3602;
	ld.shared.v4.b32 	{%r3505, %r3506, %r3507, %r3508}, [%r3629+20480];
	or.b32 	%r3630, %r3594, 12288;
	shr.u32 	%r3631, %r3630, 4;
	and.b32 	%r3632, %r3631, 880;
	add.s32 	%r3633, %r614, %r3632;
	add.s32 	%r3634, %r3633, %r3602;
	ld.shared.v4.b32 	{%r3509, %r3510, %r3511, %r3512}, [%r3634+24576];
	or.b32 	%r3635, %r6, 14336;
	shr.u32 	%r3636, %r3635, 4;
	and.b32 	%r3637, %r3636, 1008;
	add.s32 	%r3638, %r614, %r3637;
	shl.b32 	%r3639, %r3635, 1;
	add.s32 	%r3640, %r3638, %r3639;
	ld.shared.v4.b32 	{%r3513, %r3514, %r3515, %r3516}, [%r3640];
	or.b32 	%r3641, %r6, 16384;
	shr.u32 	%r3642, %r3641, 4;
	and.b32 	%r3643, %r3642, 1136;
	add.s32 	%r3644, %r614, %r3643;
	add.s32 	%r3645, %r3644, %r3602;
	ld.shared.v4.b32 	{%r3517, %r3518, %r3519, %r3520}, [%r3645+32768];
	or.b32 	%r3646, %r3594, 18432;
	shr.u32 	%r3647, %r3646, 4;
	and.b32 	%r3648, %r3647, 1264;
	add.s32 	%r3649, %r614, %r3648;
	add.s32 	%r3650, %r3649, %r3602;
	ld.shared.v4.b32 	{%r3521, %r3522, %r3523, %r3524}, [%r3650+36864];
	or.b32 	%r3651, %r3594, 20480;
	shr.u32 	%r3652, %r3651, 4;
	and.b32 	%r3653, %r3652, 1392;
	add.s32 	%r3654, %r614, %r3653;
	add.s32 	%r3655, %r3654, %r3602;
	ld.shared.v4.b32 	{%r3525, %r3526, %r3527, %r3528}, [%r3655+40960];
	or.b32 	%r3656, %r6, 22528;
	shr.u32 	%r3657, %r3656, 4;
	and.b32 	%r3658, %r3657, 1520;
	add.s32 	%r3659, %r614, %r3658;
	shl.b32 	%r3660, %r3656, 1;
	add.s32 	%r3661, %r3659, %r3660;
	ld.shared.v4.b32 	{%r3529, %r3530, %r3531, %r3532}, [%r3661];
	or.b32 	%r3662, %r6, 24576;
	shr.u32 	%r3663, %r3662, 4;
	and.b32 	%r3664, %r3663, 1648;
	add.s32 	%r3665, %r614, %r3664;
	add.s32 	%r3666, %r3665, %r3602;
	ld.shared.v4.b32 	{%r3533, %r3534, %r3535, %r3536}, [%r3666+49152];
	or.b32 	%r3667, %r3594, 26624;
	shr.u32 	%r3668, %r3667, 4;
	and.b32 	%r3669, %r3668, 1776;
	add.s32 	%r3670, %r614, %r3669;
	add.s32 	%r3671, %r3670, %r3602;
	ld.shared.v4.b32 	{%r3537, %r3538, %r3539, %r3540}, [%r3671+53248];
	or.b32 	%r3672, %r3594, 28672;
	shr.u32 	%r3673, %r3672, 4;
	and.b32 	%r3674, %r3673, 1904;
	add.s32 	%r3675, %r614, %r3674;
	add.s32 	%r3676, %r3675, %r3602;
	ld.shared.v4.b32 	{%r3541, %r3542, %r3543, %r3544}, [%r3676+57344];
	or.b32 	%r3677, %r6, 30720;
	shr.u32 	%r3678, %r3677, 4;
	and.b32 	%r3679, %r3678, 2032;
	add.s32 	%r3680, %r614, %r3679;
	shl.b32 	%r3681, %r3677, 1;
	add.s32 	%r3682, %r3680, %r3681;
	ld.shared.v4.b32 	{%r3545, %r3546, %r3547, %r3548}, [%r3682];
	// begin inline asm
	@%p67 st.global.v4.b32 [ %rd167 + 0 ], { %r3485, %r3486, %r3487, %r3488 };
	// end inline asm
	// begin inline asm
	@%p68 st.global.v4.b32 [ %rd168 + 0 ], { %r3489, %r3490, %r3491, %r3492 };
	// end inline asm
	// begin inline asm
	@%p69 st.global.v4.b32 [ %rd169 + 0 ], { %r3493, %r3494, %r3495, %r3496 };
	// end inline asm
	// begin inline asm
	@%p70 st.global.v4.b32 [ %rd170 + 0 ], { %r3497, %r3498, %r3499, %r3500 };
	// end inline asm
	// begin inline asm
	@%p71 st.global.v4.b32 [ %rd171 + 0 ], { %r3501, %r3502, %r3503, %r3504 };
	// end inline asm
	// begin inline asm
	@%p72 st.global.v4.b32 [ %rd172 + 0 ], { %r3505, %r3506, %r3507, %r3508 };
	// end inline asm
	// begin inline asm
	@%p73 st.global.v4.b32 [ %rd173 + 0 ], { %r3509, %r3510, %r3511, %r3512 };
	// end inline asm
	// begin inline asm
	@%p74 st.global.v4.b32 [ %rd174 + 0 ], { %r3513, %r3514, %r3515, %r3516 };
	// end inline asm
	// begin inline asm
	@%p75 st.global.v4.b32 [ %rd175 + 0 ], { %r3517, %r3518, %r3519, %r3520 };
	// end inline asm
	// begin inline asm
	@%p76 st.global.v4.b32 [ %rd176 + 0 ], { %r3521, %r3522, %r3523, %r3524 };
	// end inline asm
	// begin inline asm
	@%p77 st.global.v4.b32 [ %rd177 + 0 ], { %r3525, %r3526, %r3527, %r3528 };
	// end inline asm
	// begin inline asm
	@%p78 st.global.v4.b32 [ %rd178 + 0 ], { %r3529, %r3530, %r3531, %r3532 };
	// end inline asm
	// begin inline asm
	@%p79 st.global.v4.b32 [ %rd179 + 0 ], { %r3533, %r3534, %r3535, %r3536 };
	// end inline asm
	// begin inline asm
	@%p80 st.global.v4.b32 [ %rd180 + 0 ], { %r3537, %r3538, %r3539, %r3540 };
	// end inline asm
	// begin inline asm
	@%p81 st.global.v4.b32 [ %rd181 + 0 ], { %r3541, %r3542, %r3543, %r3544 };
	// end inline asm
	// begin inline asm
	@%p82 st.global.v4.b32 [ %rd182 + 0 ], { %r3545, %r3546, %r3547, %r3548 };
	// end inline asm
	.loc	1 142 4                         // gated_mlp.py:142:4
	ret;
$L__tmp5:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/PTX_dataset/triton_ptx/gated_mlp.py"
	.file	2 "/home/joy/miniconda3/envs/ptx/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 157                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x96 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 103                                 // DW_AT_name
.b8 97
.b8 116
.b8 101
.b8 100
.b8 95
.b8 109
.b8 108
.b8 112
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 80
.b8 84
.b8 88
.b8 95
.b8 100
.b8 97
.b8 116
.b8 97
.b8 115
.b8 101
.b8 116
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 112
.b8 116
.b8 120
.b8 0
.b8 2                                   // Abbrev [2] 0x4a:0x10 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x5a:0x46 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 74                                 // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x6f:0x18 DW_TAG_inlined_subroutine
.b32 74                                 // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 93                                  // DW_AT_call_line
.b8 27                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0x87:0x18 DW_TAG_inlined_subroutine
.b32 74                                 // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp4                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 120                                 // DW_AT_call_line
.b8 33                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
